[07/12/2020 03:28:03 INFO] Running command TRAIN
2020-07-12 03:28:03.506449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-12 03:28:03.987971: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:03.988306: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:28:03.991662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:28:03.993994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:28:03.995470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:28:03.996342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:28:03.998217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:28:03.999503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:28:04.003092: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:28:04.003181: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:04.003489: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:04.003846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
[07/12/2020 03:28:04 INFO] Number of GPUs detected: 1
[07/12/2020 03:28:11 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/utils/pipeline.py:99: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[07/12/2020 03:28:11 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:139: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
2020-07-12 03:28:12.803186: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-12 03:28:12.823620: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3199980000 Hz
2020-07-12 03:28:12.824767: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f0d1c000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-12 03:28:12.824818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-12 03:28:12.890823: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:12.891222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb3e84d350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-12 03:28:12.891233: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-07-12 03:28:12.891396: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:12.891697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:28:12.891723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:28:12.891733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:28:12.891756: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:28:12.891779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:28:12.891788: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:28:12.891797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:28:12.891805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:28:12.891835: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:12.892137: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:12.892422: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 03:28:12.892442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:28:12.893004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 03:28:12.893014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 03:28:12.893017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 03:28:12.893103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:12.893455: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:12.893797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
/disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:72: UserWarning: Seed 2155051337 from outer graph might be getting used by function Dataset_map_lambda, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  fn, num_parallel_calls=config['num_parallel_calls'])
2020-07-12 03:28:22.008627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:22.008999: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:28:22.009058: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:28:22.009085: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:28:22.009093: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:28:22.009100: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:28:22.009108: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:28:22.009115: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:28:22.009122: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:28:22.009193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:22.009530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:22.009844: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 03:28:22.032655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 03:28:22.032668: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 03:28:22.032672: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 03:28:22.032790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:22.033130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:22.033427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
training
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
validation
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
test
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
[07/12/2020 03:28:23 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[07/12/2020 03:28:23 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[07/12/2020 03:28:23 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/train_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/train_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/train_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

DEPTH AND ORIGINAL IMAGE:(1, 1, None, None), (1, 1, None, None), (1, 1, None, None)

(1, 1, None, None)
After expand_dims:(1, 1, None, None),(1, 1, None, None)

mask shape:(1, 1, None, None), (1, 1, None, None)

[07/12/2020 03:28:25 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[07/12/2020 03:28:26 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[07/12/2020 03:28:26 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[07/12/2020 03:28:26 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[07/12/2020 03:28:26 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

masks shape:(1, None, None), (1, 1, None, None), (1, None, None)


keypoint map shape: (1, None, None)


 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/eval_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

Run Time Image Size: (1, 1, None, None)

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/pred_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>}

Run Time Image Size: (1, 1, None, None)
2020-07-12 03:28:28.055381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:28.055721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:28:28.055779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:28:28.055790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:28:28.055798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:28:28.055806: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:28:28.055814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:28:28.055822: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:28:28.055829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:28:28.055869: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:28.056241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:28.056525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 03:28:28.056556: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 03:28:28.056560: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 03:28:28.056579: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 03:28:28.056627: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:28.056937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:28:28.057241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[07/12/2020 03:29:01 INFO] Start training
2020-07-12 03:29:10.049078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:29:10.627845: I tensorflow/core/kernels/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x55fb3ef88de0
2020-07-12 03:29:10.627942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:29:11.296772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:29:11.757465: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:29:12.420449: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.22G (3460258816 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[07/12/2020 03:29:13 INFO] Finished Training Iteration:    0
[07/12/2020 03:32:00 INFO] Iter    0: loss 10.9161, precision 0.0054, recall 0.0069
[07/12/2020 03:34:31 INFO] Running command TRAIN
2020-07-12 03:34:31.952953: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-12 03:34:32.409505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:32.409829: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:34:32.409965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:34:32.410935: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:34:32.411921: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:34:32.412081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:34:32.413098: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:34:32.413667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:34:32.415901: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:34:32.415980: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:32.416281: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:32.416527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
[07/12/2020 03:34:32 INFO] Number of GPUs detected: 1
[07/12/2020 03:34:35 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/utils/pipeline.py:99: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[07/12/2020 03:34:35 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:139: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
2020-07-12 03:34:36.684919: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-12 03:34:36.711433: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3199980000 Hz
2020-07-12 03:34:36.711922: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f1ef0000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-12 03:34:36.711935: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-12 03:34:36.765101: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:36.765487: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55eb600d21c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-12 03:34:36.765500: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-07-12 03:34:36.765678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:36.765986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:34:36.766048: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:34:36.766073: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:34:36.766099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:34:36.766141: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:34:36.766167: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:34:36.766209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:34:36.766251: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:34:36.766345: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:36.766675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:36.766965: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 03:34:36.767020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:34:36.767562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 03:34:36.767571: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 03:34:36.767575: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 03:34:36.767693: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:36.768015: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:36.768325: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
/disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:72: UserWarning: Seed 3541962951 from outer graph might be getting used by function Dataset_map_lambda, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  fn, num_parallel_calls=config['num_parallel_calls'])
2020-07-12 03:34:46.015998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:46.016353: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:34:46.016384: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:34:46.016393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:34:46.016400: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:34:46.016407: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:34:46.016416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:34:46.016449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:34:46.016457: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:34:46.016516: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:46.016836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:46.017104: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 03:34:46.017715: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 03:34:46.017725: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 03:34:46.017729: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 03:34:46.017784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:46.018082: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:46.018317: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
training
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
validation
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
test
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
[07/12/2020 03:34:47 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[07/12/2020 03:34:47 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[07/12/2020 03:34:47 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/train_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/train_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/train_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

DEPTH AND ORIGINAL IMAGE:(1, 1, None, None), (1, 1, None, None), (1, 1, None, None)

(1, 1, None, None)
After expand_dims:(1, 1, None, None),(1, 1, None, None)

mask shape:(1, 1, None, None), (1, 1, None, None)

[07/12/2020 03:34:49 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[07/12/2020 03:34:50 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[07/12/2020 03:34:50 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[07/12/2020 03:34:50 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[07/12/2020 03:34:50 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

masks shape:(1, None, None), (1, 1, None, None), (1, None, None)


keypoint map shape: (1, None, None)


 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/eval_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

Run Time Image Size: (1, 1, None, None)

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/pred_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>}

Run Time Image Size: (1, 1, None, None)
2020-07-12 03:34:52.104316: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:52.104657: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 03:34:52.104716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 03:34:52.104726: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:34:52.104733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 03:34:52.104741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 03:34:52.104748: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:34:52.104768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 03:34:52.104791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:34:52.104870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:52.105198: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:52.105482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 03:34:52.105513: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 03:34:52.105532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 03:34:52.105535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 03:34:52.105582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:52.105921: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 03:34:52.106213: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[07/12/2020 03:35:26 INFO] Start training
2020-07-12 03:35:34.680836: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:35:35.256872: I tensorflow/core/kernels/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x55eb607b7bd0
2020-07-12 03:35:35.256979: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 03:35:35.919236: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 03:35:36.308684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 03:35:37.007155: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.22G (3460258816 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[07/12/2020 03:35:37 INFO] Finished Training Iteration:    0
[07/12/2020 03:38:39 INFO] Iter    0: loss 10.1384, precision 0.0080, recall 0.0103
[07/12/2020 03:39:49 INFO] Saving checkpoint for iteration #200
[07/12/2020 03:39:53 INFO] Finished Training Iteration:  200
[07/12/2020 03:41:00 INFO] Saving checkpoint for iteration #400
[07/12/2020 03:41:00 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
[07/12/2020 03:41:00 INFO] Finished Training Iteration:  400
[07/12/2020 03:42:06 INFO] Saving checkpoint for iteration #600
[07/12/2020 03:42:07 INFO] Finished Training Iteration:  600
[07/12/2020 03:43:15 INFO] Saving checkpoint for iteration #800
[07/12/2020 03:43:15 INFO] Finished Training Iteration:  800
[07/12/2020 03:44:22 INFO] Saving checkpoint for iteration #1000
[07/12/2020 03:44:23 INFO] Finished Training Iteration: 1000
[07/12/2020 03:46:35 INFO] Iter 1000: loss 9.2295, precision 0.0049, recall 0.0060
[07/12/2020 03:47:45 INFO] Saving checkpoint for iteration #1200
[07/12/2020 03:47:45 INFO] Finished Training Iteration: 1200
[07/12/2020 03:48:53 INFO] Saving checkpoint for iteration #1400
[07/12/2020 03:48:54 INFO] Finished Training Iteration: 1400
[07/12/2020 03:50:02 INFO] Saving checkpoint for iteration #1600
[07/12/2020 03:50:02 INFO] Finished Training Iteration: 1600
[07/12/2020 03:51:10 INFO] Saving checkpoint for iteration #1800
[07/12/2020 03:51:10 INFO] Finished Training Iteration: 1800
[07/12/2020 03:52:18 INFO] Saving checkpoint for iteration #2000
[07/12/2020 03:52:18 INFO] Finished Training Iteration: 2000
[07/12/2020 03:54:26 INFO] Iter 2000: loss 9.0721, precision 0.0049, recall 0.0060
[07/12/2020 03:55:33 INFO] Saving checkpoint for iteration #2200
[07/12/2020 03:55:34 INFO] Finished Training Iteration: 2200
[07/12/2020 03:56:41 INFO] Saving checkpoint for iteration #2400
[07/12/2020 03:56:41 INFO] Finished Training Iteration: 2400
[07/12/2020 03:57:49 INFO] Saving checkpoint for iteration #2600
[07/12/2020 03:57:50 INFO] Finished Training Iteration: 2600
[07/12/2020 03:58:57 INFO] Saving checkpoint for iteration #2800
[07/12/2020 03:58:57 INFO] Finished Training Iteration: 2800
[07/12/2020 04:00:04 INFO] Saving checkpoint for iteration #3000
[07/12/2020 04:00:04 INFO] Finished Training Iteration: 3000
[07/12/2020 04:02:09 INFO] Iter 3000: loss 8.5630, precision 0.0049, recall 0.0060
[07/12/2020 04:03:17 INFO] Saving checkpoint for iteration #3200
[07/12/2020 04:03:17 INFO] Finished Training Iteration: 3200
[07/12/2020 04:04:24 INFO] Saving checkpoint for iteration #3400
[07/12/2020 04:04:25 INFO] Finished Training Iteration: 3400
[07/12/2020 04:05:32 INFO] Saving checkpoint for iteration #3600
[07/12/2020 04:05:32 INFO] Finished Training Iteration: 3600
[07/12/2020 04:06:40 INFO] Saving checkpoint for iteration #3800
[07/12/2020 04:06:40 INFO] Finished Training Iteration: 3800
[07/12/2020 04:07:49 INFO] Saving checkpoint for iteration #4000
[07/12/2020 04:07:50 INFO] Finished Training Iteration: 4000
[07/12/2020 04:10:13 INFO] Iter 4000: loss 8.1224, precision 0.0049, recall 0.0060
[07/12/2020 04:11:21 INFO] Saving checkpoint for iteration #4200
[07/12/2020 04:11:22 INFO] Finished Training Iteration: 4200
[07/12/2020 04:12:28 INFO] Saving checkpoint for iteration #4400
[07/12/2020 04:12:29 INFO] Finished Training Iteration: 4400
[07/12/2020 04:13:37 INFO] Saving checkpoint for iteration #4600
[07/12/2020 04:13:37 INFO] Finished Training Iteration: 4600
[07/12/2020 04:14:43 INFO] Saving checkpoint for iteration #4800
[07/12/2020 04:14:44 INFO] Finished Training Iteration: 4800
[07/12/2020 04:15:53 INFO] Saving checkpoint for iteration #5000
[07/12/2020 04:15:53 INFO] Finished Training Iteration: 5000
[07/12/2020 04:18:09 INFO] Iter 5000: loss 8.4582, precision 0.0049, recall 0.0060
[07/12/2020 04:19:13 INFO] Saving checkpoint for iteration #5200
[07/12/2020 04:19:14 INFO] Finished Training Iteration: 5200
[07/12/2020 04:20:23 INFO] Saving checkpoint for iteration #5400
[07/12/2020 04:20:23 INFO] Finished Training Iteration: 5400
[07/12/2020 04:21:31 INFO] Saving checkpoint for iteration #5600
[07/12/2020 04:21:31 INFO] Finished Training Iteration: 5600
[07/12/2020 04:22:38 INFO] Saving checkpoint for iteration #5800
[07/12/2020 04:22:38 INFO] Finished Training Iteration: 5800
[07/12/2020 04:23:47 INFO] Saving checkpoint for iteration #6000
[07/12/2020 04:23:47 INFO] Finished Training Iteration: 6000
[07/12/2020 04:26:05 INFO] Iter 6000: loss 8.0067, precision 0.0049, recall 0.0060
[07/12/2020 04:27:13 INFO] Saving checkpoint for iteration #6200
[07/12/2020 04:27:14 INFO] Finished Training Iteration: 6200
[07/12/2020 04:28:21 INFO] Saving checkpoint for iteration #6400
[07/12/2020 04:28:21 INFO] Finished Training Iteration: 6400
[07/12/2020 04:29:31 INFO] Saving checkpoint for iteration #6600
[07/12/2020 04:29:31 INFO] Finished Training Iteration: 6600
[07/12/2020 04:30:38 INFO] Saving checkpoint for iteration #6800
[07/12/2020 04:30:39 INFO] Finished Training Iteration: 6800
[07/12/2020 04:31:46 INFO] Saving checkpoint for iteration #7000
[07/12/2020 04:31:47 INFO] Finished Training Iteration: 7000
[07/12/2020 04:33:54 INFO] Iter 7000: loss 7.6995, precision 0.0049, recall 0.0060
[07/12/2020 04:34:59 INFO] Saving checkpoint for iteration #7200
[07/12/2020 04:35:00 INFO] Finished Training Iteration: 7200
[07/12/2020 04:36:05 INFO] Saving checkpoint for iteration #7400
[07/12/2020 04:36:06 INFO] Finished Training Iteration: 7400
[07/12/2020 04:37:13 INFO] Saving checkpoint for iteration #7600
[07/12/2020 04:37:13 INFO] Finished Training Iteration: 7600
[07/12/2020 04:38:20 INFO] Saving checkpoint for iteration #7800
[07/12/2020 04:38:20 INFO] Finished Training Iteration: 7800
[07/12/2020 04:39:26 INFO] Saving checkpoint for iteration #8000
[07/12/2020 04:39:26 INFO] Finished Training Iteration: 8000
[07/12/2020 04:41:42 INFO] Iter 8000: loss 7.3756, precision 0.0049, recall 0.0060
[07/12/2020 04:42:50 INFO] Saving checkpoint for iteration #8200
[07/12/2020 04:42:51 INFO] Finished Training Iteration: 8200
[07/12/2020 04:43:59 INFO] Saving checkpoint for iteration #8400
[07/12/2020 04:43:59 INFO] Finished Training Iteration: 8400
[07/12/2020 04:45:08 INFO] Saving checkpoint for iteration #8600
[07/12/2020 04:45:09 INFO] Finished Training Iteration: 8600
[07/12/2020 04:46:18 INFO] Saving checkpoint for iteration #8800
[07/12/2020 04:46:18 INFO] Finished Training Iteration: 8800
[07/12/2020 04:47:22 INFO] Saving checkpoint for iteration #9000
[07/12/2020 04:47:23 INFO] Finished Training Iteration: 9000
[07/12/2020 04:49:27 INFO] Iter 9000: loss 6.7611, precision 0.0065, recall 0.0077
[07/12/2020 04:50:34 INFO] Saving checkpoint for iteration #9200
[07/12/2020 04:50:35 INFO] Finished Training Iteration: 9200
[07/12/2020 04:51:42 INFO] Saving checkpoint for iteration #9400
[07/12/2020 04:51:43 INFO] Finished Training Iteration: 9400
[07/12/2020 04:52:50 INFO] Saving checkpoint for iteration #9600
[07/12/2020 04:52:50 INFO] Finished Training Iteration: 9600
[07/12/2020 04:53:57 INFO] Saving checkpoint for iteration #9800
[07/12/2020 04:53:57 INFO] Finished Training Iteration: 9800
[07/12/2020 04:55:06 INFO] Saving checkpoint for iteration #10000
[07/12/2020 04:55:06 INFO] Finished Training Iteration: 10000
[07/12/2020 04:57:30 INFO] Iter 10000: loss 6.6956, precision 0.0049, recall 0.0060
[07/12/2020 04:58:37 INFO] Saving checkpoint for iteration #10200
[07/12/2020 04:58:37 INFO] Finished Training Iteration: 10200
[07/12/2020 04:59:44 INFO] Saving checkpoint for iteration #10400
[07/12/2020 04:59:45 INFO] Finished Training Iteration: 10400
[07/12/2020 05:00:53 INFO] Saving checkpoint for iteration #10600
[07/12/2020 05:00:53 INFO] Finished Training Iteration: 10600
[07/12/2020 05:01:59 INFO] Saving checkpoint for iteration #10800
[07/12/2020 05:01:59 INFO] Finished Training Iteration: 10800
[07/12/2020 05:03:07 INFO] Saving checkpoint for iteration #11000
[07/12/2020 05:03:07 INFO] Finished Training Iteration: 11000
[07/12/2020 05:05:16 INFO] Iter 11000: loss 6.2370, precision 0.0065, recall 0.0077
[07/12/2020 05:06:20 INFO] Saving checkpoint for iteration #11200
[07/12/2020 05:06:21 INFO] Finished Training Iteration: 11200
[07/12/2020 05:07:29 INFO] Saving checkpoint for iteration #11400
[07/12/2020 05:07:30 INFO] Finished Training Iteration: 11400
[07/12/2020 05:08:38 INFO] Saving checkpoint for iteration #11600
[07/12/2020 05:08:39 INFO] Finished Training Iteration: 11600
[07/12/2020 05:09:45 INFO] Saving checkpoint for iteration #11800
[07/12/2020 05:09:46 INFO] Finished Training Iteration: 11800
[07/12/2020 05:10:53 INFO] Saving checkpoint for iteration #12000
[07/12/2020 05:10:54 INFO] Finished Training Iteration: 12000
[07/12/2020 05:13:00 INFO] Iter 12000: loss 7.0662, precision 0.0049, recall 0.0060
[07/12/2020 05:14:09 INFO] Saving checkpoint for iteration #12200
[07/12/2020 05:14:09 INFO] Finished Training Iteration: 12200
[07/12/2020 05:15:17 INFO] Saving checkpoint for iteration #12400
[07/12/2020 05:15:17 INFO] Finished Training Iteration: 12400
[07/12/2020 05:16:28 INFO] Saving checkpoint for iteration #12600
[07/12/2020 05:16:29 INFO] Finished Training Iteration: 12600
[07/12/2020 05:17:36 INFO] Saving checkpoint for iteration #12800
[07/12/2020 05:17:36 INFO] Finished Training Iteration: 12800
[07/12/2020 05:18:45 INFO] Saving checkpoint for iteration #13000
[07/12/2020 05:18:46 INFO] Finished Training Iteration: 13000
[07/12/2020 05:20:56 INFO] Iter 13000: loss 5.9005, precision 0.0044, recall 0.0055
[07/12/2020 05:22:02 INFO] Saving checkpoint for iteration #13200
[07/12/2020 05:22:02 INFO] Finished Training Iteration: 13200
[07/12/2020 05:23:09 INFO] Saving checkpoint for iteration #13400
[07/12/2020 05:23:10 INFO] Finished Training Iteration: 13400
[07/12/2020 05:24:17 INFO] Saving checkpoint for iteration #13600
[07/12/2020 05:24:17 INFO] Finished Training Iteration: 13600
[07/12/2020 05:25:25 INFO] Saving checkpoint for iteration #13800
[07/12/2020 05:25:25 INFO] Finished Training Iteration: 13800
[07/12/2020 05:26:33 INFO] Saving checkpoint for iteration #14000
[07/12/2020 05:26:33 INFO] Finished Training Iteration: 14000
[07/12/2020 05:28:35 INFO] Iter 14000: loss 6.6299, precision 0.0049, recall 0.0060
[07/12/2020 05:29:42 INFO] Saving checkpoint for iteration #14200
[07/12/2020 05:29:42 INFO] Finished Training Iteration: 14200
[07/12/2020 05:30:48 INFO] Saving checkpoint for iteration #14400
[07/12/2020 05:30:49 INFO] Finished Training Iteration: 14400
[07/12/2020 05:31:56 INFO] Saving checkpoint for iteration #14600
[07/12/2020 05:31:56 INFO] Finished Training Iteration: 14600
[07/12/2020 05:33:03 INFO] Saving checkpoint for iteration #14800
[07/12/2020 05:33:04 INFO] Finished Training Iteration: 14800
[07/12/2020 05:34:12 INFO] Saving checkpoint for iteration #15000
[07/12/2020 05:34:13 INFO] Finished Training Iteration: 15000
[07/12/2020 05:36:22 INFO] Iter 15000: loss 7.1564, precision 0.0065, recall 0.0077
[07/12/2020 05:37:30 INFO] Saving checkpoint for iteration #15200
[07/12/2020 05:37:31 INFO] Finished Training Iteration: 15200
[07/12/2020 05:38:40 INFO] Saving checkpoint for iteration #15400
[07/12/2020 05:38:40 INFO] Finished Training Iteration: 15400
[07/12/2020 05:39:46 INFO] Saving checkpoint for iteration #15600
[07/12/2020 05:39:46 INFO] Finished Training Iteration: 15600
[07/12/2020 05:40:56 INFO] Saving checkpoint for iteration #15800
[07/12/2020 05:40:57 INFO] Finished Training Iteration: 15800
[07/12/2020 05:42:01 INFO] Saving checkpoint for iteration #16000
[07/12/2020 05:42:01 INFO] Finished Training Iteration: 16000
[07/12/2020 05:44:05 INFO] Iter 16000: loss 4.5802, precision 0.0065, recall 0.0077
[07/12/2020 05:45:12 INFO] Saving checkpoint for iteration #16200
[07/12/2020 05:45:13 INFO] Finished Training Iteration: 16200
[07/12/2020 05:46:21 INFO] Saving checkpoint for iteration #16400
[07/12/2020 05:46:21 INFO] Finished Training Iteration: 16400
[07/12/2020 05:47:28 INFO] Saving checkpoint for iteration #16600
[07/12/2020 05:47:28 INFO] Finished Training Iteration: 16600
[07/12/2020 05:48:38 INFO] Saving checkpoint for iteration #16800
[07/12/2020 05:48:38 INFO] Finished Training Iteration: 16800
[07/12/2020 05:49:46 INFO] Saving checkpoint for iteration #17000
[07/12/2020 05:49:47 INFO] Finished Training Iteration: 17000
[07/12/2020 05:52:02 INFO] Iter 17000: loss 5.1796, precision 0.0070, recall 0.0089
[07/12/2020 05:53:08 INFO] Saving checkpoint for iteration #17200
[07/12/2020 05:53:08 INFO] Finished Training Iteration: 17200
[07/12/2020 05:54:19 INFO] Saving checkpoint for iteration #17400
[07/12/2020 05:54:19 INFO] Finished Training Iteration: 17400
[07/12/2020 05:55:27 INFO] Saving checkpoint for iteration #17600
[07/12/2020 05:55:28 INFO] Finished Training Iteration: 17600
[07/12/2020 05:56:35 INFO] Saving checkpoint for iteration #17800
[07/12/2020 05:56:35 INFO] Finished Training Iteration: 17800
[07/12/2020 05:57:44 INFO] Saving checkpoint for iteration #18000
[07/12/2020 05:57:44 INFO] Finished Training Iteration: 18000
[07/12/2020 05:59:53 INFO] Iter 18000: loss 4.0142, precision 0.0060, recall 0.0071
[07/12/2020 06:01:00 INFO] Saving checkpoint for iteration #18200
[07/12/2020 06:01:01 INFO] Finished Training Iteration: 18200
[07/12/2020 06:02:07 INFO] Saving checkpoint for iteration #18400
[07/12/2020 06:02:07 INFO] Finished Training Iteration: 18400
[07/12/2020 06:03:15 INFO] Saving checkpoint for iteration #18600
[07/12/2020 06:03:15 INFO] Finished Training Iteration: 18600
[07/12/2020 06:04:20 INFO] Saving checkpoint for iteration #18800
[07/12/2020 06:04:20 INFO] Finished Training Iteration: 18800
[07/12/2020 06:05:28 INFO] Saving checkpoint for iteration #19000
[07/12/2020 06:05:28 INFO] Finished Training Iteration: 19000
[07/12/2020 06:07:32 INFO] Iter 19000: loss 5.2661, precision 0.0049, recall 0.0060
[07/12/2020 06:08:40 INFO] Saving checkpoint for iteration #19200
[07/12/2020 06:08:41 INFO] Finished Training Iteration: 19200
[07/12/2020 06:09:48 INFO] Saving checkpoint for iteration #19400
[07/12/2020 06:09:48 INFO] Finished Training Iteration: 19400
[07/12/2020 06:10:56 INFO] Saving checkpoint for iteration #19600
[07/12/2020 06:10:57 INFO] Finished Training Iteration: 19600
[07/12/2020 06:12:03 INFO] Saving checkpoint for iteration #19800
[07/12/2020 06:12:03 INFO] Finished Training Iteration: 19800
[07/12/2020 06:13:09 INFO] Saving checkpoint for iteration #20000
[07/12/2020 06:13:10 INFO] Finished Training Iteration: 20000
[07/12/2020 06:14:56 INFO] Iter 20000: loss 4.4853, precision 0.0047, recall 0.0057
[07/12/2020 06:15:59 INFO] Saving checkpoint for iteration #20200
[07/12/2020 06:15:59 INFO] Finished Training Iteration: 20200
[07/12/2020 06:17:04 INFO] Saving checkpoint for iteration #20400
[07/12/2020 06:17:04 INFO] Finished Training Iteration: 20400
[07/12/2020 06:18:10 INFO] Saving checkpoint for iteration #20600
[07/12/2020 06:18:11 INFO] Finished Training Iteration: 20600
[07/12/2020 06:19:18 INFO] Saving checkpoint for iteration #20800
[07/12/2020 06:19:18 INFO] Finished Training Iteration: 20800
[07/12/2020 06:20:27 INFO] Saving checkpoint for iteration #21000
[07/12/2020 06:20:27 INFO] Finished Training Iteration: 21000
[07/12/2020 06:22:17 INFO] Iter 21000: loss 5.9880, precision 0.0054, recall 0.0065
[07/12/2020 06:23:25 INFO] Saving checkpoint for iteration #21200
[07/12/2020 06:23:25 INFO] Finished Training Iteration: 21200
[07/12/2020 06:24:34 INFO] Saving checkpoint for iteration #21400
[07/12/2020 06:24:34 INFO] Finished Training Iteration: 21400
[07/12/2020 06:25:39 INFO] Saving checkpoint for iteration #21600
[07/12/2020 06:25:40 INFO] Finished Training Iteration: 21600
[07/12/2020 06:26:49 INFO] Saving checkpoint for iteration #21800
[07/12/2020 06:26:49 INFO] Finished Training Iteration: 21800
[07/12/2020 06:27:59 INFO] Saving checkpoint for iteration #22000
[07/12/2020 06:27:59 INFO] Finished Training Iteration: 22000
[07/12/2020 06:30:04 INFO] Iter 22000: loss 4.3210, precision 0.0047, recall 0.0058
[07/12/2020 06:31:11 INFO] Saving checkpoint for iteration #22200
[07/12/2020 06:31:11 INFO] Finished Training Iteration: 22200
[07/12/2020 06:32:18 INFO] Saving checkpoint for iteration #22400
[07/12/2020 06:32:18 INFO] Finished Training Iteration: 22400
[07/12/2020 06:33:26 INFO] Saving checkpoint for iteration #22600
[07/12/2020 06:33:26 INFO] Finished Training Iteration: 22600
[07/12/2020 06:34:32 INFO] Saving checkpoint for iteration #22800
[07/12/2020 06:34:32 INFO] Finished Training Iteration: 22800
[07/12/2020 06:35:41 INFO] Saving checkpoint for iteration #23000
[07/12/2020 06:35:41 INFO] Finished Training Iteration: 23000
[07/12/2020 06:37:48 INFO] Iter 23000: loss 4.5863, precision 0.0053, recall 0.0065
[07/12/2020 06:38:57 INFO] Saving checkpoint for iteration #23200
[07/12/2020 06:38:58 INFO] Finished Training Iteration: 23200
[07/12/2020 06:40:07 INFO] Saving checkpoint for iteration #23400
[07/12/2020 06:40:07 INFO] Finished Training Iteration: 23400
[07/12/2020 06:41:14 INFO] Saving checkpoint for iteration #23600
[07/12/2020 06:41:15 INFO] Finished Training Iteration: 23600
[07/12/2020 06:42:22 INFO] Saving checkpoint for iteration #23800
[07/12/2020 06:42:23 INFO] Finished Training Iteration: 23800
[07/12/2020 06:43:30 INFO] Saving checkpoint for iteration #24000
[07/12/2020 06:43:30 INFO] Finished Training Iteration: 24000
[07/12/2020 06:45:37 INFO] Iter 24000: loss 3.8060, precision 0.0047, recall 0.0057
[07/12/2020 06:46:42 INFO] Saving checkpoint for iteration #24200
[07/12/2020 06:46:42 INFO] Finished Training Iteration: 24200
[07/12/2020 06:47:50 INFO] Saving checkpoint for iteration #24400
[07/12/2020 06:47:51 INFO] Finished Training Iteration: 24400
[07/12/2020 06:48:59 INFO] Saving checkpoint for iteration #24600
[07/12/2020 06:48:59 INFO] Finished Training Iteration: 24600
[07/12/2020 06:50:06 INFO] Saving checkpoint for iteration #24800
[07/12/2020 06:50:06 INFO] Finished Training Iteration: 24800
[07/12/2020 06:51:16 INFO] Saving checkpoint for iteration #25000
[07/12/2020 06:51:16 INFO] Finished Training Iteration: 25000
[07/12/2020 06:53:29 INFO] Iter 25000: loss 5.6423, precision 0.0053, recall 0.0066
[07/12/2020 06:54:40 INFO] Saving checkpoint for iteration #25200
[07/12/2020 06:54:40 INFO] Finished Training Iteration: 25200
[07/12/2020 06:55:46 INFO] Saving checkpoint for iteration #25400
[07/12/2020 06:55:47 INFO] Finished Training Iteration: 25400
[07/12/2020 06:56:53 INFO] Saving checkpoint for iteration #25600
[07/12/2020 06:56:53 INFO] Finished Training Iteration: 25600
[07/12/2020 06:58:01 INFO] Saving checkpoint for iteration #25800
[07/12/2020 06:58:01 INFO] Finished Training Iteration: 25800
[07/12/2020 06:59:10 INFO] Saving checkpoint for iteration #26000
[07/12/2020 06:59:11 INFO] Finished Training Iteration: 26000
[07/12/2020 07:00:38 INFO] Iter 26000: loss 5.7564, precision 0.0054, recall 0.0065
[07/12/2020 07:01:43 INFO] Saving checkpoint for iteration #26200
[07/12/2020 07:01:44 INFO] Finished Training Iteration: 26200
[07/12/2020 07:02:54 INFO] Saving checkpoint for iteration #26400
[07/12/2020 07:02:54 INFO] Finished Training Iteration: 26400
[07/12/2020 07:04:01 INFO] Saving checkpoint for iteration #26600
[07/12/2020 07:04:01 INFO] Finished Training Iteration: 26600
[07/12/2020 07:05:05 INFO] Saving checkpoint for iteration #26800
[07/12/2020 07:05:06 INFO] Finished Training Iteration: 26800
[07/12/2020 07:06:12 INFO] Saving checkpoint for iteration #27000
[07/12/2020 07:06:13 INFO] Finished Training Iteration: 27000
[07/12/2020 07:08:08 INFO] Iter 27000: loss 4.1563, precision 0.0082, recall 0.0104
[07/12/2020 07:09:15 INFO] Saving checkpoint for iteration #27200
[07/12/2020 07:09:16 INFO] Finished Training Iteration: 27200
[07/12/2020 07:10:21 INFO] Saving checkpoint for iteration #27400
[07/12/2020 07:10:21 INFO] Finished Training Iteration: 27400
[07/12/2020 07:11:28 INFO] Saving checkpoint for iteration #27600
[07/12/2020 07:11:28 INFO] Finished Training Iteration: 27600
[07/12/2020 07:12:35 INFO] Saving checkpoint for iteration #27800
[07/12/2020 07:12:35 INFO] Finished Training Iteration: 27800
[07/12/2020 07:13:38 INFO] Saving checkpoint for iteration #28000
[07/12/2020 07:13:38 INFO] Finished Training Iteration: 28000
[07/12/2020 07:15:12 INFO] Iter 28000: loss 3.7979, precision 0.0051, recall 0.0064
[07/12/2020 07:16:21 INFO] Saving checkpoint for iteration #28200
[07/12/2020 07:16:22 INFO] Finished Training Iteration: 28200
[07/12/2020 07:17:27 INFO] Saving checkpoint for iteration #28400
[07/12/2020 07:17:28 INFO] Finished Training Iteration: 28400
[07/12/2020 07:18:35 INFO] Saving checkpoint for iteration #28600
[07/12/2020 07:18:35 INFO] Finished Training Iteration: 28600
[07/12/2020 07:19:42 INFO] Saving checkpoint for iteration #28800
[07/12/2020 07:19:43 INFO] Finished Training Iteration: 28800
[07/12/2020 07:20:50 INFO] Saving checkpoint for iteration #29000
[07/12/2020 07:20:50 INFO] Finished Training Iteration: 29000
[07/12/2020 07:22:12 INFO] Iter 29000: loss 5.5653, precision 0.0051, recall 0.0064
[07/12/2020 07:23:18 INFO] Saving checkpoint for iteration #29200
[07/12/2020 07:23:19 INFO] Finished Training Iteration: 29200
[07/12/2020 07:24:27 INFO] Saving checkpoint for iteration #29400
[07/12/2020 07:24:27 INFO] Finished Training Iteration: 29400
[07/12/2020 07:25:34 INFO] Saving checkpoint for iteration #29600
[07/12/2020 07:25:35 INFO] Finished Training Iteration: 29600
[07/12/2020 07:26:44 INFO] Saving checkpoint for iteration #29800
[07/12/2020 07:26:45 INFO] Finished Training Iteration: 29800
[07/12/2020 07:27:52 INFO] Saving checkpoint for iteration #30000
[07/12/2020 07:27:53 INFO] Finished Training Iteration: 30000
[07/12/2020 07:28:09 INFO] Iter 30000: loss 4.1095, precision 0.0057, recall 0.0070
[07/12/2020 07:29:15 INFO] Saving checkpoint for iteration #30200
[07/12/2020 07:29:15 INFO] Finished Training Iteration: 30200
[07/12/2020 07:30:23 INFO] Saving checkpoint for iteration #30400
[07/12/2020 07:30:23 INFO] Finished Training Iteration: 30400
[07/12/2020 07:31:30 INFO] Saving checkpoint for iteration #30600
[07/12/2020 07:31:31 INFO] Finished Training Iteration: 30600
[07/12/2020 07:32:38 INFO] Saving checkpoint for iteration #30800
[07/12/2020 07:32:39 INFO] Finished Training Iteration: 30800
[07/12/2020 07:33:43 INFO] Saving checkpoint for iteration #31000
[07/12/2020 07:33:43 INFO] Finished Training Iteration: 31000
[07/12/2020 07:35:09 INFO] Iter 31000: loss 2.7569, precision 0.0070, recall 0.0087
[07/12/2020 07:36:16 INFO] Saving checkpoint for iteration #31200
[07/12/2020 07:36:16 INFO] Finished Training Iteration: 31200
[07/12/2020 07:37:22 INFO] Saving checkpoint for iteration #31400
[07/12/2020 07:37:22 INFO] Finished Training Iteration: 31400
[07/12/2020 07:38:31 INFO] Saving checkpoint for iteration #31600
[07/12/2020 07:38:32 INFO] Finished Training Iteration: 31600
[07/12/2020 07:39:39 INFO] Saving checkpoint for iteration #31800
[07/12/2020 07:39:39 INFO] Finished Training Iteration: 31800
[07/12/2020 07:40:48 INFO] Saving checkpoint for iteration #32000
[07/12/2020 07:40:48 INFO] Finished Training Iteration: 32000
[07/12/2020 07:40:59 INFO] Iter 32000: loss 6.5241, precision 0.0070, recall 0.0089
[07/12/2020 07:42:09 INFO] Saving checkpoint for iteration #32200
[07/12/2020 07:42:09 INFO] Finished Training Iteration: 32200
[07/12/2020 07:43:16 INFO] Saving checkpoint for iteration #32400
[07/12/2020 07:43:16 INFO] Finished Training Iteration: 32400
[07/12/2020 07:44:27 INFO] Saving checkpoint for iteration #32600
[07/12/2020 07:44:27 INFO] Finished Training Iteration: 32600
[07/12/2020 07:45:33 INFO] Saving checkpoint for iteration #32800
[07/12/2020 07:45:33 INFO] Finished Training Iteration: 32800
[07/12/2020 07:46:41 INFO] Saving checkpoint for iteration #33000
[07/12/2020 07:46:42 INFO] Finished Training Iteration: 33000
/disk_ssd/SuperPoint/superpoint/models/base_model.py:412: RuntimeWarning: Mean of empty slice
  metrics = {m: np.nanmean(metrics[m], axis=0) for m in metrics}
[07/12/2020 07:46:42 INFO] Iter 33000: loss 2.4999, precision nan, recall 0.0000
[07/12/2020 07:47:49 INFO] Saving checkpoint for iteration #33200
[07/12/2020 07:47:49 INFO] Finished Training Iteration: 33200
[07/12/2020 07:48:56 INFO] Saving checkpoint for iteration #33400
[07/12/2020 07:48:57 INFO] Finished Training Iteration: 33400
[07/12/2020 07:50:04 INFO] Saving checkpoint for iteration #33600
[07/12/2020 07:50:05 INFO] Finished Training Iteration: 33600
[07/12/2020 07:51:12 INFO] Saving checkpoint for iteration #33800
[07/12/2020 07:51:12 INFO] Finished Training Iteration: 33800
[07/12/2020 07:52:18 INFO] Saving checkpoint for iteration #34000
[07/12/2020 07:52:18 INFO] Finished Training Iteration: 34000
[07/12/2020 07:52:39 INFO] Iter 34000: loss 6.4971, precision 0.0072, recall 0.0088
[07/12/2020 07:53:48 INFO] Saving checkpoint for iteration #34200
[07/12/2020 07:53:48 INFO] Finished Training Iteration: 34200
[07/12/2020 07:54:54 INFO] Saving checkpoint for iteration #34400
[07/12/2020 07:54:55 INFO] Finished Training Iteration: 34400
[07/12/2020 07:56:01 INFO] Saving checkpoint for iteration #34600
[07/12/2020 07:56:01 INFO] Finished Training Iteration: 34600
[07/12/2020 07:57:10 INFO] Saving checkpoint for iteration #34800
[07/12/2020 07:57:10 INFO] Finished Training Iteration: 34800
[07/12/2020 07:58:18 INFO] Saving checkpoint for iteration #35000
[07/12/2020 07:58:18 INFO] Finished Training Iteration: 35000
[07/12/2020 07:58:19 INFO] Iter 35000: loss 3.6890, precision nan, recall 0.0000
[07/12/2020 07:59:25 INFO] Saving checkpoint for iteration #35200
[07/12/2020 07:59:25 INFO] Finished Training Iteration: 35200
[07/12/2020 08:00:31 INFO] Saving checkpoint for iteration #35400
[07/12/2020 08:00:31 INFO] Finished Training Iteration: 35400
[07/12/2020 08:01:39 INFO] Saving checkpoint for iteration #35600
[07/12/2020 08:01:39 INFO] Finished Training Iteration: 35600
[07/12/2020 08:02:46 INFO] Saving checkpoint for iteration #35800
[07/12/2020 08:02:47 INFO] Finished Training Iteration: 35800
[07/12/2020 08:03:53 INFO] Saving checkpoint for iteration #36000
[07/12/2020 08:03:54 INFO] Finished Training Iteration: 36000
[07/12/2020 08:04:29 INFO] Iter 36000: loss 4.0203, precision 0.0066, recall 0.0083
[07/12/2020 08:05:37 INFO] Saving checkpoint for iteration #36200
[07/12/2020 08:05:37 INFO] Finished Training Iteration: 36200
[07/12/2020 08:06:46 INFO] Saving checkpoint for iteration #36400
[07/12/2020 08:06:46 INFO] Finished Training Iteration: 36400
[07/12/2020 08:07:54 INFO] Saving checkpoint for iteration #36600
[07/12/2020 08:07:54 INFO] Finished Training Iteration: 36600
[07/12/2020 08:09:02 INFO] Saving checkpoint for iteration #36800
[07/12/2020 08:09:02 INFO] Finished Training Iteration: 36800
[07/12/2020 08:10:12 INFO] Saving checkpoint for iteration #37000
[07/12/2020 08:10:13 INFO] Finished Training Iteration: 37000
[07/12/2020 08:10:20 INFO] Iter 37000: loss 4.5006, precision 0.0049, recall 0.0060
[07/12/2020 08:11:30 INFO] Saving checkpoint for iteration #37200
[07/12/2020 08:11:30 INFO] Finished Training Iteration: 37200
[07/12/2020 08:12:39 INFO] Saving checkpoint for iteration #37400
[07/12/2020 08:12:40 INFO] Finished Training Iteration: 37400
[07/12/2020 08:13:49 INFO] Saving checkpoint for iteration #37600
[07/12/2020 08:13:50 INFO] Finished Training Iteration: 37600
[07/12/2020 08:14:55 INFO] Saving checkpoint for iteration #37800
[07/12/2020 08:14:56 INFO] Finished Training Iteration: 37800
[07/12/2020 08:16:03 INFO] Saving checkpoint for iteration #38000
[07/12/2020 08:16:04 INFO] Finished Training Iteration: 38000
[07/12/2020 08:16:04 INFO] Iter 38000: loss 3.7624, precision nan, recall 0.0000
[07/12/2020 08:17:10 INFO] Saving checkpoint for iteration #38200
[07/12/2020 08:17:10 INFO] Finished Training Iteration: 38200
[07/12/2020 08:18:18 INFO] Saving checkpoint for iteration #38400
[07/12/2020 08:18:19 INFO] Finished Training Iteration: 38400
[07/12/2020 08:19:24 INFO] Saving checkpoint for iteration #38600
[07/12/2020 08:19:25 INFO] Finished Training Iteration: 38600
[07/12/2020 08:20:33 INFO] Saving checkpoint for iteration #38800
[07/12/2020 08:20:33 INFO] Finished Training Iteration: 38800
[07/12/2020 08:21:39 INFO] Saving checkpoint for iteration #39000
[07/12/2020 08:21:39 INFO] Finished Training Iteration: 39000
[07/12/2020 08:21:40 INFO] Iter 39000: loss 3.6495, precision nan, recall 0.0000
[07/12/2020 08:22:45 INFO] Saving checkpoint for iteration #39200
[07/12/2020 08:22:45 INFO] Finished Training Iteration: 39200
[07/12/2020 08:23:53 INFO] Saving checkpoint for iteration #39400
[07/12/2020 08:23:54 INFO] Finished Training Iteration: 39400
[07/12/2020 08:25:02 INFO] Saving checkpoint for iteration #39600
[07/12/2020 08:25:03 INFO] Finished Training Iteration: 39600
[07/12/2020 08:26:10 INFO] Saving checkpoint for iteration #39800
[07/12/2020 08:26:11 INFO] Finished Training Iteration: 39800
[07/12/2020 08:27:18 INFO] Saving checkpoint for iteration #40000
[07/12/2020 08:27:19 INFO] Finished Training Iteration: 40000
[07/12/2020 08:27:25 INFO] Iter 40000: loss 4.4138, precision 0.0070, recall 0.0089
[07/12/2020 08:28:30 INFO] Saving checkpoint for iteration #40200
[07/12/2020 08:28:30 INFO] Finished Training Iteration: 40200
[07/12/2020 08:29:40 INFO] Saving checkpoint for iteration #40400
[07/12/2020 08:29:40 INFO] Finished Training Iteration: 40400
[07/12/2020 08:30:48 INFO] Saving checkpoint for iteration #40600
[07/12/2020 08:30:49 INFO] Finished Training Iteration: 40600
[07/12/2020 08:31:57 INFO] Saving checkpoint for iteration #40800
[07/12/2020 08:31:58 INFO] Finished Training Iteration: 40800
[07/12/2020 08:33:05 INFO] Saving checkpoint for iteration #41000
[07/12/2020 08:33:06 INFO] Finished Training Iteration: 41000
[07/12/2020 08:33:44 INFO] Iter 41000: loss 3.4538, precision 0.0063, recall 0.0081
[07/12/2020 08:34:51 INFO] Saving checkpoint for iteration #41200
[07/12/2020 08:34:51 INFO] Finished Training Iteration: 41200
[07/12/2020 08:35:59 INFO] Saving checkpoint for iteration #41400
[07/12/2020 08:36:00 INFO] Finished Training Iteration: 41400
[07/12/2020 08:37:06 INFO] Saving checkpoint for iteration #41600
[07/12/2020 08:37:07 INFO] Finished Training Iteration: 41600
[07/12/2020 08:38:13 INFO] Saving checkpoint for iteration #41800
[07/12/2020 08:38:14 INFO] Finished Training Iteration: 41800
[07/12/2020 08:39:21 INFO] Saving checkpoint for iteration #42000
[07/12/2020 08:39:22 INFO] Finished Training Iteration: 42000
[07/12/2020 08:39:27 INFO] Iter 42000: loss 4.6972, precision 0.0059, recall 0.0074
[07/12/2020 08:40:35 INFO] Saving checkpoint for iteration #42200
[07/12/2020 08:40:35 INFO] Finished Training Iteration: 42200
[07/12/2020 08:41:42 INFO] Saving checkpoint for iteration #42400
[07/12/2020 08:41:43 INFO] Finished Training Iteration: 42400
[07/12/2020 08:42:51 INFO] Saving checkpoint for iteration #42600
[07/12/2020 08:42:52 INFO] Finished Training Iteration: 42600
[07/12/2020 08:43:59 INFO] Saving checkpoint for iteration #42800
[07/12/2020 08:43:59 INFO] Finished Training Iteration: 42800
[07/12/2020 08:45:09 INFO] Saving checkpoint for iteration #43000
[07/12/2020 08:45:09 INFO] Finished Training Iteration: 43000
[07/12/2020 08:45:10 INFO] Iter 43000: loss 4.0148, precision nan, recall 0.0000
[07/12/2020 08:46:18 INFO] Saving checkpoint for iteration #43200
[07/12/2020 08:46:19 INFO] Finished Training Iteration: 43200
[07/12/2020 08:47:25 INFO] Saving checkpoint for iteration #43400
[07/12/2020 08:47:25 INFO] Finished Training Iteration: 43400
[07/12/2020 08:48:33 INFO] Saving checkpoint for iteration #43600
[07/12/2020 08:48:33 INFO] Finished Training Iteration: 43600
[07/12/2020 08:49:42 INFO] Saving checkpoint for iteration #43800
[07/12/2020 08:49:42 INFO] Finished Training Iteration: 43800
[07/12/2020 08:50:51 INFO] Saving checkpoint for iteration #44000
[07/12/2020 08:50:52 INFO] Finished Training Iteration: 44000
[07/12/2020 08:50:52 INFO] Iter 44000: loss 1.6557, precision nan, recall 0.0000
[07/12/2020 08:51:55 INFO] Saving checkpoint for iteration #44200
[07/12/2020 08:51:55 INFO] Finished Training Iteration: 44200
[07/12/2020 08:53:04 INFO] Saving checkpoint for iteration #44400
[07/12/2020 08:53:05 INFO] Finished Training Iteration: 44400
[07/12/2020 08:54:12 INFO] Saving checkpoint for iteration #44600
[07/12/2020 08:54:12 INFO] Finished Training Iteration: 44600
[07/12/2020 08:55:19 INFO] Saving checkpoint for iteration #44800
[07/12/2020 08:55:20 INFO] Finished Training Iteration: 44800
[07/12/2020 08:56:26 INFO] Saving checkpoint for iteration #45000
[07/12/2020 08:56:27 INFO] Finished Training Iteration: 45000
[07/12/2020 08:56:27 INFO] Iter 45000: loss 3.8619, precision nan, recall 0.0000
[07/12/2020 08:57:34 INFO] Saving checkpoint for iteration #45200
[07/12/2020 08:57:35 INFO] Finished Training Iteration: 45200
[07/12/2020 08:58:40 INFO] Saving checkpoint for iteration #45400
[07/12/2020 08:58:41 INFO] Finished Training Iteration: 45400
[07/12/2020 08:59:50 INFO] Saving checkpoint for iteration #45600
[07/12/2020 08:59:50 INFO] Finished Training Iteration: 45600
[07/12/2020 09:00:57 INFO] Saving checkpoint for iteration #45800
[07/12/2020 09:00:57 INFO] Finished Training Iteration: 45800
[07/12/2020 09:02:05 INFO] Saving checkpoint for iteration #46000
[07/12/2020 09:02:06 INFO] Finished Training Iteration: 46000
[07/12/2020 09:02:06 INFO] Iter 46000: loss 5.5492, precision nan, recall 0.0000
[07/12/2020 09:03:15 INFO] Saving checkpoint for iteration #46200
[07/12/2020 09:03:15 INFO] Finished Training Iteration: 46200
[07/12/2020 09:04:23 INFO] Saving checkpoint for iteration #46400
[07/12/2020 09:04:23 INFO] Finished Training Iteration: 46400
[07/12/2020 09:05:31 INFO] Saving checkpoint for iteration #46600
[07/12/2020 09:05:31 INFO] Finished Training Iteration: 46600
[07/12/2020 09:06:37 INFO] Saving checkpoint for iteration #46800
[07/12/2020 09:06:37 INFO] Finished Training Iteration: 46800
[07/12/2020 09:07:45 INFO] Saving checkpoint for iteration #47000
[07/12/2020 09:07:46 INFO] Finished Training Iteration: 47000
[07/12/2020 09:07:46 INFO] Iter 47000: loss 2.8842, precision nan, recall 0.0000
[07/12/2020 09:08:54 INFO] Saving checkpoint for iteration #47200
[07/12/2020 09:08:55 INFO] Finished Training Iteration: 47200
[07/12/2020 09:10:00 INFO] Saving checkpoint for iteration #47400
[07/12/2020 09:10:00 INFO] Finished Training Iteration: 47400
[07/12/2020 09:11:06 INFO] Saving checkpoint for iteration #47600
[07/12/2020 09:11:06 INFO] Finished Training Iteration: 47600
[07/12/2020 09:12:13 INFO] Saving checkpoint for iteration #47800
[07/12/2020 09:12:14 INFO] Finished Training Iteration: 47800
[07/12/2020 09:13:23 INFO] Saving checkpoint for iteration #48000
[07/12/2020 09:13:23 INFO] Finished Training Iteration: 48000
[07/12/2020 09:13:24 INFO] Iter 48000: loss 4.1007, precision nan, recall 0.0000
[07/12/2020 09:14:33 INFO] Saving checkpoint for iteration #48200
[07/12/2020 09:14:33 INFO] Finished Training Iteration: 48200
[07/12/2020 09:15:38 INFO] Saving checkpoint for iteration #48400
[07/12/2020 09:15:39 INFO] Finished Training Iteration: 48400
[07/12/2020 09:16:45 INFO] Saving checkpoint for iteration #48600
[07/12/2020 09:16:45 INFO] Finished Training Iteration: 48600
[07/12/2020 09:17:54 INFO] Saving checkpoint for iteration #48800
[07/12/2020 09:17:54 INFO] Finished Training Iteration: 48800
[07/12/2020 09:19:02 INFO] Saving checkpoint for iteration #49000
[07/12/2020 09:19:03 INFO] Finished Training Iteration: 49000
[07/12/2020 09:19:07 INFO] Iter 49000: loss 2.8347, precision 0.0070, recall 0.0087
[07/12/2020 09:20:17 INFO] Saving checkpoint for iteration #49200
[07/12/2020 09:20:17 INFO] Finished Training Iteration: 49200
[07/12/2020 09:21:23 INFO] Saving checkpoint for iteration #49400
[07/12/2020 09:21:23 INFO] Finished Training Iteration: 49400
[07/12/2020 09:22:29 INFO] Saving checkpoint for iteration #49600
[07/12/2020 09:22:30 INFO] Finished Training Iteration: 49600
[07/12/2020 09:23:39 INFO] Saving checkpoint for iteration #49800
[07/12/2020 09:23:39 INFO] Finished Training Iteration: 49800
[07/12/2020 09:24:46 INFO] Saving checkpoint for iteration #50000
[07/12/2020 09:24:47 INFO] Finished Training Iteration: 50000
[07/12/2020 09:25:06 INFO] Iter 50000: loss 5.7919, precision 0.0045, recall 0.0055
[07/12/2020 09:26:13 INFO] Saving checkpoint for iteration #50200
[07/12/2020 09:26:14 INFO] Finished Training Iteration: 50200
[07/12/2020 09:27:20 INFO] Saving checkpoint for iteration #50400
[07/12/2020 09:27:20 INFO] Finished Training Iteration: 50400
[07/12/2020 09:28:28 INFO] Saving checkpoint for iteration #50600
[07/12/2020 09:28:28 INFO] Finished Training Iteration: 50600
[07/12/2020 09:29:38 INFO] Saving checkpoint for iteration #50800
[07/12/2020 09:29:39 INFO] Finished Training Iteration: 50800
[07/12/2020 09:30:47 INFO] Saving checkpoint for iteration #51000
[07/12/2020 09:30:47 INFO] Finished Training Iteration: 51000
[07/12/2020 09:31:45 INFO] Iter 51000: loss 5.3847, precision 0.0070, recall 0.0089
[07/12/2020 09:32:51 INFO] Saving checkpoint for iteration #51200
[07/12/2020 09:32:51 INFO] Finished Training Iteration: 51200
[07/12/2020 09:33:56 INFO] Saving checkpoint for iteration #51400
[07/12/2020 09:33:56 INFO] Finished Training Iteration: 51400
[07/12/2020 09:35:02 INFO] Saving checkpoint for iteration #51600
[07/12/2020 09:35:03 INFO] Finished Training Iteration: 51600
[07/12/2020 09:36:09 INFO] Saving checkpoint for iteration #51800
[07/12/2020 09:36:09 INFO] Finished Training Iteration: 51800
[07/12/2020 09:37:16 INFO] Saving checkpoint for iteration #52000
[07/12/2020 09:37:16 INFO] Finished Training Iteration: 52000
[07/12/2020 09:37:19 INFO] Iter 52000: loss 4.9337, precision nan, recall 0.0000
[07/12/2020 09:38:25 INFO] Saving checkpoint for iteration #52200
[07/12/2020 09:38:25 INFO] Finished Training Iteration: 52200
[07/12/2020 09:39:36 INFO] Saving checkpoint for iteration #52400
[07/12/2020 09:39:36 INFO] Finished Training Iteration: 52400
[07/12/2020 09:40:42 INFO] Saving checkpoint for iteration #52600
[07/12/2020 09:40:43 INFO] Finished Training Iteration: 52600
[07/12/2020 09:41:53 INFO] Saving checkpoint for iteration #52800
[07/12/2020 09:41:53 INFO] Finished Training Iteration: 52800
[07/12/2020 09:43:00 INFO] Saving checkpoint for iteration #53000
[07/12/2020 09:43:00 INFO] Finished Training Iteration: 53000
[07/12/2020 09:43:01 INFO] Iter 53000: loss 5.5536, precision nan, recall 0.0000
[07/12/2020 09:44:08 INFO] Saving checkpoint for iteration #53200
[07/12/2020 09:44:08 INFO] Finished Training Iteration: 53200
[07/12/2020 09:45:18 INFO] Saving checkpoint for iteration #53400
[07/12/2020 09:45:18 INFO] Finished Training Iteration: 53400
[07/12/2020 09:46:24 INFO] Saving checkpoint for iteration #53600
[07/12/2020 09:46:25 INFO] Finished Training Iteration: 53600
[07/12/2020 09:47:32 INFO] Saving checkpoint for iteration #53800
[07/12/2020 09:47:32 INFO] Finished Training Iteration: 53800
[07/12/2020 09:48:40 INFO] Saving checkpoint for iteration #54000
[07/12/2020 09:48:40 INFO] Finished Training Iteration: 54000
[07/12/2020 09:48:56 INFO] Iter 54000: loss 1.9591, precision 0.0056, recall 0.0067
[07/12/2020 09:50:07 INFO] Saving checkpoint for iteration #54200
[07/12/2020 09:50:08 INFO] Finished Training Iteration: 54200
[07/12/2020 09:51:16 INFO] Saving checkpoint for iteration #54400
[07/12/2020 09:51:17 INFO] Finished Training Iteration: 54400
[07/12/2020 09:52:23 INFO] Saving checkpoint for iteration #54600
[07/12/2020 09:52:23 INFO] Finished Training Iteration: 54600
[07/12/2020 09:53:33 INFO] Saving checkpoint for iteration #54800
[07/12/2020 09:53:33 INFO] Finished Training Iteration: 54800
[07/12/2020 09:54:41 INFO] Saving checkpoint for iteration #55000
[07/12/2020 09:54:41 INFO] Finished Training Iteration: 55000
[07/12/2020 09:54:42 INFO] Iter 55000: loss 3.6022, precision nan, recall 0.0000
[07/12/2020 09:55:49 INFO] Saving checkpoint for iteration #55200
[07/12/2020 09:55:49 INFO] Finished Training Iteration: 55200
[07/12/2020 09:56:59 INFO] Saving checkpoint for iteration #55400
[07/12/2020 09:56:59 INFO] Finished Training Iteration: 55400
[07/12/2020 09:58:07 INFO] Saving checkpoint for iteration #55600
[07/12/2020 09:58:08 INFO] Finished Training Iteration: 55600
[07/12/2020 09:59:15 INFO] Saving checkpoint for iteration #55800
[07/12/2020 09:59:16 INFO] Finished Training Iteration: 55800
[07/12/2020 10:00:23 INFO] Saving checkpoint for iteration #56000
[07/12/2020 10:00:24 INFO] Finished Training Iteration: 56000
[07/12/2020 10:00:24 INFO] Iter 56000: loss 5.2288, precision nan, recall 0.0000
[07/12/2020 10:01:34 INFO] Saving checkpoint for iteration #56200
[07/12/2020 10:01:34 INFO] Finished Training Iteration: 56200
[07/12/2020 10:02:42 INFO] Saving checkpoint for iteration #56400
[07/12/2020 10:02:42 INFO] Finished Training Iteration: 56400
[07/12/2020 10:03:48 INFO] Saving checkpoint for iteration #56600
[07/12/2020 10:03:49 INFO] Finished Training Iteration: 56600
[07/12/2020 10:04:56 INFO] Saving checkpoint for iteration #56800
[07/12/2020 10:04:56 INFO] Finished Training Iteration: 56800
[07/12/2020 10:06:02 INFO] Saving checkpoint for iteration #57000
[07/12/2020 10:06:03 INFO] Finished Training Iteration: 57000
[07/12/2020 10:06:03 INFO] Iter 57000: loss 3.2462, precision nan, recall 0.0000
[07/12/2020 10:07:08 INFO] Saving checkpoint for iteration #57200
[07/12/2020 10:07:08 INFO] Finished Training Iteration: 57200
[07/12/2020 10:08:14 INFO] Saving checkpoint for iteration #57400
[07/12/2020 10:08:15 INFO] Finished Training Iteration: 57400
[07/12/2020 10:09:22 INFO] Saving checkpoint for iteration #57600
[07/12/2020 10:09:23 INFO] Finished Training Iteration: 57600
[07/12/2020 10:10:29 INFO] Saving checkpoint for iteration #57800
[07/12/2020 10:10:30 INFO] Finished Training Iteration: 57800
[07/12/2020 10:11:37 INFO] Saving checkpoint for iteration #58000
[07/12/2020 10:11:38 INFO] Finished Training Iteration: 58000
[07/12/2020 10:11:47 INFO] Iter 58000: loss 4.3705, precision 0.0056, recall 0.0067
[07/12/2020 10:12:54 INFO] Saving checkpoint for iteration #58200
[07/12/2020 10:12:55 INFO] Finished Training Iteration: 58200
[07/12/2020 10:14:04 INFO] Saving checkpoint for iteration #58400
[07/12/2020 10:14:05 INFO] Finished Training Iteration: 58400
[07/12/2020 10:15:10 INFO] Saving checkpoint for iteration #58600
[07/12/2020 10:15:11 INFO] Finished Training Iteration: 58600
[07/12/2020 10:16:19 INFO] Saving checkpoint for iteration #58800
[07/12/2020 10:16:19 INFO] Finished Training Iteration: 58800
[07/12/2020 10:17:25 INFO] Saving checkpoint for iteration #59000
[07/12/2020 10:17:26 INFO] Finished Training Iteration: 59000
[07/12/2020 10:17:28 INFO] Iter 59000: loss 4.5811, precision 0.0060, recall 0.0076
[07/12/2020 10:18:35 INFO] Saving checkpoint for iteration #59200
[07/12/2020 10:18:35 INFO] Finished Training Iteration: 59200
[07/12/2020 10:19:41 INFO] Saving checkpoint for iteration #59400
[07/12/2020 10:19:42 INFO] Finished Training Iteration: 59400
[07/12/2020 10:20:47 INFO] Saving checkpoint for iteration #59600
[07/12/2020 10:20:48 INFO] Finished Training Iteration: 59600
[07/12/2020 10:21:57 INFO] Saving checkpoint for iteration #59800
[07/12/2020 10:21:58 INFO] Finished Training Iteration: 59800
[07/12/2020 10:23:05 INFO] Saving checkpoint for iteration #60000
[07/12/2020 10:23:05 INFO] Finished Training Iteration: 60000
[07/12/2020 10:23:07 INFO] Iter 60000: loss 4.9675, precision 0.0055, recall 0.0068
[07/12/2020 10:24:13 INFO] Saving checkpoint for iteration #60200
[07/12/2020 10:24:13 INFO] Finished Training Iteration: 60200
[07/12/2020 10:25:24 INFO] Saving checkpoint for iteration #60400
[07/12/2020 10:25:24 INFO] Finished Training Iteration: 60400
[07/12/2020 10:26:33 INFO] Saving checkpoint for iteration #60600
[07/12/2020 10:26:33 INFO] Finished Training Iteration: 60600
[07/12/2020 10:27:42 INFO] Saving checkpoint for iteration #60800
[07/12/2020 10:27:42 INFO] Finished Training Iteration: 60800
[07/12/2020 10:28:50 INFO] Saving checkpoint for iteration #61000
[07/12/2020 10:28:50 INFO] Finished Training Iteration: 61000
[07/12/2020 10:28:55 INFO] Iter 61000: loss 4.2036, precision 0.0047, recall 0.0059
[07/12/2020 10:30:04 INFO] Saving checkpoint for iteration #61200
[07/12/2020 10:30:04 INFO] Finished Training Iteration: 61200
[07/12/2020 10:31:12 INFO] Saving checkpoint for iteration #61400
[07/12/2020 10:31:12 INFO] Finished Training Iteration: 61400
[07/12/2020 10:32:20 INFO] Saving checkpoint for iteration #61600
[07/12/2020 10:32:21 INFO] Finished Training Iteration: 61600
[07/12/2020 10:33:27 INFO] Saving checkpoint for iteration #61800
[07/12/2020 10:33:28 INFO] Finished Training Iteration: 61800
[07/12/2020 10:34:32 INFO] Saving checkpoint for iteration #62000
[07/12/2020 10:34:33 INFO] Finished Training Iteration: 62000
[07/12/2020 10:35:14 INFO] Iter 62000: loss 4.3909, precision 0.0070, recall 0.0089
[07/12/2020 10:36:23 INFO] Saving checkpoint for iteration #62200
[07/12/2020 10:36:23 INFO] Finished Training Iteration: 62200
[07/12/2020 10:37:32 INFO] Saving checkpoint for iteration #62400
[07/12/2020 10:37:32 INFO] Finished Training Iteration: 62400
[07/12/2020 10:38:41 INFO] Saving checkpoint for iteration #62600
[07/12/2020 10:38:42 INFO] Finished Training Iteration: 62600
[07/12/2020 10:39:51 INFO] Saving checkpoint for iteration #62800
[07/12/2020 10:39:51 INFO] Finished Training Iteration: 62800
[07/12/2020 10:40:58 INFO] Saving checkpoint for iteration #63000
[07/12/2020 10:40:58 INFO] Finished Training Iteration: 63000
[07/12/2020 10:40:59 INFO] Iter 63000: loss 4.2969, precision nan, recall 0.0000
[07/12/2020 10:42:07 INFO] Saving checkpoint for iteration #63200
[07/12/2020 10:42:07 INFO] Finished Training Iteration: 63200
[07/12/2020 10:43:14 INFO] Saving checkpoint for iteration #63400
[07/12/2020 10:43:14 INFO] Finished Training Iteration: 63400
[07/12/2020 10:44:20 INFO] Saving checkpoint for iteration #63600
[07/12/2020 10:44:21 INFO] Finished Training Iteration: 63600
[07/12/2020 10:45:29 INFO] Saving checkpoint for iteration #63800
[07/12/2020 10:45:30 INFO] Finished Training Iteration: 63800
[07/12/2020 10:46:36 INFO] Saving checkpoint for iteration #64000
[07/12/2020 10:46:37 INFO] Finished Training Iteration: 64000
[07/12/2020 10:46:49 INFO] Iter 64000: loss 4.7286, precision 0.0054, recall 0.0068
[07/12/2020 10:47:59 INFO] Saving checkpoint for iteration #64200
[07/12/2020 10:47:59 INFO] Finished Training Iteration: 64200
[07/12/2020 10:49:05 INFO] Saving checkpoint for iteration #64400
[07/12/2020 10:49:05 INFO] Finished Training Iteration: 64400
[07/12/2020 10:50:12 INFO] Saving checkpoint for iteration #64600
[07/12/2020 10:50:12 INFO] Finished Training Iteration: 64600
[07/12/2020 10:51:20 INFO] Saving checkpoint for iteration #64800
[07/12/2020 10:51:20 INFO] Finished Training Iteration: 64800
[07/12/2020 10:52:28 INFO] Saving checkpoint for iteration #65000
[07/12/2020 10:52:29 INFO] Finished Training Iteration: 65000
[07/12/2020 10:52:30 INFO] Iter 65000: loss 5.2612, precision nan, recall 0.0000
[07/12/2020 10:53:38 INFO] Saving checkpoint for iteration #65200
[07/12/2020 10:53:38 INFO] Finished Training Iteration: 65200
[07/12/2020 10:54:46 INFO] Saving checkpoint for iteration #65400
[07/12/2020 10:54:46 INFO] Finished Training Iteration: 65400
[07/12/2020 10:55:51 INFO] Saving checkpoint for iteration #65600
[07/12/2020 10:55:52 INFO] Finished Training Iteration: 65600
[07/12/2020 10:56:59 INFO] Saving checkpoint for iteration #65800
[07/12/2020 10:56:59 INFO] Finished Training Iteration: 65800
[07/12/2020 10:58:07 INFO] Saving checkpoint for iteration #66000
[07/12/2020 10:58:07 INFO] Finished Training Iteration: 66000
[07/12/2020 10:58:08 INFO] Iter 66000: loss 5.0634, precision nan, recall 0.0000
[07/12/2020 10:59:15 INFO] Saving checkpoint for iteration #66200
[07/12/2020 10:59:16 INFO] Finished Training Iteration: 66200
[07/12/2020 11:00:22 INFO] Saving checkpoint for iteration #66400
[07/12/2020 11:00:22 INFO] Finished Training Iteration: 66400
[07/12/2020 11:01:30 INFO] Saving checkpoint for iteration #66600
[07/12/2020 11:01:30 INFO] Finished Training Iteration: 66600
[07/12/2020 11:02:40 INFO] Saving checkpoint for iteration #66800
[07/12/2020 11:02:40 INFO] Finished Training Iteration: 66800
[07/12/2020 11:03:48 INFO] Saving checkpoint for iteration #67000
[07/12/2020 11:03:48 INFO] Finished Training Iteration: 67000
[07/12/2020 11:03:49 INFO] Iter 67000: loss 2.8658, precision nan, recall 0.0000
[07/12/2020 11:04:54 INFO] Saving checkpoint for iteration #67200
[07/12/2020 11:04:55 INFO] Finished Training Iteration: 67200
[07/12/2020 11:06:02 INFO] Saving checkpoint for iteration #67400
[07/12/2020 11:06:03 INFO] Finished Training Iteration: 67400
[07/12/2020 11:07:08 INFO] Saving checkpoint for iteration #67600
[07/12/2020 11:07:09 INFO] Finished Training Iteration: 67600
[07/12/2020 11:08:18 INFO] Saving checkpoint for iteration #67800
[07/12/2020 11:08:18 INFO] Finished Training Iteration: 67800
[07/12/2020 11:09:26 INFO] Saving checkpoint for iteration #68000
[07/12/2020 11:09:27 INFO] Finished Training Iteration: 68000
[07/12/2020 11:09:32 INFO] Iter 68000: loss 3.5308, precision 0.0053, recall 0.0065
[07/12/2020 11:10:42 INFO] Saving checkpoint for iteration #68200
[07/12/2020 11:10:42 INFO] Finished Training Iteration: 68200
[07/12/2020 11:11:49 INFO] Saving checkpoint for iteration #68400
[07/12/2020 11:11:50 INFO] Finished Training Iteration: 68400
[07/12/2020 11:12:57 INFO] Saving checkpoint for iteration #68600
[07/12/2020 11:12:58 INFO] Finished Training Iteration: 68600
[07/12/2020 11:14:04 INFO] Saving checkpoint for iteration #68800
[07/12/2020 11:14:04 INFO] Finished Training Iteration: 68800
[07/12/2020 11:15:09 INFO] Saving checkpoint for iteration #69000
[07/12/2020 11:15:09 INFO] Finished Training Iteration: 69000
[07/12/2020 11:15:10 INFO] Iter 69000: loss 4.4013, precision nan, recall 0.0000
[07/12/2020 11:16:18 INFO] Saving checkpoint for iteration #69200
[07/12/2020 11:16:18 INFO] Finished Training Iteration: 69200
[07/12/2020 11:17:25 INFO] Saving checkpoint for iteration #69400
[07/12/2020 11:17:25 INFO] Finished Training Iteration: 69400
[07/12/2020 11:18:33 INFO] Saving checkpoint for iteration #69600
[07/12/2020 11:18:33 INFO] Finished Training Iteration: 69600
[07/12/2020 11:19:39 INFO] Saving checkpoint for iteration #69800
[07/12/2020 11:19:40 INFO] Finished Training Iteration: 69800
[07/12/2020 11:20:46 INFO] Saving checkpoint for iteration #70000
[07/12/2020 11:20:47 INFO] Finished Training Iteration: 70000
[07/12/2020 11:20:52 INFO] Iter 70000: loss 3.4896, precision 0.0055, recall 0.0068
[07/12/2020 11:21:58 INFO] Saving checkpoint for iteration #70200
[07/12/2020 11:21:58 INFO] Finished Training Iteration: 70200
[07/12/2020 11:23:04 INFO] Saving checkpoint for iteration #70400
[07/12/2020 11:23:05 INFO] Finished Training Iteration: 70400
[07/12/2020 11:24:12 INFO] Saving checkpoint for iteration #70600
[07/12/2020 11:24:13 INFO] Finished Training Iteration: 70600
[07/12/2020 11:25:19 INFO] Saving checkpoint for iteration #70800
[07/12/2020 11:25:19 INFO] Finished Training Iteration: 70800
[07/12/2020 11:26:23 INFO] Saving checkpoint for iteration #71000
[07/12/2020 11:26:24 INFO] Finished Training Iteration: 71000
[07/12/2020 11:26:24 INFO] Iter 71000: loss 3.8942, precision nan, recall 0.0000
[07/12/2020 11:27:32 INFO] Saving checkpoint for iteration #71200
[07/12/2020 11:27:33 INFO] Finished Training Iteration: 71200
[07/12/2020 11:28:41 INFO] Saving checkpoint for iteration #71400
[07/12/2020 11:28:42 INFO] Finished Training Iteration: 71400
[07/12/2020 11:29:51 INFO] Saving checkpoint for iteration #71600
[07/12/2020 11:29:51 INFO] Finished Training Iteration: 71600
[07/12/2020 11:30:58 INFO] Saving checkpoint for iteration #71800
[07/12/2020 11:30:58 INFO] Finished Training Iteration: 71800
[07/12/2020 11:32:06 INFO] Saving checkpoint for iteration #72000
[07/12/2020 11:32:06 INFO] Finished Training Iteration: 72000
[07/12/2020 11:32:07 INFO] Iter 72000: loss 3.8015, precision nan, recall 0.0000
[07/12/2020 11:33:14 INFO] Saving checkpoint for iteration #72200
[07/12/2020 11:33:14 INFO] Finished Training Iteration: 72200
[07/12/2020 11:34:21 INFO] Saving checkpoint for iteration #72400
[07/12/2020 11:34:21 INFO] Finished Training Iteration: 72400
[07/12/2020 11:35:30 INFO] Saving checkpoint for iteration #72600
[07/12/2020 11:35:31 INFO] Finished Training Iteration: 72600
[07/12/2020 11:36:38 INFO] Saving checkpoint for iteration #72800
[07/12/2020 11:36:39 INFO] Finished Training Iteration: 72800
[07/12/2020 11:37:45 INFO] Saving checkpoint for iteration #73000
[07/12/2020 11:37:45 INFO] Finished Training Iteration: 73000
[07/12/2020 11:37:47 INFO] Iter 73000: loss 2.5101, precision 0.0053, recall 0.0064
[07/12/2020 11:38:54 INFO] Saving checkpoint for iteration #73200
[07/12/2020 11:38:55 INFO] Finished Training Iteration: 73200
[07/12/2020 11:40:02 INFO] Saving checkpoint for iteration #73400
[07/12/2020 11:40:02 INFO] Finished Training Iteration: 73400
[07/12/2020 11:41:12 INFO] Saving checkpoint for iteration #73600
[07/12/2020 11:41:13 INFO] Finished Training Iteration: 73600
[07/12/2020 11:42:21 INFO] Saving checkpoint for iteration #73800
[07/12/2020 11:42:21 INFO] Finished Training Iteration: 73800
[07/12/2020 11:43:29 INFO] Saving checkpoint for iteration #74000
[07/12/2020 11:43:30 INFO] Finished Training Iteration: 74000
[07/12/2020 11:43:30 INFO] Iter 74000: loss 3.5326, precision nan, recall 0.0000
[07/12/2020 11:44:40 INFO] Saving checkpoint for iteration #74200
[07/12/2020 11:44:41 INFO] Finished Training Iteration: 74200
[07/12/2020 11:45:49 INFO] Saving checkpoint for iteration #74400
[07/12/2020 11:45:49 INFO] Finished Training Iteration: 74400
[07/12/2020 11:46:56 INFO] Saving checkpoint for iteration #74600
[07/12/2020 11:46:57 INFO] Finished Training Iteration: 74600
[07/12/2020 11:48:04 INFO] Saving checkpoint for iteration #74800
[07/12/2020 11:48:04 INFO] Finished Training Iteration: 74800
[07/12/2020 11:49:09 INFO] Saving checkpoint for iteration #75000
[07/12/2020 11:49:10 INFO] Finished Training Iteration: 75000
[07/12/2020 11:49:10 INFO] Iter 75000: loss 2.0643, precision nan, recall 0.0000
[07/12/2020 11:50:18 INFO] Saving checkpoint for iteration #75200
[07/12/2020 11:50:18 INFO] Finished Training Iteration: 75200
[07/12/2020 11:51:29 INFO] Saving checkpoint for iteration #75400
[07/12/2020 11:51:30 INFO] Finished Training Iteration: 75400
[07/12/2020 11:52:40 INFO] Saving checkpoint for iteration #75600
[07/12/2020 11:52:41 INFO] Finished Training Iteration: 75600
[07/12/2020 11:53:48 INFO] Saving checkpoint for iteration #75800
[07/12/2020 11:53:48 INFO] Finished Training Iteration: 75800
[07/12/2020 11:54:56 INFO] Saving checkpoint for iteration #76000
[07/12/2020 11:54:57 INFO] Finished Training Iteration: 76000
[07/12/2020 11:54:58 INFO] Iter 76000: loss 5.3716, precision 0.0051, recall 0.0064
[07/12/2020 11:56:04 INFO] Saving checkpoint for iteration #76200
[07/12/2020 11:56:05 INFO] Finished Training Iteration: 76200
[07/12/2020 11:57:13 INFO] Saving checkpoint for iteration #76400
[07/12/2020 11:57:13 INFO] Finished Training Iteration: 76400
[07/12/2020 11:58:19 INFO] Saving checkpoint for iteration #76600
[07/12/2020 11:58:20 INFO] Finished Training Iteration: 76600
[07/12/2020 11:59:26 INFO] Saving checkpoint for iteration #76800
[07/12/2020 11:59:27 INFO] Finished Training Iteration: 76800
[07/12/2020 12:00:36 INFO] Saving checkpoint for iteration #77000
[07/12/2020 12:00:37 INFO] Finished Training Iteration: 77000
[07/12/2020 12:00:41 INFO] Iter 77000: loss 5.2701, precision 0.0047, recall 0.0059
[07/12/2020 12:01:48 INFO] Saving checkpoint for iteration #77200
[07/12/2020 12:01:48 INFO] Finished Training Iteration: 77200
[07/12/2020 12:02:55 INFO] Saving checkpoint for iteration #77400
[07/12/2020 12:02:56 INFO] Finished Training Iteration: 77400
[07/12/2020 12:04:05 INFO] Saving checkpoint for iteration #77600
[07/12/2020 12:04:05 INFO] Finished Training Iteration: 77600
[07/12/2020 12:05:13 INFO] Saving checkpoint for iteration #77800
[07/12/2020 12:05:13 INFO] Finished Training Iteration: 77800
[07/12/2020 12:06:20 INFO] Saving checkpoint for iteration #78000
[07/12/2020 12:06:20 INFO] Finished Training Iteration: 78000
[07/12/2020 12:07:44 INFO] Iter 78000: loss 4.4333, precision 0.0053, recall 0.0066
[07/12/2020 12:08:51 INFO] Saving checkpoint for iteration #78200
[07/12/2020 12:08:51 INFO] Finished Training Iteration: 78200
[07/12/2020 12:10:00 INFO] Saving checkpoint for iteration #78400
[07/12/2020 12:10:00 INFO] Finished Training Iteration: 78400
[07/12/2020 12:11:06 INFO] Saving checkpoint for iteration #78600
[07/12/2020 12:11:06 INFO] Finished Training Iteration: 78600
[07/12/2020 12:12:13 INFO] Saving checkpoint for iteration #78800
[07/12/2020 12:12:13 INFO] Finished Training Iteration: 78800
[07/12/2020 12:13:21 INFO] Saving checkpoint for iteration #79000
[07/12/2020 12:13:21 INFO] Finished Training Iteration: 79000
[07/12/2020 12:13:22 INFO] Iter 79000: loss 4.1221, precision nan, recall 0.0000
[07/12/2020 12:14:29 INFO] Saving checkpoint for iteration #79200
[07/12/2020 12:14:29 INFO] Finished Training Iteration: 79200
[07/12/2020 12:15:36 INFO] Saving checkpoint for iteration #79400
[07/12/2020 12:15:37 INFO] Finished Training Iteration: 79400
[07/12/2020 12:16:44 INFO] Saving checkpoint for iteration #79600
[07/12/2020 12:16:45 INFO] Finished Training Iteration: 79600
[07/12/2020 12:17:51 INFO] Saving checkpoint for iteration #79800
[07/12/2020 12:17:52 INFO] Finished Training Iteration: 79800
[07/12/2020 12:18:59 INFO] Saving checkpoint for iteration #80000
[07/12/2020 12:19:00 INFO] Finished Training Iteration: 80000
[07/12/2020 12:19:00 INFO] Iter 80000: loss 5.0002, precision nan, recall 0.0000
[07/12/2020 12:20:09 INFO] Saving checkpoint for iteration #80200
[07/12/2020 12:20:10 INFO] Finished Training Iteration: 80200
[07/12/2020 12:21:16 INFO] Saving checkpoint for iteration #80400
[07/12/2020 12:21:17 INFO] Finished Training Iteration: 80400
[07/12/2020 12:22:26 INFO] Saving checkpoint for iteration #80600
[07/12/2020 12:22:27 INFO] Finished Training Iteration: 80600
[07/12/2020 12:23:34 INFO] Saving checkpoint for iteration #80800
[07/12/2020 12:23:34 INFO] Finished Training Iteration: 80800
[07/12/2020 12:24:41 INFO] Saving checkpoint for iteration #81000
[07/12/2020 12:24:41 INFO] Finished Training Iteration: 81000
[07/12/2020 12:25:33 INFO] Iter 81000: loss 4.9233, precision 0.0059, recall 0.0074
[07/12/2020 12:26:41 INFO] Saving checkpoint for iteration #81200
[07/12/2020 12:26:42 INFO] Finished Training Iteration: 81200
[07/12/2020 12:27:48 INFO] Saving checkpoint for iteration #81400
[07/12/2020 12:27:49 INFO] Finished Training Iteration: 81400
[07/12/2020 12:28:54 INFO] Saving checkpoint for iteration #81600
[07/12/2020 12:28:54 INFO] Finished Training Iteration: 81600
[07/12/2020 12:30:01 INFO] Saving checkpoint for iteration #81800
[07/12/2020 12:30:01 INFO] Finished Training Iteration: 81800
[07/12/2020 12:31:10 INFO] Saving checkpoint for iteration #82000
[07/12/2020 12:31:11 INFO] Finished Training Iteration: 82000
[07/12/2020 12:31:12 INFO] Iter 82000: loss 3.1079, precision 0.0072, recall 0.0088
[07/12/2020 12:32:19 INFO] Saving checkpoint for iteration #82200
[07/12/2020 12:32:19 INFO] Finished Training Iteration: 82200
[07/12/2020 12:33:27 INFO] Saving checkpoint for iteration #82400
[07/12/2020 12:33:27 INFO] Finished Training Iteration: 82400
[07/12/2020 12:34:34 INFO] Saving checkpoint for iteration #82600
[07/12/2020 12:34:34 INFO] Finished Training Iteration: 82600
[07/12/2020 12:35:40 INFO] Saving checkpoint for iteration #82800
[07/12/2020 12:35:40 INFO] Finished Training Iteration: 82800
[07/12/2020 12:36:45 INFO] Saving checkpoint for iteration #83000
[07/12/2020 12:36:46 INFO] Finished Training Iteration: 83000
[07/12/2020 12:36:55 INFO] Iter 83000: loss 4.8263, precision 0.0070, recall 0.0089
[07/12/2020 12:38:03 INFO] Saving checkpoint for iteration #83200
[07/12/2020 12:38:04 INFO] Finished Training Iteration: 83200
[07/12/2020 12:39:10 INFO] Saving checkpoint for iteration #83400
[07/12/2020 12:39:10 INFO] Finished Training Iteration: 83400
[07/12/2020 12:40:17 INFO] Saving checkpoint for iteration #83600
[07/12/2020 12:40:17 INFO] Finished Training Iteration: 83600
[07/12/2020 12:41:25 INFO] Saving checkpoint for iteration #83800
[07/12/2020 12:41:25 INFO] Finished Training Iteration: 83800
[07/12/2020 12:42:34 INFO] Saving checkpoint for iteration #84000
[07/12/2020 12:42:35 INFO] Finished Training Iteration: 84000
[07/12/2020 12:42:35 INFO] Iter 84000: loss 3.5535, precision nan, recall 0.0000
[07/12/2020 12:43:44 INFO] Saving checkpoint for iteration #84200
[07/12/2020 12:43:44 INFO] Finished Training Iteration: 84200
[07/12/2020 12:44:52 INFO] Saving checkpoint for iteration #84400
[07/12/2020 12:44:53 INFO] Finished Training Iteration: 84400
[07/12/2020 12:46:00 INFO] Saving checkpoint for iteration #84600
[07/12/2020 12:46:00 INFO] Finished Training Iteration: 84600
[07/12/2020 12:47:07 INFO] Saving checkpoint for iteration #84800
[07/12/2020 12:47:07 INFO] Finished Training Iteration: 84800
[07/12/2020 12:48:16 INFO] Saving checkpoint for iteration #85000
[07/12/2020 12:48:17 INFO] Finished Training Iteration: 85000
[07/12/2020 12:48:18 INFO] Iter 85000: loss 4.2984, precision nan, recall 0.0000
[07/12/2020 12:49:23 INFO] Saving checkpoint for iteration #85200
[07/12/2020 12:49:23 INFO] Finished Training Iteration: 85200
[07/12/2020 12:50:31 INFO] Saving checkpoint for iteration #85400
[07/12/2020 12:50:31 INFO] Finished Training Iteration: 85400
[07/12/2020 12:51:38 INFO] Saving checkpoint for iteration #85600
[07/12/2020 12:51:39 INFO] Finished Training Iteration: 85600
[07/12/2020 12:52:44 INFO] Saving checkpoint for iteration #85800
[07/12/2020 12:52:44 INFO] Finished Training Iteration: 85800
[07/12/2020 12:53:52 INFO] Saving checkpoint for iteration #86000
[07/12/2020 12:53:52 INFO] Finished Training Iteration: 86000
[07/12/2020 12:54:45 INFO] Iter 86000: loss 4.3508, precision 0.0053, recall 0.0065
[07/12/2020 12:55:52 INFO] Saving checkpoint for iteration #86200
[07/12/2020 12:55:52 INFO] Finished Training Iteration: 86200
[07/12/2020 12:56:59 INFO] Saving checkpoint for iteration #86400
[07/12/2020 12:57:00 INFO] Finished Training Iteration: 86400
[07/12/2020 12:58:08 INFO] Saving checkpoint for iteration #86600
[07/12/2020 12:58:09 INFO] Finished Training Iteration: 86600
[07/12/2020 12:59:18 INFO] Saving checkpoint for iteration #86800
[07/12/2020 12:59:18 INFO] Finished Training Iteration: 86800
[07/12/2020 13:00:27 INFO] Saving checkpoint for iteration #87000
[07/12/2020 13:00:27 INFO] Finished Training Iteration: 87000
[07/12/2020 13:00:28 INFO] Iter 87000: loss 2.5640, precision nan, recall 0.0000
[07/12/2020 13:01:34 INFO] Saving checkpoint for iteration #87200
[07/12/2020 13:01:34 INFO] Finished Training Iteration: 87200
[07/12/2020 13:02:42 INFO] Saving checkpoint for iteration #87400
[07/12/2020 13:02:43 INFO] Finished Training Iteration: 87400
[07/12/2020 13:03:48 INFO] Saving checkpoint for iteration #87600
[07/12/2020 13:03:49 INFO] Finished Training Iteration: 87600
[07/12/2020 13:04:57 INFO] Saving checkpoint for iteration #87800
[07/12/2020 13:04:57 INFO] Finished Training Iteration: 87800
[07/12/2020 13:06:03 INFO] Saving checkpoint for iteration #88000
[07/12/2020 13:06:03 INFO] Finished Training Iteration: 88000
[07/12/2020 13:06:04 INFO] Iter 88000: loss 3.3468, precision nan, recall 0.0000
[07/12/2020 13:07:13 INFO] Saving checkpoint for iteration #88200
[07/12/2020 13:07:13 INFO] Finished Training Iteration: 88200
[07/12/2020 13:08:20 INFO] Saving checkpoint for iteration #88400
[07/12/2020 13:08:20 INFO] Finished Training Iteration: 88400
[07/12/2020 13:09:27 INFO] Saving checkpoint for iteration #88600
[07/12/2020 13:09:28 INFO] Finished Training Iteration: 88600
[07/12/2020 13:10:36 INFO] Saving checkpoint for iteration #88800
[07/12/2020 13:10:36 INFO] Finished Training Iteration: 88800
[07/12/2020 13:11:43 INFO] Saving checkpoint for iteration #89000
[07/12/2020 13:11:43 INFO] Finished Training Iteration: 89000
[07/12/2020 13:11:44 INFO] Iter 89000: loss 5.7198, precision nan, recall 0.0000
[07/12/2020 13:12:52 INFO] Saving checkpoint for iteration #89200
[07/12/2020 13:12:52 INFO] Finished Training Iteration: 89200
[07/12/2020 13:14:01 INFO] Saving checkpoint for iteration #89400
[07/12/2020 13:14:01 INFO] Finished Training Iteration: 89400
[07/12/2020 13:15:07 INFO] Saving checkpoint for iteration #89600
[07/12/2020 13:15:07 INFO] Finished Training Iteration: 89600
[07/12/2020 13:16:14 INFO] Saving checkpoint for iteration #89800
[07/12/2020 13:16:15 INFO] Finished Training Iteration: 89800
[07/12/2020 13:17:21 INFO] Saving checkpoint for iteration #90000
[07/12/2020 13:17:22 INFO] Finished Training Iteration: 90000
[07/12/2020 13:17:23 INFO] Iter 90000: loss 5.2702, precision 0.0063, recall 0.0077
[07/12/2020 13:18:28 INFO] Saving checkpoint for iteration #90200
[07/12/2020 13:18:28 INFO] Finished Training Iteration: 90200
[07/12/2020 13:19:37 INFO] Saving checkpoint for iteration #90400
[07/12/2020 13:19:38 INFO] Finished Training Iteration: 90400
[07/12/2020 13:20:42 INFO] Saving checkpoint for iteration #90600
[07/12/2020 13:20:43 INFO] Finished Training Iteration: 90600
[07/12/2020 13:21:49 INFO] Saving checkpoint for iteration #90800
[07/12/2020 13:21:49 INFO] Finished Training Iteration: 90800
[07/12/2020 13:22:58 INFO] Saving checkpoint for iteration #91000
[07/12/2020 13:22:58 INFO] Finished Training Iteration: 91000
[07/12/2020 13:23:00 INFO] Iter 91000: loss 2.7186, precision 0.0054, recall 0.0065
[07/12/2020 13:24:08 INFO] Saving checkpoint for iteration #91200
[07/12/2020 13:24:08 INFO] Finished Training Iteration: 91200
[07/12/2020 13:25:17 INFO] Saving checkpoint for iteration #91400
[07/12/2020 13:25:17 INFO] Finished Training Iteration: 91400
[07/12/2020 13:26:25 INFO] Saving checkpoint for iteration #91600
[07/12/2020 13:26:26 INFO] Finished Training Iteration: 91600
[07/12/2020 13:27:31 INFO] Saving checkpoint for iteration #91800
[07/12/2020 13:27:31 INFO] Finished Training Iteration: 91800
[07/12/2020 13:28:39 INFO] Saving checkpoint for iteration #92000
[07/12/2020 13:28:39 INFO] Finished Training Iteration: 92000
[07/12/2020 13:28:55 INFO] Iter 92000: loss 4.9007, precision 0.0055, recall 0.0069
[07/12/2020 13:30:02 INFO] Saving checkpoint for iteration #92200
[07/12/2020 13:30:03 INFO] Finished Training Iteration: 92200
[07/12/2020 13:31:10 INFO] Saving checkpoint for iteration #92400
[07/12/2020 13:31:11 INFO] Finished Training Iteration: 92400
[07/12/2020 13:32:17 INFO] Saving checkpoint for iteration #92600
[07/12/2020 13:32:18 INFO] Finished Training Iteration: 92600
[07/12/2020 13:33:27 INFO] Saving checkpoint for iteration #92800
[07/12/2020 13:33:27 INFO] Finished Training Iteration: 92800
[07/12/2020 13:34:33 INFO] Saving checkpoint for iteration #93000
[07/12/2020 13:34:33 INFO] Finished Training Iteration: 93000
[07/12/2020 13:34:42 INFO] Iter 93000: loss 3.1012, precision 0.0061, recall 0.0077
[07/12/2020 13:35:50 INFO] Saving checkpoint for iteration #93200
[07/12/2020 13:35:50 INFO] Finished Training Iteration: 93200
[07/12/2020 13:36:57 INFO] Saving checkpoint for iteration #93400
[07/12/2020 13:36:57 INFO] Finished Training Iteration: 93400
[07/12/2020 13:38:03 INFO] Saving checkpoint for iteration #93600
[07/12/2020 13:38:03 INFO] Finished Training Iteration: 93600
[07/12/2020 13:39:11 INFO] Saving checkpoint for iteration #93800
[07/12/2020 13:39:12 INFO] Finished Training Iteration: 93800
[07/12/2020 13:40:16 INFO] Saving checkpoint for iteration #94000
[07/12/2020 13:40:16 INFO] Finished Training Iteration: 94000
[07/12/2020 13:40:17 INFO] Iter 94000: loss 3.7425, precision nan, recall 0.0000
[07/12/2020 13:41:25 INFO] Saving checkpoint for iteration #94200
[07/12/2020 13:41:25 INFO] Finished Training Iteration: 94200
[07/12/2020 13:42:34 INFO] Saving checkpoint for iteration #94400
[07/12/2020 13:42:34 INFO] Finished Training Iteration: 94400
[07/12/2020 13:43:40 INFO] Saving checkpoint for iteration #94600
[07/12/2020 13:43:41 INFO] Finished Training Iteration: 94600
[07/12/2020 13:44:48 INFO] Saving checkpoint for iteration #94800
[07/12/2020 13:44:48 INFO] Finished Training Iteration: 94800
[07/12/2020 13:45:56 INFO] Saving checkpoint for iteration #95000
[07/12/2020 13:45:57 INFO] Finished Training Iteration: 95000
[07/12/2020 13:45:57 INFO] Iter 95000: loss 4.0126, precision nan, recall 0.0000
[07/12/2020 13:47:05 INFO] Saving checkpoint for iteration #95200
[07/12/2020 13:47:06 INFO] Finished Training Iteration: 95200
[07/12/2020 13:48:16 INFO] Saving checkpoint for iteration #95400
[07/12/2020 13:48:16 INFO] Finished Training Iteration: 95400
[07/12/2020 13:49:22 INFO] Saving checkpoint for iteration #95600
[07/12/2020 13:49:23 INFO] Finished Training Iteration: 95600
[07/12/2020 13:50:31 INFO] Saving checkpoint for iteration #95800
[07/12/2020 13:50:32 INFO] Finished Training Iteration: 95800
[07/12/2020 13:51:39 INFO] Saving checkpoint for iteration #96000
[07/12/2020 13:51:39 INFO] Finished Training Iteration: 96000
[07/12/2020 13:51:40 INFO] Iter 96000: loss 2.9670, precision nan, recall 0.0000
[07/12/2020 13:52:47 INFO] Saving checkpoint for iteration #96200
[07/12/2020 13:52:47 INFO] Finished Training Iteration: 96200
[07/12/2020 13:53:55 INFO] Saving checkpoint for iteration #96400
[07/12/2020 13:53:55 INFO] Finished Training Iteration: 96400
[07/12/2020 13:55:03 INFO] Saving checkpoint for iteration #96600
[07/12/2020 13:55:03 INFO] Finished Training Iteration: 96600
[07/12/2020 13:56:10 INFO] Saving checkpoint for iteration #96800
[07/12/2020 13:56:11 INFO] Finished Training Iteration: 96800
[07/12/2020 13:57:18 INFO] Saving checkpoint for iteration #97000
[07/12/2020 13:57:19 INFO] Finished Training Iteration: 97000
[07/12/2020 13:57:19 INFO] Iter 97000: loss 5.4526, precision nan, recall 0.0000
[07/12/2020 13:58:26 INFO] Saving checkpoint for iteration #97200
[07/12/2020 13:58:26 INFO] Finished Training Iteration: 97200
[07/12/2020 13:59:34 INFO] Saving checkpoint for iteration #97400
[07/12/2020 13:59:34 INFO] Finished Training Iteration: 97400
[07/12/2020 14:00:42 INFO] Saving checkpoint for iteration #97600
[07/12/2020 14:00:42 INFO] Finished Training Iteration: 97600
[07/12/2020 14:01:52 INFO] Saving checkpoint for iteration #97800
[07/12/2020 14:01:52 INFO] Finished Training Iteration: 97800
[07/12/2020 14:03:00 INFO] Saving checkpoint for iteration #98000
[07/12/2020 14:03:00 INFO] Finished Training Iteration: 98000
[07/12/2020 14:03:15 INFO] Iter 98000: loss 2.9167, precision 0.0066, recall 0.0083
[07/12/2020 14:04:24 INFO] Saving checkpoint for iteration #98200
[07/12/2020 14:04:24 INFO] Finished Training Iteration: 98200
[07/12/2020 14:05:31 INFO] Saving checkpoint for iteration #98400
[07/12/2020 14:05:31 INFO] Finished Training Iteration: 98400
[07/12/2020 14:06:40 INFO] Saving checkpoint for iteration #98600
[07/12/2020 14:06:40 INFO] Finished Training Iteration: 98600
[07/12/2020 14:07:45 INFO] Saving checkpoint for iteration #98800
[07/12/2020 14:07:45 INFO] Finished Training Iteration: 98800
[07/12/2020 14:08:52 INFO] Saving checkpoint for iteration #99000
[07/12/2020 14:08:52 INFO] Finished Training Iteration: 99000
[07/12/2020 14:09:11 INFO] Iter 99000: loss 4.5395, precision 0.0049, recall 0.0059
[07/12/2020 14:10:20 INFO] Saving checkpoint for iteration #99200
[07/12/2020 14:10:21 INFO] Finished Training Iteration: 99200
[07/12/2020 14:11:27 INFO] Saving checkpoint for iteration #99400
[07/12/2020 14:11:27 INFO] Finished Training Iteration: 99400
[07/12/2020 14:12:37 INFO] Saving checkpoint for iteration #99600
[07/12/2020 14:12:37 INFO] Finished Training Iteration: 99600
[07/12/2020 14:13:44 INFO] Saving checkpoint for iteration #99800
[07/12/2020 14:13:44 INFO] Finished Training Iteration: 99800
[07/12/2020 14:14:50 INFO] Saving checkpoint for iteration #100000
[07/12/2020 14:14:50 INFO] Finished Training Iteration: 100000
[07/12/2020 14:14:51 INFO] Iter 100000: loss 5.0755, precision nan, recall 0.0000
[07/12/2020 14:16:02 INFO] Saving checkpoint for iteration #100200
[07/12/2020 14:16:02 INFO] Finished Training Iteration: 100200
[07/12/2020 14:17:09 INFO] Saving checkpoint for iteration #100400
[07/12/2020 14:17:10 INFO] Finished Training Iteration: 100400
[07/12/2020 14:18:18 INFO] Saving checkpoint for iteration #100600
[07/12/2020 14:18:18 INFO] Finished Training Iteration: 100600
[07/12/2020 14:19:25 INFO] Saving checkpoint for iteration #100800
[07/12/2020 14:19:25 INFO] Finished Training Iteration: 100800
[07/12/2020 14:20:32 INFO] Saving checkpoint for iteration #101000
[07/12/2020 14:20:32 INFO] Finished Training Iteration: 101000
[07/12/2020 14:20:33 INFO] Iter 101000: loss 6.7743, precision nan, recall 0.0000
[07/12/2020 14:21:40 INFO] Saving checkpoint for iteration #101200
[07/12/2020 14:21:40 INFO] Finished Training Iteration: 101200
[07/12/2020 14:22:47 INFO] Saving checkpoint for iteration #101400
[07/12/2020 14:22:47 INFO] Finished Training Iteration: 101400
[07/12/2020 14:23:52 INFO] Saving checkpoint for iteration #101600
[07/12/2020 14:23:53 INFO] Finished Training Iteration: 101600
[07/12/2020 14:25:01 INFO] Saving checkpoint for iteration #101800
[07/12/2020 14:25:01 INFO] Finished Training Iteration: 101800
[07/12/2020 14:26:10 INFO] Saving checkpoint for iteration #102000
[07/12/2020 14:26:10 INFO] Finished Training Iteration: 102000
[07/12/2020 14:26:16 INFO] Iter 102000: loss 6.3817, precision 0.0065, recall 0.0077
[07/12/2020 14:27:23 INFO] Saving checkpoint for iteration #102200
[07/12/2020 14:27:24 INFO] Finished Training Iteration: 102200
[07/12/2020 14:28:31 INFO] Saving checkpoint for iteration #102400
[07/12/2020 14:28:31 INFO] Finished Training Iteration: 102400
[07/12/2020 14:29:38 INFO] Saving checkpoint for iteration #102600
[07/12/2020 14:29:38 INFO] Finished Training Iteration: 102600
[07/12/2020 14:30:46 INFO] Saving checkpoint for iteration #102800
[07/12/2020 14:30:46 INFO] Finished Training Iteration: 102800
[07/12/2020 14:31:53 INFO] Saving checkpoint for iteration #103000
[07/12/2020 14:31:53 INFO] Finished Training Iteration: 103000
[07/12/2020 14:31:54 INFO] Iter 103000: loss 5.1390, precision nan, recall 0.0000
[07/12/2020 14:33:00 INFO] Saving checkpoint for iteration #103200
[07/12/2020 14:33:00 INFO] Finished Training Iteration: 103200
[07/12/2020 14:34:07 INFO] Saving checkpoint for iteration #103400
[07/12/2020 14:34:07 INFO] Finished Training Iteration: 103400
[07/12/2020 14:35:15 INFO] Saving checkpoint for iteration #103600
[07/12/2020 14:35:15 INFO] Finished Training Iteration: 103600
[07/12/2020 14:36:23 INFO] Saving checkpoint for iteration #103800
[07/12/2020 14:36:23 INFO] Finished Training Iteration: 103800
[07/12/2020 14:37:30 INFO] Saving checkpoint for iteration #104000
[07/12/2020 14:37:31 INFO] Finished Training Iteration: 104000
[07/12/2020 14:37:31 INFO] Iter 104000: loss 4.0466, precision nan, recall 0.0000
[07/12/2020 14:38:40 INFO] Saving checkpoint for iteration #104200
[07/12/2020 14:38:41 INFO] Finished Training Iteration: 104200
[07/12/2020 14:39:46 INFO] Saving checkpoint for iteration #104400
[07/12/2020 14:39:47 INFO] Finished Training Iteration: 104400
[07/12/2020 14:40:56 INFO] Saving checkpoint for iteration #104600
[07/12/2020 14:40:56 INFO] Finished Training Iteration: 104600
[07/12/2020 14:42:05 INFO] Saving checkpoint for iteration #104800
[07/12/2020 14:42:05 INFO] Finished Training Iteration: 104800
[07/12/2020 14:43:13 INFO] Saving checkpoint for iteration #105000
[07/12/2020 14:43:13 INFO] Finished Training Iteration: 105000
[07/12/2020 14:43:14 INFO] Iter 105000: loss 2.7046, precision nan, recall 0.0000
[07/12/2020 14:44:20 INFO] Saving checkpoint for iteration #105200
[07/12/2020 14:44:20 INFO] Finished Training Iteration: 105200
[07/12/2020 14:45:28 INFO] Saving checkpoint for iteration #105400
[07/12/2020 14:45:28 INFO] Finished Training Iteration: 105400
[07/12/2020 14:46:34 INFO] Saving checkpoint for iteration #105600
[07/12/2020 14:46:34 INFO] Finished Training Iteration: 105600
[07/12/2020 14:47:42 INFO] Saving checkpoint for iteration #105800
[07/12/2020 14:47:42 INFO] Finished Training Iteration: 105800
[07/12/2020 14:48:51 INFO] Saving checkpoint for iteration #106000
[07/12/2020 14:48:52 INFO] Finished Training Iteration: 106000
[07/12/2020 14:48:53 INFO] Iter 106000: loss 5.8780, precision nan, recall 0.0000
[07/12/2020 14:50:01 INFO] Saving checkpoint for iteration #106200
[07/12/2020 14:50:02 INFO] Finished Training Iteration: 106200
[07/12/2020 14:51:08 INFO] Saving checkpoint for iteration #106400
[07/12/2020 14:51:08 INFO] Finished Training Iteration: 106400
[07/12/2020 14:52:16 INFO] Saving checkpoint for iteration #106600
[07/12/2020 14:52:16 INFO] Finished Training Iteration: 106600
[07/12/2020 14:53:23 INFO] Saving checkpoint for iteration #106800
[07/12/2020 14:53:24 INFO] Finished Training Iteration: 106800
[07/12/2020 14:54:29 INFO] Saving checkpoint for iteration #107000
[07/12/2020 14:54:29 INFO] Finished Training Iteration: 107000
[07/12/2020 14:54:30 INFO] Iter 107000: loss 3.3441, precision nan, recall 0.0000
[07/12/2020 14:55:39 INFO] Saving checkpoint for iteration #107200
[07/12/2020 14:55:39 INFO] Finished Training Iteration: 107200
[07/12/2020 14:56:46 INFO] Saving checkpoint for iteration #107400
[07/12/2020 14:56:46 INFO] Finished Training Iteration: 107400
[07/12/2020 14:57:55 INFO] Saving checkpoint for iteration #107600
[07/12/2020 14:57:55 INFO] Finished Training Iteration: 107600
[07/12/2020 14:59:03 INFO] Saving checkpoint for iteration #107800
[07/12/2020 14:59:04 INFO] Finished Training Iteration: 107800
[07/12/2020 15:00:14 INFO] Saving checkpoint for iteration #108000
[07/12/2020 15:00:15 INFO] Finished Training Iteration: 108000
[07/12/2020 15:00:15 INFO] Iter 108000: loss 5.1772, precision nan, recall 0.0000
[07/12/2020 15:01:21 INFO] Saving checkpoint for iteration #108200
[07/12/2020 15:01:21 INFO] Finished Training Iteration: 108200
[07/12/2020 15:02:27 INFO] Saving checkpoint for iteration #108400
[07/12/2020 15:02:28 INFO] Finished Training Iteration: 108400
[07/12/2020 15:03:34 INFO] Saving checkpoint for iteration #108600
[07/12/2020 15:03:34 INFO] Finished Training Iteration: 108600
[07/12/2020 15:04:43 INFO] Saving checkpoint for iteration #108800
[07/12/2020 15:04:44 INFO] Finished Training Iteration: 108800
[07/12/2020 15:05:49 INFO] Saving checkpoint for iteration #109000
[07/12/2020 15:05:49 INFO] Finished Training Iteration: 109000
[07/12/2020 15:05:50 INFO] Iter 109000: loss 5.2395, precision nan, recall 0.0000
[07/12/2020 15:06:59 INFO] Saving checkpoint for iteration #109200
[07/12/2020 15:06:59 INFO] Finished Training Iteration: 109200
[07/12/2020 15:08:05 INFO] Saving checkpoint for iteration #109400
[07/12/2020 15:08:06 INFO] Finished Training Iteration: 109400
[07/12/2020 15:09:10 INFO] Saving checkpoint for iteration #109600
[07/12/2020 15:09:10 INFO] Finished Training Iteration: 109600
[07/12/2020 15:10:17 INFO] Saving checkpoint for iteration #109800
[07/12/2020 15:10:18 INFO] Finished Training Iteration: 109800
[07/12/2020 15:11:25 INFO] Saving checkpoint for iteration #110000
[07/12/2020 15:11:26 INFO] Finished Training Iteration: 110000
[07/12/2020 15:11:59 INFO] Iter 110000: loss 4.1912, precision 0.0054, recall 0.0066
[07/12/2020 15:13:03 INFO] Saving checkpoint for iteration #110200
[07/12/2020 15:13:03 INFO] Finished Training Iteration: 110200
[07/12/2020 15:14:11 INFO] Saving checkpoint for iteration #110400
[07/12/2020 15:14:12 INFO] Finished Training Iteration: 110400
[07/12/2020 15:15:18 INFO] Saving checkpoint for iteration #110600
[07/12/2020 15:15:18 INFO] Finished Training Iteration: 110600
[07/12/2020 15:16:22 INFO] Saving checkpoint for iteration #110800
[07/12/2020 15:16:22 INFO] Finished Training Iteration: 110800
[07/12/2020 15:17:31 INFO] Saving checkpoint for iteration #111000
[07/12/2020 15:17:32 INFO] Finished Training Iteration: 111000
[07/12/2020 15:17:53 INFO] Iter 111000: loss 3.8388, precision 0.0064, recall 0.0084
[07/12/2020 15:19:00 INFO] Saving checkpoint for iteration #111200
[07/12/2020 15:19:01 INFO] Finished Training Iteration: 111200
[07/12/2020 15:20:08 INFO] Saving checkpoint for iteration #111400
[07/12/2020 15:20:08 INFO] Finished Training Iteration: 111400
[07/12/2020 15:21:16 INFO] Saving checkpoint for iteration #111600
[07/12/2020 15:21:16 INFO] Finished Training Iteration: 111600
[07/12/2020 15:22:21 INFO] Saving checkpoint for iteration #111800
[07/12/2020 15:22:22 INFO] Finished Training Iteration: 111800
[07/12/2020 15:23:29 INFO] Saving checkpoint for iteration #112000
[07/12/2020 15:23:29 INFO] Finished Training Iteration: 112000
[07/12/2020 15:23:41 INFO] Iter 112000: loss 6.6564, precision 0.0060, recall 0.0071
[07/12/2020 15:24:48 INFO] Saving checkpoint for iteration #112200
[07/12/2020 15:24:49 INFO] Finished Training Iteration: 112200
[07/12/2020 15:25:56 INFO] Saving checkpoint for iteration #112400
[07/12/2020 15:25:56 INFO] Finished Training Iteration: 112400
[07/12/2020 15:27:06 INFO] Saving checkpoint for iteration #112600
[07/12/2020 15:27:07 INFO] Finished Training Iteration: 112600
[07/12/2020 15:28:14 INFO] Saving checkpoint for iteration #112800
[07/12/2020 15:28:14 INFO] Finished Training Iteration: 112800
[07/12/2020 15:29:20 INFO] Saving checkpoint for iteration #113000
[07/12/2020 15:29:20 INFO] Finished Training Iteration: 113000
[07/12/2020 15:29:21 INFO] Iter 113000: loss 4.7329, precision nan, recall 0.0000
[07/12/2020 15:30:30 INFO] Saving checkpoint for iteration #113200
[07/12/2020 15:30:30 INFO] Finished Training Iteration: 113200
[07/12/2020 15:31:36 INFO] Saving checkpoint for iteration #113400
[07/12/2020 15:31:37 INFO] Finished Training Iteration: 113400
[07/12/2020 15:32:45 INFO] Saving checkpoint for iteration #113600
[07/12/2020 15:32:45 INFO] Finished Training Iteration: 113600
[07/12/2020 15:33:51 INFO] Saving checkpoint for iteration #113800
[07/12/2020 15:33:51 INFO] Finished Training Iteration: 113800
[07/12/2020 15:34:58 INFO] Saving checkpoint for iteration #114000
[07/12/2020 15:34:59 INFO] Finished Training Iteration: 114000
[07/12/2020 15:34:59 INFO] Iter 114000: loss 3.7562, precision nan, recall 0.0000
[07/12/2020 15:36:05 INFO] Saving checkpoint for iteration #114200
[07/12/2020 15:36:05 INFO] Finished Training Iteration: 114200
[07/12/2020 15:37:16 INFO] Saving checkpoint for iteration #114400
[07/12/2020 15:37:16 INFO] Finished Training Iteration: 114400
[07/12/2020 15:38:23 INFO] Saving checkpoint for iteration #114600
[07/12/2020 15:38:24 INFO] Finished Training Iteration: 114600
[07/12/2020 15:39:31 INFO] Saving checkpoint for iteration #114800
[07/12/2020 15:39:32 INFO] Finished Training Iteration: 114800
[07/12/2020 15:40:41 INFO] Saving checkpoint for iteration #115000
[07/12/2020 15:40:42 INFO] Finished Training Iteration: 115000
[07/12/2020 15:40:42 INFO] Iter 115000: loss 2.9486, precision nan, recall 0.0000
[07/12/2020 15:41:50 INFO] Saving checkpoint for iteration #115200
[07/12/2020 15:41:50 INFO] Finished Training Iteration: 115200
[07/12/2020 15:43:00 INFO] Saving checkpoint for iteration #115400
[07/12/2020 15:43:00 INFO] Finished Training Iteration: 115400
[07/12/2020 15:44:08 INFO] Saving checkpoint for iteration #115600
[07/12/2020 15:44:08 INFO] Finished Training Iteration: 115600
[07/12/2020 15:45:17 INFO] Saving checkpoint for iteration #115800
[07/12/2020 15:45:17 INFO] Finished Training Iteration: 115800
[07/12/2020 15:46:23 INFO] Saving checkpoint for iteration #116000
[07/12/2020 15:46:24 INFO] Finished Training Iteration: 116000
[07/12/2020 15:46:24 INFO] Iter 116000: loss 4.0273, precision nan, recall 0.0000
[07/12/2020 15:47:30 INFO] Saving checkpoint for iteration #116200
[07/12/2020 15:47:30 INFO] Finished Training Iteration: 116200
[07/12/2020 15:48:39 INFO] Saving checkpoint for iteration #116400
[07/12/2020 15:48:39 INFO] Finished Training Iteration: 116400
[07/12/2020 15:49:47 INFO] Saving checkpoint for iteration #116600
[07/12/2020 15:49:48 INFO] Finished Training Iteration: 116600
[07/12/2020 15:50:53 INFO] Saving checkpoint for iteration #116800
[07/12/2020 15:50:53 INFO] Finished Training Iteration: 116800
[07/12/2020 15:52:02 INFO] Saving checkpoint for iteration #117000
[07/12/2020 15:52:02 INFO] Finished Training Iteration: 117000
[07/12/2020 15:53:02 INFO] Iter 117000: loss 3.6054, precision 0.0054, recall 0.0068
[07/12/2020 15:54:06 INFO] Saving checkpoint for iteration #117200
[07/12/2020 15:54:07 INFO] Finished Training Iteration: 117200
[07/12/2020 15:55:15 INFO] Saving checkpoint for iteration #117400
[07/12/2020 15:55:15 INFO] Finished Training Iteration: 117400
[07/12/2020 15:56:24 INFO] Saving checkpoint for iteration #117600
[07/12/2020 15:56:24 INFO] Finished Training Iteration: 117600
[07/12/2020 15:57:31 INFO] Saving checkpoint for iteration #117800
[07/12/2020 15:57:31 INFO] Finished Training Iteration: 117800
[07/12/2020 15:58:38 INFO] Saving checkpoint for iteration #118000
[07/12/2020 15:58:38 INFO] Finished Training Iteration: 118000
[07/12/2020 15:58:39 INFO] Iter 118000: loss 9.4408, precision nan, recall 0.0000
[07/12/2020 15:59:45 INFO] Saving checkpoint for iteration #118200
[07/12/2020 15:59:46 INFO] Finished Training Iteration: 118200
[07/12/2020 16:00:53 INFO] Saving checkpoint for iteration #118400
[07/12/2020 16:00:54 INFO] Finished Training Iteration: 118400
[07/12/2020 16:02:00 INFO] Saving checkpoint for iteration #118600
[07/12/2020 16:02:01 INFO] Finished Training Iteration: 118600
[07/12/2020 16:03:08 INFO] Saving checkpoint for iteration #118800
[07/12/2020 16:03:08 INFO] Finished Training Iteration: 118800
[07/12/2020 16:04:17 INFO] Saving checkpoint for iteration #119000
[07/12/2020 16:04:17 INFO] Finished Training Iteration: 119000
[07/12/2020 16:04:18 INFO] Iter 119000: loss 5.8539, precision nan, recall 0.0000
[07/12/2020 16:05:25 INFO] Saving checkpoint for iteration #119200
[07/12/2020 16:05:26 INFO] Finished Training Iteration: 119200
[07/12/2020 16:06:33 INFO] Saving checkpoint for iteration #119400
[07/12/2020 16:06:34 INFO] Finished Training Iteration: 119400
[07/12/2020 16:07:41 INFO] Saving checkpoint for iteration #119600
[07/12/2020 16:07:42 INFO] Finished Training Iteration: 119600
[07/12/2020 16:08:51 INFO] Saving checkpoint for iteration #119800
[07/12/2020 16:08:52 INFO] Finished Training Iteration: 119800
[07/12/2020 16:10:00 INFO] Saving checkpoint for iteration #120000
[07/12/2020 16:10:01 INFO] Finished Training Iteration: 120000
[07/12/2020 16:10:01 INFO] Iter 120000: loss 3.0059, precision nan, recall 0.0000
[07/12/2020 16:11:11 INFO] Saving checkpoint for iteration #120200
[07/12/2020 16:11:11 INFO] Finished Training Iteration: 120200
[07/12/2020 16:12:19 INFO] Saving checkpoint for iteration #120400
[07/12/2020 16:12:20 INFO] Finished Training Iteration: 120400
[07/12/2020 16:13:27 INFO] Saving checkpoint for iteration #120600
[07/12/2020 16:13:28 INFO] Finished Training Iteration: 120600
[07/12/2020 16:14:34 INFO] Saving checkpoint for iteration #120800
[07/12/2020 16:14:35 INFO] Finished Training Iteration: 120800
[07/12/2020 16:15:41 INFO] Saving checkpoint for iteration #121000
[07/12/2020 16:15:42 INFO] Finished Training Iteration: 121000
[07/12/2020 16:15:43 INFO] Iter 121000: loss 3.4052, precision nan, recall 0.0000
[07/12/2020 16:16:50 INFO] Saving checkpoint for iteration #121200
[07/12/2020 16:16:50 INFO] Finished Training Iteration: 121200
[07/12/2020 16:17:54 INFO] Saving checkpoint for iteration #121400
[07/12/2020 16:17:55 INFO] Finished Training Iteration: 121400
[07/12/2020 16:19:03 INFO] Saving checkpoint for iteration #121600
[07/12/2020 16:19:03 INFO] Finished Training Iteration: 121600
[07/12/2020 16:20:08 INFO] Saving checkpoint for iteration #121800
[07/12/2020 16:20:09 INFO] Finished Training Iteration: 121800
[07/12/2020 16:21:14 INFO] Saving checkpoint for iteration #122000
[07/12/2020 16:21:14 INFO] Finished Training Iteration: 122000
[07/12/2020 16:21:15 INFO] Iter 122000: loss 2.8209, precision nan, recall 0.0000
[07/12/2020 16:22:23 INFO] Saving checkpoint for iteration #122200
[07/12/2020 16:22:24 INFO] Finished Training Iteration: 122200
[07/12/2020 16:23:04 INFO] Got Keyboard Interrupt, saving model and closing.
[07/12/2020 16:23:04 INFO] Saving checkpoint for iteration #122325
[07/12/2020 16:23:58 INFO] Running command TRAIN
2020-07-12 16:23:58.141483: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-12 16:23:58.661439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:23:58.662372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:23:58.663772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:23:58.669564: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:23:58.681261: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:23:58.682933: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:23:58.689106: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:23:58.692107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:23:58.706605: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:23:58.706768: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:23:58.707387: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:23:58.707881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
[07/12/2020 16:23:58 INFO] Number of GPUs detected: 1
[07/12/2020 16:24:03 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/utils/pipeline.py:99: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[07/12/2020 16:24:04 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:139: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
2020-07-12 16:24:05.521764: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-12 16:24:05.683317: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3199980000 Hz
2020-07-12 16:24:05.683725: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f5c68000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-12 16:24:05.683739: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-12 16:24:05.772945: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:05.773314: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x559bf4692160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-12 16:24:05.773326: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-07-12 16:24:05.773581: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:05.773860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:24:05.773884: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:24:05.773893: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:24:05.773900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:24:05.773922: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:24:05.773931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:24:05.773939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:24:05.773947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:24:05.773976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:05.774273: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:05.774533: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 16:24:05.774567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:24:05.775410: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 16:24:05.775420: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 16:24:05.775424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 16:24:05.775952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:05.776254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:05.776537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
/disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:72: UserWarning: Seed 1352910221 from outer graph might be getting used by function Dataset_map_lambda, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  fn, num_parallel_calls=config['num_parallel_calls'])
2020-07-12 16:24:14.961075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:14.961447: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:24:14.961510: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:24:14.961520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:24:14.961528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:24:14.961535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:24:14.961542: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:24:14.961549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:24:14.961556: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:24:14.961597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:14.961875: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:14.962182: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 16:24:15.010856: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 16:24:15.010895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 16:24:15.010908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 16:24:15.011154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:15.011894: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:15.012528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
training
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
validation
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
test
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
[07/12/2020 16:24:16 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[07/12/2020 16:24:16 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[07/12/2020 16:24:16 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/train_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/train_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/train_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

DEPTH AND ORIGINAL IMAGE:(1, 1, None, None), (1, 1, None, None), (1, 1, None, None)

(1, 1, None, None)
After expand_dims:(1, 1, None, None),(1, 1, None, None)

mask shape:(1, 1, None, None), (1, 1, None, None)

[07/12/2020 16:24:18 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[07/12/2020 16:24:18 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[07/12/2020 16:24:18 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[07/12/2020 16:24:18 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[07/12/2020 16:24:19 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

masks shape:(1, None, None), (1, 1, None, None), (1, None, None)


keypoint map shape: (1, None, None)


 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/eval_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

Run Time Image Size: (1, 1, None, None)

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/pred_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>}

Run Time Image Size: (1, 1, None, None)
2020-07-12 16:24:20.989822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:20.990165: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:24:20.990227: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:24:20.990239: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:24:20.990247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:24:20.990255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:24:20.990264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:24:20.990271: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:24:20.990281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:24:20.990346: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:20.990646: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:20.990914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 16:24:20.990945: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 16:24:20.990949: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 16:24:20.990967: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 16:24:20.991038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:20.991381: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:24:20.991695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[07/12/2020 16:24:55 INFO] Start training
2020-07-12 16:25:04.517881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:25:15.979622: I tensorflow/core/kernels/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x559bf4e073e0
2020-07-12 16:25:15.979818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:25:16.672923: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:25:17.276727: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:25:18.334903: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.22G (3460258816 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
[07/12/2020 16:25:19 INFO] Finished Training Iteration:    0
[07/12/2020 16:27:53 INFO] Iter    0: loss nan, precision 0.0060, recall 0.0076
[07/12/2020 16:28:58 INFO] Finished Training Iteration:  200
[07/12/2020 16:29:21 INFO] Got Keyboard Interrupt, saving model and closing.
[07/12/2020 16:29:25 INFO] Saving checkpoint for iteration #269
[07/12/2020 16:31:59 INFO] Running command TRAIN
2020-07-12 16:31:59.008020: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-07-12 16:31:59.476465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:31:59.476772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:31:59.479651: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:31:59.481913: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:31:59.483281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:31:59.484152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:31:59.486084: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:31:59.486831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:31:59.490225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:31:59.490307: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:31:59.490638: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:31:59.490872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
[07/12/2020 16:31:59 INFO] Number of GPUs detected: 1
[07/12/2020 16:32:02 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/utils/pipeline.py:99: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[07/12/2020 16:32:03 WARNING] From /disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:139: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
2020-07-12 16:32:04.255825: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-07-12 16:32:04.279492: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3199980000 Hz
2020-07-12 16:32:04.280326: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6dd0000b60 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-07-12 16:32:04.280365: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-07-12 16:32:04.348282: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:04.348670: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561a2bd131c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-07-12 16:32:04.348684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-07-12 16:32:04.348828: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:04.349119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:32:04.349142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:32:04.349152: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:32:04.349183: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:32:04.349192: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:32:04.349213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:32:04.349237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:32:04.349245: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:32:04.349292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:04.349586: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:04.349851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 16:32:04.349871: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:32:04.350430: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 16:32:04.350439: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 16:32:04.350444: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 16:32:04.350543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:04.350842: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:04.351155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
/disk_ssd/SuperPoint/superpoint/datasets/coco_megapoint.py:72: UserWarning: Seed 213809601 from outer graph might be getting used by function Dataset_map_lambda, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  fn, num_parallel_calls=config['num_parallel_calls'])
2020-07-12 16:32:13.523893: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:13.524263: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:32:13.524322: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:32:13.524349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:32:13.524357: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:32:13.524364: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:32:13.524371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:32:13.524378: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:32:13.524399: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:32:13.524453: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:13.524801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:13.525110: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 16:32:13.550101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 16:32:13.550115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 16:32:13.550119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 16:32:13.550194: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:13.550499: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:13.550774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
training
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
validation
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
test
image (None, None, 1)
depth (None, None, 1)
semantic (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'depth': TensorShape([None, None, 1]), 'semantic': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
[07/12/2020 16:32:14 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:348: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[07/12/2020 16:32:14 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:349: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[07/12/2020 16:32:14 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/data/ops/iterator_ops.py:351: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/train_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/train_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/train_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/train_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/train_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/train_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/train_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/train_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/train_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

DEPTH AND ORIGINAL IMAGE:(1, 1, None, None), (1, 1, None, None), (1, 1, None, None)

(1, 1, None, None)
After expand_dims:(1, 1, None, None),(1, 1, None, None)

mask shape:(1, 1, None, None), (1, 1, None, None)

[07/12/2020 16:32:17 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[07/12/2020 16:32:17 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[07/12/2020 16:32:17 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[07/12/2020 16:32:17 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[07/12/2020 16:32:17 WARNING] From /disk_ssd/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.

 OG SET: (1, 1, None, None),(1, 1, None, None),(1, 1, None, None)

masks shape:(1, None, None), (1, 1, None, None), (1, None, None)


keypoint map shape: (1, None, None)


 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_1:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_2:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_3:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_4:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_5:0' shape=(1, None, None) dtype=int32>, 'warped': {'image': <tf.Tensor 'megapoint/eval_data_sharding/stack_6:0' shape=(1, None, None, 1) dtype=float32>, 'depth': <tf.Tensor 'megapoint/eval_data_sharding/stack_7:0' shape=(1, None, None, 1) dtype=float32>, 'semantic': <tf.Tensor 'megapoint/eval_data_sharding/stack_8:0' shape=(1, None, None, 1) dtype=float32>, 'name': <tf.Tensor 'megapoint/eval_data_sharding/stack_9:0' shape=(1,) dtype=string>, 'keypoints': <tf.Tensor 'megapoint/eval_data_sharding/stack_10:0' shape=(1, None, 2) dtype=float32>, 'valid_mask': <tf.Tensor 'megapoint/eval_data_sharding/stack_11:0' shape=(1, None, None) dtype=int32>, 'homography': <tf.Tensor 'megapoint/eval_data_sharding/stack_12:0' shape=(1, 8) dtype=float32>, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_13:0' shape=(1, None, None) dtype=int32>}, 'keypoint_map': <tf.Tensor 'megapoint/eval_data_sharding/stack_14:0' shape=(1, None, None) dtype=int32>}

Run Time Image Size: (1, 1, None, None)

 In Evalution:


 Data is {'image': <tf.Tensor 'megapoint/pred_data_sharding/stack:0' shape=(1, None, None, 1) dtype=float32>}

Run Time Image Size: (1, 1, None, None)
2020-07-12 16:32:19.647007: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:19.647327: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-07-12 16:32:19.647371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-07-12 16:32:19.647381: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:32:19.647389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-07-12 16:32:19.647397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-07-12 16:32:19.647405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:32:19.647412: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-07-12 16:32:19.647420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:32:19.647469: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:19.647786: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:19.648050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-07-12 16:32:19.648067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-07-12 16:32:19.648071: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-07-12 16:32:19.648074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-07-12 16:32:19.648135: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:19.648468: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-07-12 16:32:19.648738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7410 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[07/12/2020 16:32:53 INFO] Start training
2020-07-12 16:33:01.688416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:33:02.238840: I tensorflow/core/kernels/cuda_solvers.cc:180] Creating CudaSolver handles for stream 0x561a2f9a2760
2020-07-12 16:33:02.238945: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-07-12 16:33:02.831097: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-07-12 16:33:03.096389: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-07-12 16:33:03.922575: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.71G (3980352512 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-12 16:33:04.515160: W tensorflow/core/common_runtime/bfc_allocator.cc:311] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-07-12 16:33:04.585439: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.37G (3621358080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-12 16:33:04.585563: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.06GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-12 16:33:04.990151: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.37G (3621358080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-12 16:33:04.990173: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-07-12 16:33:04.990641: I tensorflow/stream_executor/cuda/cuda_driver.cc:763] failed to allocate 3.37G (3621358080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-07-12 16:33:04.990653: W tensorflow/core/common_runtime/bfc_allocator.cc:245] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
[07/12/2020 16:33:05 INFO] Finished Training Iteration:    0
[07/12/2020 16:36:02 INFO] Iter    0: loss 10.3006, precision 0.0061, recall 0.0076
[07/12/2020 16:37:09 INFO] Finished Training Iteration:  200
[07/12/2020 16:38:19 INFO] Finished Training Iteration:  400
[07/12/2020 16:39:25 INFO] Finished Training Iteration:  600
[07/12/2020 16:40:32 INFO] Finished Training Iteration:  800
[07/12/2020 16:41:44 INFO] Saving checkpoint for iteration #1000
[07/12/2020 16:41:48 INFO] Finished Training Iteration: 1000
[07/12/2020 16:42:58 INFO] Finished Training Iteration: 1200
[07/12/2020 16:44:07 INFO] Finished Training Iteration: 1400
[07/12/2020 16:45:15 INFO] Finished Training Iteration: 1600
[07/12/2020 16:46:23 INFO] Finished Training Iteration: 1800
[07/12/2020 16:47:31 INFO] Saving checkpoint for iteration #2000
[07/12/2020 16:47:31 WARNING] From /home/hashswan/.conda/envs/superpoint/lib/python3.7/site-packages/tensorflow/python/training/saver.py:971: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.
Instructions for updating:
Use standard file APIs to delete files with this prefix.
[07/12/2020 16:47:31 INFO] Finished Training Iteration: 2000
[07/12/2020 16:48:40 INFO] Finished Training Iteration: 2200
[07/12/2020 16:49:49 INFO] Finished Training Iteration: 2400
[07/12/2020 16:52:33 INFO] Iter 2500: loss 8.7637, precision 0.0053, recall 0.0066
[07/12/2020 16:53:07 INFO] Finished Training Iteration: 2600
[07/12/2020 16:54:14 INFO] Finished Training Iteration: 2800
[07/12/2020 16:55:21 INFO] Saving checkpoint for iteration #3000
[07/12/2020 16:55:21 INFO] Finished Training Iteration: 3000
[07/12/2020 16:56:30 INFO] Finished Training Iteration: 3200
[07/12/2020 16:57:38 INFO] Finished Training Iteration: 3400
[07/12/2020 16:58:45 INFO] Finished Training Iteration: 3600
[07/12/2020 16:59:55 INFO] Finished Training Iteration: 3800
[07/12/2020 17:01:05 INFO] Saving checkpoint for iteration #4000
[07/12/2020 17:01:05 INFO] Finished Training Iteration: 4000
[07/12/2020 17:02:16 INFO] Finished Training Iteration: 4200
[07/12/2020 17:03:23 INFO] Finished Training Iteration: 4400
[07/12/2020 17:04:33 INFO] Finished Training Iteration: 4600
[07/12/2020 17:05:40 INFO] Finished Training Iteration: 4800
[07/12/2020 17:06:49 INFO] Saving checkpoint for iteration #5000
[07/12/2020 17:06:50 INFO] Finished Training Iteration: 5000
[07/12/2020 17:09:11 INFO] Iter 5000: loss 8.0510, precision 0.0053, recall 0.0066
[07/12/2020 17:10:17 INFO] Finished Training Iteration: 5200
[07/12/2020 17:11:27 INFO] Finished Training Iteration: 5400
[07/12/2020 17:12:36 INFO] Finished Training Iteration: 5600
[07/12/2020 17:13:43 INFO] Finished Training Iteration: 5800
[07/12/2020 17:14:54 INFO] Saving checkpoint for iteration #6000
[07/12/2020 17:14:54 INFO] Finished Training Iteration: 6000
[07/12/2020 17:16:02 INFO] Finished Training Iteration: 6200
[07/12/2020 17:17:10 INFO] Finished Training Iteration: 6400
[07/12/2020 17:18:19 INFO] Finished Training Iteration: 6600
[07/12/2020 17:19:27 INFO] Finished Training Iteration: 6800
[07/12/2020 17:20:34 INFO] Saving checkpoint for iteration #7000
[07/12/2020 17:20:34 INFO] Finished Training Iteration: 7000
[07/12/2020 17:21:42 INFO] Finished Training Iteration: 7200
[07/12/2020 17:22:48 INFO] Finished Training Iteration: 7400
[07/12/2020 17:25:25 INFO] Iter 7500: loss 6.6994, precision 0.0053, recall 0.0066
[07/12/2020 17:25:56 INFO] Finished Training Iteration: 7600
[07/12/2020 17:27:03 INFO] Finished Training Iteration: 7800
[07/12/2020 17:28:11 INFO] Saving checkpoint for iteration #8000
[07/12/2020 17:28:11 INFO] Finished Training Iteration: 8000
[07/12/2020 17:29:21 INFO] Finished Training Iteration: 8200
[07/12/2020 17:30:30 INFO] Finished Training Iteration: 8400
[07/12/2020 17:31:40 INFO] Finished Training Iteration: 8600
[07/12/2020 17:32:49 INFO] Finished Training Iteration: 8800
[07/12/2020 17:33:55 INFO] Saving checkpoint for iteration #9000
[07/12/2020 17:33:55 INFO] Finished Training Iteration: 9000
[07/12/2020 17:35:04 INFO] Finished Training Iteration: 9200
[07/12/2020 17:36:12 INFO] Finished Training Iteration: 9400
[07/12/2020 17:37:19 INFO] Finished Training Iteration: 9600
[07/12/2020 17:38:25 INFO] Finished Training Iteration: 9800
[07/12/2020 17:39:34 INFO] Saving checkpoint for iteration #10000
[07/12/2020 17:39:35 INFO] Finished Training Iteration: 10000
[07/12/2020 17:41:46 INFO] Iter 10000: loss 7.3742, precision 0.0053, recall 0.0066
[07/12/2020 17:42:54 INFO] Finished Training Iteration: 10200
[07/12/2020 17:44:00 INFO] Finished Training Iteration: 10400
[07/12/2020 17:45:08 INFO] Finished Training Iteration: 10600
[07/12/2020 17:46:14 INFO] Finished Training Iteration: 10800
[07/12/2020 17:47:22 INFO] Saving checkpoint for iteration #11000
[07/12/2020 17:47:22 INFO] Finished Training Iteration: 11000
[07/12/2020 17:48:28 INFO] Finished Training Iteration: 11200
[07/12/2020 17:49:37 INFO] Finished Training Iteration: 11400
[07/12/2020 17:50:47 INFO] Finished Training Iteration: 11600
[07/12/2020 17:51:55 INFO] Finished Training Iteration: 11800
[07/12/2020 17:53:03 INFO] Saving checkpoint for iteration #12000
[07/12/2020 17:53:04 INFO] Finished Training Iteration: 12000
[07/12/2020 17:54:14 INFO] Finished Training Iteration: 12200
[07/12/2020 17:55:22 INFO] Finished Training Iteration: 12400
[07/12/2020 17:58:17 INFO] Iter 12500: loss 6.7893, precision 0.0053, recall 0.0066
[07/12/2020 17:58:52 INFO] Finished Training Iteration: 12600
[07/12/2020 18:00:01 INFO] Finished Training Iteration: 12800
[07/12/2020 18:01:11 INFO] Saving checkpoint for iteration #13000
[07/12/2020 18:01:12 INFO] Finished Training Iteration: 13000
[07/12/2020 18:02:19 INFO] Finished Training Iteration: 13200
[07/12/2020 18:03:27 INFO] Finished Training Iteration: 13400
[07/12/2020 18:04:36 INFO] Finished Training Iteration: 13600
[07/12/2020 18:05:45 INFO] Finished Training Iteration: 13800
[07/12/2020 18:06:53 INFO] Saving checkpoint for iteration #14000
[07/12/2020 18:06:54 INFO] Finished Training Iteration: 14000
[07/12/2020 18:08:02 INFO] Finished Training Iteration: 14200
[07/12/2020 18:09:10 INFO] Finished Training Iteration: 14400
[07/12/2020 18:10:20 INFO] Finished Training Iteration: 14600
[07/12/2020 18:11:28 INFO] Finished Training Iteration: 14800
[07/12/2020 18:12:38 INFO] Saving checkpoint for iteration #15000
[07/12/2020 18:12:38 INFO] Finished Training Iteration: 15000
[07/12/2020 18:14:53 INFO] Iter 15000: loss 6.4850, precision 0.0085, recall 0.0119
[07/12/2020 18:16:01 INFO] Finished Training Iteration: 15200
[07/12/2020 18:17:12 INFO] Finished Training Iteration: 15400
[07/12/2020 18:18:19 INFO] Finished Training Iteration: 15600
[07/12/2020 18:19:30 INFO] Finished Training Iteration: 15800
[07/12/2020 18:20:35 INFO] Saving checkpoint for iteration #16000
[07/12/2020 18:20:35 INFO] Finished Training Iteration: 16000
[07/12/2020 18:21:45 INFO] Finished Training Iteration: 16200
[07/12/2020 18:22:54 INFO] Finished Training Iteration: 16400
[07/12/2020 18:24:02 INFO] Finished Training Iteration: 16600
[07/12/2020 18:25:12 INFO] Finished Training Iteration: 16800
[07/12/2020 18:26:20 INFO] Saving checkpoint for iteration #17000
[07/12/2020 18:26:21 INFO] Finished Training Iteration: 17000
[07/12/2020 18:27:28 INFO] Finished Training Iteration: 17200
[07/12/2020 18:28:39 INFO] Finished Training Iteration: 17400
[07/12/2020 18:31:16 INFO] Iter 17500: loss 5.1287, precision 0.0047, recall 0.0057
[07/12/2020 18:31:49 INFO] Finished Training Iteration: 17600
[07/12/2020 18:32:58 INFO] Finished Training Iteration: 17800
[07/12/2020 18:34:07 INFO] Saving checkpoint for iteration #18000
[07/12/2020 18:34:07 INFO] Finished Training Iteration: 18000
[07/12/2020 18:35:16 INFO] Finished Training Iteration: 18200
[07/12/2020 18:36:22 INFO] Finished Training Iteration: 18400
[07/12/2020 18:37:31 INFO] Finished Training Iteration: 18600
[07/12/2020 18:38:38 INFO] Finished Training Iteration: 18800
[07/12/2020 18:39:47 INFO] Saving checkpoint for iteration #19000
[07/12/2020 18:39:47 INFO] Finished Training Iteration: 19000
[07/12/2020 18:40:56 INFO] Finished Training Iteration: 19200
[07/12/2020 18:42:05 INFO] Finished Training Iteration: 19400
[07/12/2020 18:43:13 INFO] Finished Training Iteration: 19600
[07/12/2020 18:44:21 INFO] Finished Training Iteration: 19800
[07/12/2020 18:45:29 INFO] Saving checkpoint for iteration #20000
[07/12/2020 18:45:29 INFO] Finished Training Iteration: 20000
[07/12/2020 18:47:04 INFO] Iter 20000: loss 4.7143, precision 0.0047, recall 0.0058
[07/12/2020 18:48:13 INFO] Finished Training Iteration: 20200
[07/12/2020 18:49:20 INFO] Finished Training Iteration: 20400
[07/12/2020 18:50:28 INFO] Finished Training Iteration: 20600
[07/12/2020 18:51:36 INFO] Finished Training Iteration: 20800
[07/12/2020 18:52:46 INFO] Saving checkpoint for iteration #21000
[07/12/2020 18:52:47 INFO] Finished Training Iteration: 21000
[07/12/2020 18:53:56 INFO] Finished Training Iteration: 21200
[07/12/2020 18:55:06 INFO] Finished Training Iteration: 21400
[07/12/2020 18:56:14 INFO] Finished Training Iteration: 21600
[07/12/2020 18:57:24 INFO] Finished Training Iteration: 21800
[07/12/2020 18:58:34 INFO] Saving checkpoint for iteration #22000
[07/12/2020 18:58:34 INFO] Finished Training Iteration: 22000
[07/12/2020 18:59:40 INFO] Finished Training Iteration: 22200
[07/12/2020 19:00:47 INFO] Finished Training Iteration: 22400
[07/12/2020 19:02:55 INFO] Iter 22500: loss 4.4785, precision 0.0049, recall 0.0062
[07/12/2020 19:03:27 INFO] Finished Training Iteration: 22600
[07/12/2020 19:04:33 INFO] Finished Training Iteration: 22800
[07/12/2020 19:05:42 INFO] Saving checkpoint for iteration #23000
[07/12/2020 19:05:42 INFO] Finished Training Iteration: 23000
[07/12/2020 19:06:53 INFO] Finished Training Iteration: 23200
[07/12/2020 19:08:03 INFO] Finished Training Iteration: 23400
[07/12/2020 19:09:11 INFO] Finished Training Iteration: 23600
[07/12/2020 19:10:20 INFO] Finished Training Iteration: 23800
[07/12/2020 19:11:28 INFO] Saving checkpoint for iteration #24000
[07/12/2020 19:11:28 INFO] Finished Training Iteration: 24000
[07/12/2020 19:12:35 INFO] Finished Training Iteration: 24200
[07/12/2020 19:13:43 INFO] Finished Training Iteration: 24400
[07/12/2020 19:14:52 INFO] Finished Training Iteration: 24600
[07/12/2020 19:16:00 INFO] Finished Training Iteration: 24800
[07/12/2020 19:17:10 INFO] Saving checkpoint for iteration #25000
[07/12/2020 19:17:11 INFO] Finished Training Iteration: 25000
[07/12/2020 19:18:05 INFO] Iter 25000: loss 4.3575, precision 0.0050, recall 0.0061
[07/12/2020 19:19:17 INFO] Finished Training Iteration: 25200
[07/12/2020 19:20:25 INFO] Finished Training Iteration: 25400
[07/12/2020 19:21:32 INFO] Finished Training Iteration: 25600
[07/12/2020 19:22:40 INFO] Finished Training Iteration: 25800
[07/12/2020 19:23:51 INFO] Saving checkpoint for iteration #26000
[07/12/2020 19:23:51 INFO] Finished Training Iteration: 26000
[07/12/2020 19:24:58 INFO] Finished Training Iteration: 26200
[07/12/2020 19:26:09 INFO] Finished Training Iteration: 26400
[07/12/2020 19:27:16 INFO] Finished Training Iteration: 26600
[07/12/2020 19:28:21 INFO] Finished Training Iteration: 26800
[07/12/2020 19:29:29 INFO] Saving checkpoint for iteration #27000
[07/12/2020 19:29:29 INFO] Finished Training Iteration: 27000
[07/12/2020 19:30:38 INFO] Finished Training Iteration: 27200
[07/12/2020 19:31:44 INFO] Finished Training Iteration: 27400
[07/12/2020 19:33:22 INFO] Iter 27500: loss 6.1116, precision 0.0049, recall 0.0060
[07/12/2020 19:33:56 INFO] Finished Training Iteration: 27600
[07/12/2020 19:35:04 INFO] Finished Training Iteration: 27800
[07/12/2020 19:36:08 INFO] Saving checkpoint for iteration #28000
[07/12/2020 19:36:08 INFO] Finished Training Iteration: 28000
[07/12/2020 19:37:18 INFO] Finished Training Iteration: 28200
[07/12/2020 19:38:25 INFO] Finished Training Iteration: 28400
[07/12/2020 19:39:35 INFO] Finished Training Iteration: 28600
[07/12/2020 19:40:44 INFO] Finished Training Iteration: 28800
[07/12/2020 19:41:51 INFO] Saving checkpoint for iteration #29000
[07/12/2020 19:41:52 INFO] Finished Training Iteration: 29000
[07/12/2020 19:43:00 INFO] Finished Training Iteration: 29200
[07/12/2020 19:44:09 INFO] Finished Training Iteration: 29400
[07/12/2020 19:45:17 INFO] Finished Training Iteration: 29600
[07/12/2020 19:46:28 INFO] Finished Training Iteration: 29800
[07/12/2020 19:47:36 INFO] Saving checkpoint for iteration #30000
[07/12/2020 19:47:36 INFO] Finished Training Iteration: 30000
[07/12/2020 19:48:55 INFO] Iter 30000: loss 4.1265, precision 0.0059, recall 0.0074
[07/12/2020 19:50:02 INFO] Finished Training Iteration: 30200
[07/12/2020 19:51:11 INFO] Finished Training Iteration: 30400
[07/12/2020 19:52:19 INFO] Finished Training Iteration: 30600
[07/12/2020 19:53:28 INFO] Finished Training Iteration: 30800
[07/12/2020 19:54:34 INFO] Saving checkpoint for iteration #31000
[07/12/2020 19:54:34 INFO] Finished Training Iteration: 31000
[07/12/2020 19:55:44 INFO] Finished Training Iteration: 31200
[07/12/2020 19:56:50 INFO] Finished Training Iteration: 31400
[07/12/2020 19:58:01 INFO] Finished Training Iteration: 31600
[07/12/2020 19:59:09 INFO] Finished Training Iteration: 31800
[07/12/2020 20:00:18 INFO] Saving checkpoint for iteration #32000
[07/12/2020 20:00:19 INFO] Finished Training Iteration: 32000
[07/12/2020 20:01:29 INFO] Finished Training Iteration: 32200
[07/12/2020 20:02:38 INFO] Finished Training Iteration: 32400
[07/12/2020 20:04:09 INFO] Iter 32500: loss 5.3046, precision 0.0053, recall 0.0066
[07/12/2020 20:04:45 INFO] Finished Training Iteration: 32600
[07/12/2020 20:05:52 INFO] Finished Training Iteration: 32800
[07/12/2020 20:07:02 INFO] Saving checkpoint for iteration #33000
[07/12/2020 20:07:02 INFO] Finished Training Iteration: 33000
[07/12/2020 20:08:10 INFO] Finished Training Iteration: 33200
[07/12/2020 20:09:18 INFO] Finished Training Iteration: 33400
[07/12/2020 20:10:26 INFO] Finished Training Iteration: 33600
[07/12/2020 20:11:34 INFO] Finished Training Iteration: 33800
[07/12/2020 20:12:42 INFO] Saving checkpoint for iteration #34000
[07/12/2020 20:12:42 INFO] Finished Training Iteration: 34000
[07/12/2020 20:13:52 INFO] Finished Training Iteration: 34200
[07/12/2020 20:14:58 INFO] Finished Training Iteration: 34400
[07/12/2020 20:16:06 INFO] Finished Training Iteration: 34600
[07/12/2020 20:17:16 INFO] Finished Training Iteration: 34800
[07/12/2020 20:18:23 INFO] Saving checkpoint for iteration #35000
[07/12/2020 20:18:24 INFO] Finished Training Iteration: 35000
[07/12/2020 20:19:25 INFO] Iter 35000: loss 4.3671, precision 0.0056, recall 0.0067
[07/12/2020 20:20:32 INFO] Finished Training Iteration: 35200
[07/12/2020 20:21:40 INFO] Finished Training Iteration: 35400
[07/12/2020 20:22:49 INFO] Finished Training Iteration: 35600
[07/12/2020 20:23:57 INFO] Finished Training Iteration: 35800
[07/12/2020 20:25:06 INFO] Saving checkpoint for iteration #36000
[07/12/2020 20:25:06 INFO] Finished Training Iteration: 36000
[07/12/2020 20:26:15 INFO] Finished Training Iteration: 36200
[07/12/2020 20:27:25 INFO] Finished Training Iteration: 36400
[07/12/2020 20:28:34 INFO] Finished Training Iteration: 36600
[07/12/2020 20:29:43 INFO] Finished Training Iteration: 36800
[07/12/2020 20:30:54 INFO] Saving checkpoint for iteration #37000
[07/12/2020 20:30:54 INFO] Finished Training Iteration: 37000
[07/12/2020 20:32:05 INFO] Finished Training Iteration: 37200
[07/12/2020 20:33:16 INFO] Finished Training Iteration: 37400
/disk_ssd/SuperPoint/superpoint/models/base_model.py:412: RuntimeWarning: Mean of empty slice
  metrics = {m: np.nanmean(metrics[m], axis=0) for m in metrics}
[07/12/2020 20:33:53 INFO] Iter 37500: loss 3.3782, precision nan, recall 0.0000
[07/12/2020 20:34:28 INFO] Finished Training Iteration: 37600
[07/12/2020 20:35:36 INFO] Finished Training Iteration: 37800
[07/12/2020 20:36:45 INFO] Saving checkpoint for iteration #38000
[07/12/2020 20:36:45 INFO] Finished Training Iteration: 38000
[07/12/2020 20:37:53 INFO] Finished Training Iteration: 38200
[07/12/2020 20:39:02 INFO] Finished Training Iteration: 38400
[07/12/2020 20:40:10 INFO] Finished Training Iteration: 38600
[07/12/2020 20:41:19 INFO] Finished Training Iteration: 38800
[07/12/2020 20:42:26 INFO] Saving checkpoint for iteration #39000
[07/12/2020 20:42:26 INFO] Finished Training Iteration: 39000
[07/12/2020 20:43:33 INFO] Finished Training Iteration: 39200
[07/12/2020 20:44:42 INFO] Finished Training Iteration: 39400
[07/12/2020 20:45:51 INFO] Finished Training Iteration: 39600
[07/12/2020 20:47:01 INFO] Finished Training Iteration: 39800
[07/12/2020 20:48:09 INFO] Saving checkpoint for iteration #40000
[07/12/2020 20:48:10 INFO] Finished Training Iteration: 40000
[07/12/2020 20:48:35 INFO] Iter 40000: loss 4.4830, precision 0.0065, recall 0.0083
[07/12/2020 20:49:41 INFO] Finished Training Iteration: 40200
[07/12/2020 20:50:51 INFO] Finished Training Iteration: 40400
[07/12/2020 20:52:00 INFO] Finished Training Iteration: 40600
[07/12/2020 20:53:10 INFO] Finished Training Iteration: 40800
[07/12/2020 20:54:18 INFO] Saving checkpoint for iteration #41000
[07/12/2020 20:54:18 INFO] Finished Training Iteration: 41000
[07/12/2020 20:55:26 INFO] Finished Training Iteration: 41200
[07/12/2020 20:56:35 INFO] Finished Training Iteration: 41400
[07/12/2020 20:57:44 INFO] Finished Training Iteration: 41600
[07/12/2020 20:58:51 INFO] Finished Training Iteration: 41800
[07/12/2020 21:00:00 INFO] Saving checkpoint for iteration #42000
[07/12/2020 21:00:01 INFO] Finished Training Iteration: 42000
[07/12/2020 21:01:09 INFO] Finished Training Iteration: 42200
[07/12/2020 21:02:18 INFO] Finished Training Iteration: 42400
[07/12/2020 21:03:41 INFO] Iter 42500: loss 6.0322, precision 0.0047, recall 0.0058
[07/12/2020 21:04:16 INFO] Finished Training Iteration: 42600
[07/12/2020 21:05:24 INFO] Finished Training Iteration: 42800
[07/12/2020 21:06:35 INFO] Saving checkpoint for iteration #43000
[07/12/2020 21:06:36 INFO] Finished Training Iteration: 43000
[07/12/2020 21:07:45 INFO] Finished Training Iteration: 43200
[07/12/2020 21:08:51 INFO] Finished Training Iteration: 43400
[07/12/2020 21:10:00 INFO] Finished Training Iteration: 43600
[07/12/2020 21:11:09 INFO] Finished Training Iteration: 43800
[07/12/2020 21:12:19 INFO] Saving checkpoint for iteration #44000
[07/12/2020 21:12:19 INFO] Finished Training Iteration: 44000
[07/12/2020 21:13:24 INFO] Finished Training Iteration: 44200
[07/12/2020 21:14:34 INFO] Finished Training Iteration: 44400
[07/12/2020 21:15:43 INFO] Finished Training Iteration: 44600
[07/12/2020 21:16:51 INFO] Finished Training Iteration: 44800
[07/12/2020 21:17:59 INFO] Saving checkpoint for iteration #45000
[07/12/2020 21:17:59 INFO] Finished Training Iteration: 45000
[07/12/2020 21:19:07 INFO] Iter 45000: loss 4.2449, precision 0.0062, recall 0.0078
[07/12/2020 21:20:15 INFO] Finished Training Iteration: 45200
[07/12/2020 21:21:22 INFO] Finished Training Iteration: 45400
[07/12/2020 21:22:32 INFO] Finished Training Iteration: 45600
[07/12/2020 21:23:40 INFO] Finished Training Iteration: 45800
[07/12/2020 21:24:49 INFO] Saving checkpoint for iteration #46000
[07/12/2020 21:24:49 INFO] Finished Training Iteration: 46000
[07/12/2020 21:25:59 INFO] Finished Training Iteration: 46200
[07/12/2020 21:27:08 INFO] Finished Training Iteration: 46400
[07/12/2020 21:28:16 INFO] Finished Training Iteration: 46600
[07/12/2020 21:29:23 INFO] Finished Training Iteration: 46800
[07/12/2020 21:30:33 INFO] Saving checkpoint for iteration #47000
[07/12/2020 21:30:33 INFO] Finished Training Iteration: 47000
[07/12/2020 21:31:42 INFO] Finished Training Iteration: 47200
[07/12/2020 21:32:49 INFO] Finished Training Iteration: 47400
[07/12/2020 21:33:23 INFO] Iter 47500: loss 4.8564, precision nan, recall 0.0000
[07/12/2020 21:33:56 INFO] Finished Training Iteration: 47600
[07/12/2020 21:35:05 INFO] Finished Training Iteration: 47800
[07/12/2020 21:36:15 INFO] Saving checkpoint for iteration #48000
[07/12/2020 21:36:15 INFO] Finished Training Iteration: 48000
[07/12/2020 21:37:26 INFO] Finished Training Iteration: 48200
[07/12/2020 21:38:33 INFO] Finished Training Iteration: 48400
[07/12/2020 21:39:41 INFO] Finished Training Iteration: 48600
[07/12/2020 21:40:52 INFO] Finished Training Iteration: 48800
[07/12/2020 21:42:01 INFO] Saving checkpoint for iteration #49000
[07/12/2020 21:42:01 INFO] Finished Training Iteration: 49000
[07/12/2020 21:43:12 INFO] Finished Training Iteration: 49200
[07/12/2020 21:44:19 INFO] Finished Training Iteration: 49400
[07/12/2020 21:45:25 INFO] Finished Training Iteration: 49600
[07/12/2020 21:46:35 INFO] Finished Training Iteration: 49800
[07/12/2020 21:47:43 INFO] Saving checkpoint for iteration #50000
[07/12/2020 21:47:44 INFO] Finished Training Iteration: 50000
[07/12/2020 21:47:46 INFO] Iter 50000: loss 5.9736, precision nan, recall 0.0000
[07/12/2020 21:48:54 INFO] Finished Training Iteration: 50200
[07/12/2020 21:50:02 INFO] Finished Training Iteration: 50400
[07/12/2020 21:51:11 INFO] Finished Training Iteration: 50600
[07/12/2020 21:51:34 INFO] Got Keyboard Interrupt, saving model and closing.
[07/12/2020 21:51:34 INFO] Saving checkpoint for iteration #50668
