[03/26/2020 15:59:04 INFO] Running command TRAIN
[03/26/2020 15:59:21 INFO] Running command TRAIN
[03/26/2020 15:59:34 INFO] Running command TRAIN
[03/26/2020 15:59:34 INFO] Number of GPUs detected: 1
2020-03-26 15:59:35.100624: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 15:59:35.746743: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.747083: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 15:59:35.748003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 15:59:35.764741: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 15:59:35.772208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 15:59:35.774484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 15:59:35.791918: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 15:59:35.804966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 15:59:35.852548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 15:59:35.852856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.854237: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.855405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 15:59:35.856787: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 15:59:35.892346: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 15:59:35.893043: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563c452b9f0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 15:59:35.893067: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 15:59:35.957715: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.958097: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5563c45c19a0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 15:59:35.958109: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 15:59:35.958256: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.958546: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 15:59:35.958574: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 15:59:35.958583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 15:59:35.958608: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 15:59:35.958615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 15:59:35.958623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 15:59:35.958631: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 15:59:35.958641: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 15:59:35.958675: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.959023: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.959292: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 15:59:35.959311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 15:59:35.960141: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 15:59:35.960149: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 15:59:35.960153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 15:59:35.960214: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.960522: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:35.960818: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
[03/26/2020 15:59:54 INFO] Running command TRAIN
[03/26/2020 15:59:54 INFO] Number of GPUs detected: 1
2020-03-26 15:59:54.671724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 15:59:55.136504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.136812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 15:59:55.136955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 15:59:55.138099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 15:59:55.138899: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 15:59:55.139075: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 15:59:55.140150: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 15:59:55.140937: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 15:59:55.143414: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 15:59:55.143496: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.143801: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.144047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 15:59:55.144362: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 15:59:55.168362: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 15:59:55.169045: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f3e91e9b70 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 15:59:55.169061: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 15:59:55.217320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.217667: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55f3e927fb20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 15:59:55.217681: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 15:59:55.217797: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.218052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 15:59:55.218079: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 15:59:55.218089: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 15:59:55.218096: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 15:59:55.218104: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 15:59:55.218113: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 15:59:55.218121: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 15:59:55.218128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 15:59:55.218162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.218423: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.218658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 15:59:55.218677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 15:59:55.219241: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 15:59:55.219249: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 15:59:55.219253: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 15:59:55.219312: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.219580: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 15:59:55.219836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 16:00:14 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7ff2059804d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 16:00:14 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 16:00:16 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 16:00:17 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 16:00:18.131909: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 16:00:18 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7ff15c572c20> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 16:00:18.177157: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 16:00:18 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7ff1781267a0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 16:00:18.226110: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 16:00:18.226837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:00:18.227142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 16:00:18.227178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 16:00:18.227194: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 16:00:18.227209: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 16:00:18.227224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 16:00:18.227238: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 16:00:18.227253: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 16:00:18.227268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 16:00:18.227311: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:00:18.227600: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:00:18.227859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 16:00:18.287589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 16:00:18.287610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 16:00:18.287618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 16:00:18.287748: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:00:18.288112: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:00:18.288412: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[03/26/2020 16:20:18 INFO] Running command TRAIN
[03/26/2020 16:20:18 INFO] Number of GPUs detected: 1
2020-03-26 16:20:18.244587: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 16:20:18.707417: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.707695: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 16:20:18.707833: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 16:20:18.708889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 16:20:18.709632: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 16:20:18.709795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 16:20:18.710818: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 16:20:18.711747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 16:20:18.714230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 16:20:18.714389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.714784: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.715109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 16:20:18.715434: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 16:20:18.740315: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 16:20:18.740751: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c44e2483e0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 16:20:18.740761: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 16:20:18.788974: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.789318: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c44e2de390 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 16:20:18.789331: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 16:20:18.789471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.789759: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 16:20:18.789786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 16:20:18.789796: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 16:20:18.789804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 16:20:18.789829: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 16:20:18.789838: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 16:20:18.789847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 16:20:18.789854: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 16:20:18.789889: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.790199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.790467: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 16:20:18.790487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 16:20:18.791072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 16:20:18.791081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 16:20:18.791085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 16:20:18.791179: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.791490: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:18.791782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 16:20:40 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f4ed3db24d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 16:20:40 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 16:20:42 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 16:20:43 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 16:20:43.971708: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 16:20:43 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f4dcc670950> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 16:20:44.018091: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 16:20:44 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f4e2014a440> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 16:20:44.067409: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 16:20:44.068151: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:44.068449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 16:20:44.068480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 16:20:44.068490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 16:20:44.068498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 16:20:44.068506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 16:20:44.068514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 16:20:44.068523: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 16:20:44.068531: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 16:20:44.068569: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:44.068852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:44.069106: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 16:20:44.090395: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 16:20:44.090407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 16:20:44.090411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 16:20:44.090484: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:44.090766: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 16:20:44.091017: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 18:29:24 INFO] Running command TRAIN
[03/26/2020 18:29:24 INFO] Number of GPUs detected: 1
2020-03-26 18:29:24.685053: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:29:25.146763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.147137: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:29:25.147315: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:29:25.148435: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:29:25.149177: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:29:25.149379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:29:25.150420: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:29:25.151213: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:29:25.153666: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:29:25.153836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.154213: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.154506: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:29:25.154802: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:29:25.180311: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:29:25.180679: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9caa76880 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:29:25.180690: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:29:25.228402: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.228745: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c9cab0c840 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:29:25.228758: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:29:25.228908: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.229198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:29:25.229224: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:29:25.229233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:29:25.229258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:29:25.229267: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:29:25.229279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:29:25.229290: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:29:25.229301: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:29:25.229352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.229649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.229919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:29:25.229941: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:29:25.230525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:29:25.230534: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:29:25.230538: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:29:25.230633: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.230937: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:25.231228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 18:29:46 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fdbf39264d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 18:29:46 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 18:29:48 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 18:29:49 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 18:29:49.622517: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:29:49 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fdb245d4cb0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:29:49.668313: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:29:49 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fdb404bf200> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:29:49.716694: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 18:29:49.717408: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:49.717706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:29:49.717736: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:29:49.717746: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:29:49.717754: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:29:49.717762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:29:49.717770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:29:49.717778: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:29:49.717786: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:29:49.717824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:49.718104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:49.718355: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:29:49.738749: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:29:49.738763: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:29:49.738767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:29:49.738854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:49.739142: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:29:49.739394: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 18:41:02 INFO] Running command TRAIN
[03/26/2020 18:41:02 INFO] Number of GPUs detected: 1
2020-03-26 18:41:02.431958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:41:02.896760: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.897068: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:41:02.897211: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:41:02.898356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:41:02.899156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:41:02.899332: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:41:02.900456: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:41:02.901240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:41:02.903625: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:41:02.903700: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.904000: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.904254: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:41:02.904496: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:41:02.928416: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:41:02.928936: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560cc346f5c0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:41:02.928950: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:41:02.977317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.977671: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560cc3505580 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:41:02.977684: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:41:02.977832: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.978119: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:41:02.978146: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:41:02.978155: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:41:02.978163: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:41:02.978191: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:41:02.978200: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:41:02.978208: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:41:02.978217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:41:02.978252: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.978568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.978843: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:41:02.978864: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:41:02.979460: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:41:02.979468: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:41:02.979472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:41:02.979551: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.979906: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:02.980205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 18:41:24 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f130d6e14d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 18:41:24 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 18:41:26 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 18:41:27 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 18:41:27.870502: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:41:27 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f12603dc950> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:41:27.915583: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:41:27 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f12603f5b90> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:41:27.964830: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 18:41:27.965504: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:27.965807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:41:27.965841: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:41:27.965857: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:41:27.965873: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:41:27.965887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:41:27.965902: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:41:27.965916: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:41:27.965932: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:41:27.965976: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:27.966268: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:27.966527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:41:27.985180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:41:27.985192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:41:27.985198: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:41:27.985265: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:27.985550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:41:27.985805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[03/26/2020 18:45:38 INFO] Running command TRAIN
[03/26/2020 18:45:38 INFO] Number of GPUs detected: 1
2020-03-26 18:45:38.713266: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:45:39.175156: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.175488: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:45:39.175680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:45:39.176889: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:45:39.177662: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:45:39.178490: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:45:39.179551: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:45:39.180431: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:45:39.182768: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:45:39.182922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.183471: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.183790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:45:39.184177: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:45:39.208313: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:45:39.208809: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562141e90070 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:45:39.208818: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:45:39.257810: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.258222: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x562141f26030 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:45:39.258240: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:45:39.258360: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.258614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:45:39.258645: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:45:39.258656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:45:39.258665: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:45:39.258675: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:45:39.258684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:45:39.258692: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:45:39.258702: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:45:39.258736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.258998: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.259233: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:45:39.259255: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:45:39.259813: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:45:39.259822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:45:39.259825: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:45:39.259883: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.260157: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:45:39.260411: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 18:46:00 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f93bf55b4d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 18:46:00 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 18:46:02 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 18:46:03 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 18:46:03.614947: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:46:03 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f9344148710> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:46:03.660533: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:46:03 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f92fc5b2dd0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:46:03.709670: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 18:46:03.710505: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:46:03.710905: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:46:03.710940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:46:03.710951: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:46:03.710960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:46:03.710968: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:46:03.710977: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:46:03.710985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:46:03.710994: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:46:03.711039: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:46:03.711320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:46:03.711572: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:46:03.734519: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:46:03.734532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:46:03.734536: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:46:03.734614: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:46:03.734898: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:46:03.735150: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 18:52:40 INFO] Running command TRAIN
[03/26/2020 18:52:40 INFO] Number of GPUs detected: 1
2020-03-26 18:52:40.128361: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:52:40.592590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.592897: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:52:40.593038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:52:40.594184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:52:40.594980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:52:40.595156: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:52:40.596317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:52:40.597103: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:52:40.599493: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:52:40.599567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.599870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.600123: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:52:40.600358: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:52:40.624297: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:52:40.624620: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561fd482dad0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:52:40.624631: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:52:40.672241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.672601: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x561fd48c3a90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:52:40.672613: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:52:40.672761: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.673143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:52:40.673171: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:52:40.673181: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:52:40.673188: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:52:40.673196: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:52:40.673204: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:52:40.673237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:52:40.673246: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:52:40.673278: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.673593: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.673863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:52:40.673883: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:52:40.674445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:52:40.674454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:52:40.674458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:52:40.674515: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.674824: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:52:40.675078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 18:53:01 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f16dc8724d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 18:53:01 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 18:53:03 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 18:53:04 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 18:53:04.703406: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:53:04 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f161c0da710> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:53:04.749945: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:53:04 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f161c19f560> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:53:04.800336: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 18:53:04.801054: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:53:04.801369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:53:04.801406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:53:04.801425: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:53:04.801438: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:53:04.801447: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:53:04.801455: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:53:04.801464: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:53:04.801472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:53:04.801521: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:53:04.801816: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:53:04.802082: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:53:04.812080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:53:04.812090: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:53:04.812094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:53:04.812162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:53:04.812458: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:53:04.812719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 18:54:43 INFO] Running command TRAIN
[03/26/2020 18:54:43 INFO] Number of GPUs detected: 1
2020-03-26 18:54:43.966240: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:54:44.423429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.423770: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:54:44.423936: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:54:44.425041: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:54:44.425860: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:54:44.426080: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:54:44.427189: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:54:44.428111: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:54:44.430533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:54:44.430668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.431050: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.431351: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:54:44.431646: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:54:44.456347: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:54:44.456885: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5584e9413290 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:54:44.456899: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:54:44.508817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.509190: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5584e94a9250 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:54:44.509201: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:54:44.509371: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.509682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:54:44.509710: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:54:44.509721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:54:44.509747: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:54:44.509775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:54:44.509785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:54:44.509794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:54:44.509804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:54:44.509852: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.510189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.510486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:54:44.510507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:54:44.511109: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:54:44.511118: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:54:44.511121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:54:44.511229: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.511543: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:54:44.511860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 18:55:06 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fe65cf624d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 18:55:06 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 18:55:09 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 18:55:09 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 18:55:10.380036: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:55:10 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fe5a00974d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:55:10.427350: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:55:10 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fe5a04594d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:55:10.477137: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 18:55:10.477892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:55:10.478200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:55:10.478233: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:55:10.478243: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:55:10.478252: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:55:10.478264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:55:10.478280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:55:10.478296: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:55:10.478311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:55:10.478352: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:55:10.478651: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:55:10.478913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:55:10.496009: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:55:10.496020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:55:10.496024: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:55:10.496104: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:55:10.496399: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:55:10.496658: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 18:57:46 INFO] Running command TRAIN
[03/26/2020 18:57:46 INFO] Number of GPUs detected: 1
2020-03-26 18:57:46.797724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:57:47.259481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.259796: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:57:47.259938: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:57:47.261091: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:57:47.261987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:57:47.262178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:57:47.263230: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:57:47.264021: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:57:47.266367: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:57:47.266530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.266870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.267170: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:57:47.267463: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:57:47.288366: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:57:47.288943: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c469163350 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:57:47.288953: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:57:47.341897: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.342274: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c4691f9310 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:57:47.342286: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:57:47.342481: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.342918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:57:47.342948: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:57:47.342958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:57:47.342966: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:57:47.342993: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:57:47.343009: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:57:47.343025: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:57:47.343038: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:57:47.343103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.343411: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.343689: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:57:47.343711: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:57:47.344347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:57:47.344357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:57:47.344360: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:57:47.344446: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.344777: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:57:47.345073: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 18:58:08 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fddbead14d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 18:58:08 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 18:58:10 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 18:58:11 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 18:58:12.034326: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:58:12 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fdd2410a560> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:58:12.079503: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 18:58:12 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fdce43e9950> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 18:58:12.127877: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 18:58:12.128966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:58:12.129266: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:58:12.129298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:58:12.129308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:58:12.129316: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:58:12.129326: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:58:12.129334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:58:12.129343: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:58:12.129352: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:58:12.129388: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:58:12.129668: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:58:12.129918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:58:12.148145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:58:12.148155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:58:12.148159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:58:12.148220: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:58:12.148497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:58:12.148744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 18:59:38 INFO] Running command TRAIN
[03/26/2020 18:59:38 INFO] Number of GPUs detected: 1
2020-03-26 18:59:38.415040: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 18:59:38.876511: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.876851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:59:38.877016: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:59:38.878162: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:59:38.878960: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:59:38.879138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:59:38.880293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:59:38.881147: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:59:38.883588: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:59:38.883666: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.883972: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.884226: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:59:38.884453: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 18:59:38.908248: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 18:59:38.908617: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c20eb58900 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:59:38.908631: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 18:59:38.956879: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.957273: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c20ebee8b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 18:59:38.957287: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 18:59:38.957480: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.957782: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 18:59:38.957811: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:59:38.957849: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 18:59:38.957882: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 18:59:38.957910: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 18:59:38.957939: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 18:59:38.957987: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 18:59:38.958015: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 18:59:38.958075: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.958427: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.958705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 18:59:38.958767: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 18:59:38.959362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 18:59:38.959372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 18:59:38.959375: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 18:59:38.959486: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.959805: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 18:59:38.960155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 19:00:00 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fa2692524d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 19:00:00 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 19:00:02 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 19:00:02 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 19:00:03.460399: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:00:03 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fa19c751e60> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:00:03.506372: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:00:03 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fa1dc0e5f80> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:00:03.554413: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 19:00:03.555136: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:03.555434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:00:03.555466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:00:03.555477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:00:03.555486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:00:03.555496: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:00:03.555505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:00:03.555513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:00:03.555522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:00:03.555557: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:03.555837: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:03.556096: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:00:03.575258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:00:03.575271: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:00:03.575275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:00:03.575356: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:03.575640: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:03.575888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 19:00:26 INFO] Running command TRAIN
[03/26/2020 19:00:26 INFO] Number of GPUs detected: 1
2020-03-26 19:00:26.751887: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 19:00:27.215854: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.216144: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:00:27.216280: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:00:27.217368: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:00:27.218134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:00:27.218302: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:00:27.219392: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:00:27.220225: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:00:27.222571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:00:27.222681: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.223069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.223549: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:00:27.223912: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 19:00:27.248455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 19:00:27.248967: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55da50445220 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:00:27.248977: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 19:00:27.297597: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.298052: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55da504db1d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:00:27.298065: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 19:00:27.298180: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.298434: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:00:27.298461: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:00:27.298471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:00:27.298478: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:00:27.298488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:00:27.298497: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:00:27.298504: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:00:27.298512: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:00:27.298546: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.298809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.299043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:00:27.299065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:00:27.299624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:00:27.299633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:00:27.299637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:00:27.299696: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.299965: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:27.300228: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 19:00:48 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fb4c76bd4d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 19:00:48 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 19:00:50 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 19:00:51 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 19:00:51.949154: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:00:51 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fb40077f5f0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:00:51.994702: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:00:52 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fb40077e5f0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:00:52.043771: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 19:00:52.044439: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:52.044732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:00:52.044762: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:00:52.044771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:00:52.044780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:00:52.044787: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:00:52.044795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:00:52.044804: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:00:52.044812: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:00:52.044849: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:52.045131: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:52.045383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:00:52.063309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:00:52.063319: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:00:52.063323: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:00:52.063384: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:52.063660: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:00:52.063907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 19:02:29 INFO] Running command TRAIN
[03/26/2020 19:02:29 INFO] Number of GPUs detected: 1
2020-03-26 19:02:29.101164: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 19:02:29.560079: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.560493: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:02:29.560688: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:02:29.561775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:02:29.562590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:02:29.562809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:02:29.563878: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:02:29.564685: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:02:29.567099: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:02:29.567241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.567620: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.567948: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:02:29.568252: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 19:02:29.592355: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 19:02:29.592747: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db42695360 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:02:29.592760: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 19:02:29.643167: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.643521: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55db435a0350 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:02:29.643534: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 19:02:29.643658: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.643922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:02:29.643955: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:02:29.643972: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:02:29.643988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:02:29.644003: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:02:29.644018: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:02:29.644033: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:02:29.644049: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:02:29.644098: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.644374: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.644618: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:02:29.644644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:02:29.645207: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:02:29.645217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:02:29.645223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:02:29.645290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.645568: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:29.645833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 19:02:51 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f71bce5e4d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 19:02:51 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 19:02:53 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 19:02:53 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 19:02:54.434785: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:02:54 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f70d432c8c0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:02:54.481306: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:02:54 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f710446ea70> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:02:54.530171: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 19:02:54.530905: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:54.531205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:02:54.531237: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:02:54.531249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:02:54.531258: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:02:54.531268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:02:54.531278: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:02:54.531287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:02:54.531298: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:02:54.531339: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:54.531629: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:54.531887: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:02:54.550215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:02:54.550227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:02:54.550232: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:02:54.550320: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:54.550613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:02:54.550869: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 19:04:17 INFO] Running command TRAIN
[03/26/2020 19:04:17 INFO] Number of GPUs detected: 1
2020-03-26 19:04:17.159219: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 19:04:17.618130: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.618446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:04:17.618609: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:04:17.619656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:04:17.620449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:04:17.620672: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:04:17.621757: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:04:17.622601: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:04:17.624965: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:04:17.625128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.625523: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.625853: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:04:17.626172: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 19:04:17.648329: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 19:04:17.648823: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dfb642cc00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:04:17.648849: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 19:04:17.702565: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.702906: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55dfb6c2fa00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:04:17.702920: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 19:04:17.703036: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.703291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:04:17.703317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:04:17.703327: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:04:17.703335: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:04:17.703342: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:04:17.703350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:04:17.703358: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:04:17.703365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:04:17.703398: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.703659: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.703893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:04:17.703914: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:04:17.704477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:04:17.704486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:04:17.704490: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:04:17.704550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.704817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:17.705072: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 19:04:38 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fc360cef4d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 19:04:38 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 19:04:40 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 19:04:41 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 19:04:41.838795: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:04:41 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fc2705dd170> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:04:41.884676: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:04:41 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fc2a81efb00> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:04:41.933653: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 19:04:41.934391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:41.934690: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:04:41.934720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:04:41.934729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:04:41.934737: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:04:41.934745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:04:41.934753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:04:41.934761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:04:41.934770: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:04:41.934808: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:41.935088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:41.935339: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:04:41.957408: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:04:41.957419: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:04:41.957423: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:04:41.957485: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:41.957763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:04:41.958013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 19:06:03 INFO] Running command TRAIN
[03/26/2020 19:06:03 INFO] Number of GPUs detected: 1
2020-03-26 19:06:03.739689: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 19:06:04.200119: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.200399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:06:04.200532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:06:04.201561: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:06:04.202428: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:06:04.202684: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:06:04.203879: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:06:04.204723: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:06:04.207030: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:06:04.207189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.207589: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.207914: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:06:04.208273: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 19:06:04.232455: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 19:06:04.232953: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55727d63a260 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:06:04.232966: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 19:06:04.283189: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.283534: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55727d6d0210 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 19:06:04.283548: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 19:06:04.283665: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.283920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:06:04.283947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:06:04.283956: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:06:04.283964: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:06:04.283971: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:06:04.283980: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:06:04.283988: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:06:04.283996: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:06:04.284029: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.284298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.284535: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:06:04.284554: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:06:04.285113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:06:04.285122: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:06:04.285126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:06:04.285183: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.285451: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:04.285703: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 19:06:25 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7ff1e20474d0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 19:06:25 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 19:06:27 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 19:06:27 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 19:06:28.378041: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:06:28 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7ff1841a3320> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:06:28.423650: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 19:06:28 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7ff1841a8950> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 19:06:28.473580: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 19:06:28.474436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:28.474741: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 19:06:28.474774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 19:06:28.474783: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 19:06:28.474790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 19:06:28.474798: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 19:06:28.474805: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 19:06:28.474814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 19:06:28.474823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 19:06:28.474866: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:28.475150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:28.475404: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 19:06:28.497732: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 19:06:28.497744: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 19:06:28.497748: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 19:06:28.497822: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:28.498110: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 19:06:28.498364: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[03/26/2020 19:58:17 INFO] Running command TRAIN
[03/26/2020 20:02:19 INFO] Running command TRAIN
[03/26/2020 20:02:19 INFO] Number of GPUs detected: 1
2020-03-26 20:02:21.305728: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 20:02:21.965841: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:21.966210: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:02:21.967145: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:02:21.984926: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:02:21.992451: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:02:21.994891: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:02:22.011637: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:02:22.023034: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:02:22.055712: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:02:22.055850: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.056196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.056440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:02:22.060391: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 20:02:22.264117: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 20:02:22.265708: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b18b0c20b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 20:02:22.265737: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 20:02:22.346161: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.346578: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55b18b158040 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 20:02:22.346592: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 20:02:22.346772: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.347067: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:02:22.347116: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:02:22.347128: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:02:22.347138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:02:22.347153: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:02:22.347166: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:02:22.347175: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:02:22.347184: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:02:22.347235: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.347532: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.347806: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:02:22.362270: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:02:22.363369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 20:02:22.363398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 20:02:22.363403: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 20:02:22.372525: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.373046: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:22.373486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
[03/26/2020 20:02:32 INFO] Running command TRAIN
[03/26/2020 20:02:32 INFO] Number of GPUs detected: 1
2020-03-26 20:02:32.360565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 20:02:32.818966: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.819358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:02:32.819560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:02:32.820677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:02:32.821520: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:02:32.821752: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:02:32.822888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:02:32.823774: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:02:32.826185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:02:32.826329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.828069: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.828343: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:02:32.828603: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 20:02:32.852073: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 20:02:32.852535: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605391de430 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 20:02:32.852562: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 20:02:32.905150: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.905507: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5605392743c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 20:02:32.905520: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 20:02:32.905645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.905900: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:02:32.905931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:02:32.905942: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:02:32.905950: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:02:32.905958: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:02:32.905967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:02:32.905975: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:02:32.905984: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:02:32.906022: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.906289: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.906524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:02:32.906549: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:02:32.907314: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 20:02:32.907328: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 20:02:32.907335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 20:02:32.907433: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.907733: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:02:32.908033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 20:02:55 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fe3a75fab90> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 20:02:55 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 20:02:57 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 20:02:58 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 20:02:59.920935: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 20:02:59 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fe3144f2830> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 20:02:59.970276: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 20:02:59 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fe2dc35a830> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 20:03:00.023022: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 20:03:00.023827: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:03:00.024239: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:03:00.024281: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:03:00.024293: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:03:00.024303: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:03:00.024311: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:03:00.024320: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:03:00.024330: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:03:00.024340: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:03:00.024391: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:03:00.024678: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:03:00.024931: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:03:00.104688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 20:03:00.104712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 20:03:00.104717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 20:03:00.104870: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:03:00.105193: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:03:00.105445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
[03/26/2020 20:34:06 INFO] Running command TRAIN
[03/26/2020 20:34:06 INFO] Number of GPUs detected: 1
2020-03-26 20:34:06.550448: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 20:34:07.009833: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.010114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:34:07.010249: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:34:07.011323: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:34:07.012216: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:34:07.012472: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:34:07.013575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:34:07.014409: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:34:07.016881: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:34:07.017049: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.017448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.017777: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:34:07.018081: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-03-26 20:34:07.040292: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-03-26 20:34:07.041778: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e500cdc160 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-03-26 20:34:07.041830: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-03-26 20:34:07.093583: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.093941: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e500d720f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-03-26 20:34:07.093954: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-03-26 20:34:07.094127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.094415: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:34:07.094444: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:34:07.094454: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:34:07.094479: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:34:07.094488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:34:07.094498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:34:07.094506: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:34:07.094516: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:34:07.094552: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.094907: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.095177: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:34:07.095201: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:34:07.095933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 20:34:07.095943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 20:34:07.095946: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 20:34:07.096025: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.096377: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:07.096685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
Extracting archive for primitive draw_lines.
Extracting archive for primitive draw_polygon.
Extracting archive for primitive draw_multiple_polygons.
Extracting archive for primitive draw_ellipses.
Extracting archive for primitive draw_star.
Extracting archive for primitive draw_checkerboard.
Extracting archive for primitive draw_stripes.
Extracting archive for primitive draw_cube.
Extracting archive for primitive gaussian_noise.
[03/26/2020 20:34:28 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f3216b5eb90> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[03/26/2020 20:34:28 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
Caching data, fist access will take some time.
[03/26/2020 20:34:30 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:218: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[03/26/2020 20:34:30 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/homographies.py:277: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2020-03-26 20:34:31.554417: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 20:34:31 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f316c23ccb0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 20:34:31.600527: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[03/26/2020 20:34:31 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f316c26cc20> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

Caching data, fist access will take some time.
2020-03-26 20:34:31.650314: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2020-03-26 20:34:31.651129: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:31.651428: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-03-26 20:34:31.651460: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-03-26 20:34:31.651471: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-03-26 20:34:31.651480: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-03-26 20:34:31.651488: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-03-26 20:34:31.651498: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-03-26 20:34:31.651511: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-03-26 20:34:31.651522: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 20:34:31.651567: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:31.651868: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:31.652126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-03-26 20:34:31.672042: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 20:34:31.672053: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-03-26 20:34:31.672057: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-03-26 20:34:31.672124: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:31.672406: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-03-26 20:34:31.672655: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7489 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
[04/04/2020 04:08:28 INFO] Running command TRAIN
2020-04-04 04:08:28.729615: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-04 04:08:28.811403: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:08:28.811708: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:08:28.811764: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:08:28.811801: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:08:28.820405: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:08:28.822831: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:08:28.841753: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:08:28.844507: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:08:28.844534: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:08:28.844611: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:08:28.844857: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:08:28.845037: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
[04/04/2020 04:08:28 INFO] Number of GPUs detected: 0
[04/04/2020 04:10:27 INFO] Running command TRAIN
2020-04-04 04:10:27.968541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-04 04:10:28.003184: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:28.003461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:10:28.003494: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:10:28.003528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:10:28.005217: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:10:28.006102: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:10:28.008758: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:10:28.009900: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:10:28.009931: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:10:28.009995: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:28.010283: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:28.010524: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
[04/04/2020 04:10:28 INFO] Number of GPUs detected: 1
[04/04/2020 04:10:55 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fa82815fd40> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[04/04/2020 04:10:56 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
[04/04/2020 04:10:56 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/utils/pipeline.py:69: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[04/04/2020 04:10:56 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fa8206039e0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[04/04/2020 04:10:56 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7fa820088680> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

2020-04-04 04:10:56.829541: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-04 04:10:57.194170: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-04-04 04:10:57.219962: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb02adbd90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-04 04:10:57.219987: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-04 04:10:57.535066: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:57.535381: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55fb029b6e10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-04 04:10:57.535393: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-04-04 04:10:57.547011: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:57.562216: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:10:57.686078: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:10:57.696639: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:10:57.803782: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:10:57.804072: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:10:57.804328: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:10:57.804638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:10:57.815466: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:10:57.815550: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:57.815825: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:57.816002: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-04 04:10:57.816458: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:10:58.728501: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-04 04:10:58.728528: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-04 04:10:58.740200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-04 04:10:58.772201: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:58.772443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:10:58.773044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1711 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
[04/04/2020 04:10:59 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[04/04/2020 04:10:59 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[04/04/2020 04:10:59 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
[04/04/2020 04:11:00 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[04/04/2020 04:11:00 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[04/04/2020 04:11:00 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[04/04/2020 04:11:00 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[04/04/2020 04:11:00 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.
2020-04-04 04:11:02.210507: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:11:02.302893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:11:02.497334: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:11:02.497868: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:11:02.584619: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:11:02.584947: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:11:02.585234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:11:02.585513: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:11:02.596277: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:11:02.596389: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:11:02.596645: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:11:02.602740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-04 04:11:02.603100: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-04 04:11:02.603115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-04 04:11:02.603121: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-04 04:11:02.603315: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:11:02.603575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:11:02.603767: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1711 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[04/04/2020 04:11:07 INFO] Start training
2020-04-04 04:11:24.109657: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:11:30.776787: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:30.868230: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:30.932502: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 701.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:30.932553: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 701.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:31.454135: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:11:33.245252: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 656.12M (687996928 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:33.325387: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 590.51M (619197440 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:33.327065: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 531.46M (557277696 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:33.328710: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 478.32M (501550080 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:33.330423: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 430.48M (451395072 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:33.332199: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 387.44M (406255616 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:33.425599: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 316.00MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:33.425626: W tensorflow/core/kernels/gpu_utils.cc:48] Failed to allocate memory for convolution redzone checking; skipping this check. This is benign and only means that we won't check cudnn for out-of-bounds reads and writes. This message will only be printed once.
2020-04-04 04:11:33.686658: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:33.687521: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.65GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:33.921125: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:33.921158: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 1.33GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:11:34.011306: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 307.43M (322366720 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:34.011329: W tensorflow/core/common_runtime/bfc_allocator.cc:309] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-04-04 04:11:34.042513: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 315.43M (330755328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:34.043048: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 315.43M (330755328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:34.043574: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 315.43M (330755328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:34.044086: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 315.43M (330755328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:44.779634: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 315.43M (330755328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:44.873315: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 315.43M (330755328 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:11:44.882931: W tensorflow/core/common_runtime/bfc_allocator.cc:424] Allocator (GPU_0_bfc) ran out of memory trying to allocate 300.00MiB (rounded to 314572800).  Current allocation summary follows.
2020-04-04 04:11:44.889954: I tensorflow/core/common_runtime/bfc_allocator.cc:894] BFCAllocator dump for GPU_0_bfc
2020-04-04 04:11:44.889972: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (256): 	Total Chunks: 31, Chunks in use: 27. 7.8KiB allocated for chunks. 6.8KiB in use in bin. 2.8KiB client-requested in use in bin.
2020-04-04 04:11:44.889983: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (512): 	Total Chunks: 15, Chunks in use: 15. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 6.8KiB client-requested in use in bin.
2020-04-04 04:11:44.889990: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (1024): 	Total Chunks: 5, Chunks in use: 4. 5.8KiB allocated for chunks. 4.2KiB in use in bin. 4.0KiB client-requested in use in bin.
2020-04-04 04:11:44.889996: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (2048): 	Total Chunks: 1, Chunks in use: 0. 2.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890001: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890006: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890012: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890017: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890024: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (65536): 	Total Chunks: 2, Chunks in use: 2. 140.0KiB allocated for chunks. 140.0KiB in use in bin. 140.0KiB client-requested in use in bin.
2020-04-04 04:11:44.890031: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (131072): 	Total Chunks: 4, Chunks in use: 4. 582.0KiB allocated for chunks. 582.0KiB in use in bin. 582.0KiB client-requested in use in bin.
2020-04-04 04:11:44.890037: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (262144): 	Total Chunks: 1, Chunks in use: 1. 288.0KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.
2020-04-04 04:11:44.890043: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (524288): 	Total Chunks: 3, Chunks in use: 3. 2.21MiB allocated for chunks. 2.21MiB in use in bin. 1.69MiB client-requested in use in bin.
2020-04-04 04:11:44.890051: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.12MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2020-04-04 04:11:44.890058: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (2097152): 	Total Chunks: 1, Chunks in use: 0. 2.65MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890063: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (4194304): 	Total Chunks: 1, Chunks in use: 1. 4.69MiB allocated for chunks. 4.69MiB in use in bin. 4.69MiB client-requested in use in bin.
2020-04-04 04:11:44.890069: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (8388608): 	Total Chunks: 1, Chunks in use: 0. 11.31MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890076: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890081: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890087: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890092: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (134217728): 	Total Chunks: 2, Chunks in use: 0. 424.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:11:44.890099: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (268435456): 	Total Chunks: 3, Chunks in use: 3. 948.69MiB allocated for chunks. 948.69MiB in use in bin. 900.00MiB client-requested in use in bin.
2020-04-04 04:11:44.890109: I tensorflow/core/common_runtime/bfc_allocator.cc:917] Bin for 300.00MiB was 256.00MiB, Chunk State: 
2020-04-04 04:11:44.890114: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 365630208
2020-04-04 04:11:44.890708: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa5a8000000 of size 365630208 next 18446744073709551615
2020-04-04 04:11:44.890717: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 536870912
2020-04-04 04:11:44.890723: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa5c8000000 of size 314572800 next 67
2020-04-04 04:11:44.890727: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa5dac00000 of size 222298112 next 18446744073709551615
2020-04-04 04:11:44.890731: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 536870912
2020-04-04 04:11:44.890736: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa6b6000000 of size 314572800 next 63
2020-04-04 04:11:44.890740: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa6c8c00000 of size 222298112 next 18446744073709551615
2020-04-04 04:11:44.890744: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 16777216
2020-04-04 04:11:44.890749: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa6d6000000 of size 4915200 next 60
2020-04-04 04:11:44.890753: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa6d64b0000 of size 11862016 next 18446744073709551615
2020-04-04 04:11:44.890757: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 1048576
2020-04-04 04:11:44.890762: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00000 of size 1280 next 1
2020-04-04 04:11:44.890766: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00500 of size 256 next 2
2020-04-04 04:11:44.890773: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00600 of size 256 next 3
2020-04-04 04:11:44.890779: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00700 of size 256 next 4
2020-04-04 04:11:44.890783: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00800 of size 256 next 5
2020-04-04 04:11:44.890787: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00900 of size 256 next 6
2020-04-04 04:11:44.890792: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00a00 of size 256 next 7
2020-04-04 04:11:44.890797: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00b00 of size 256 next 8
2020-04-04 04:11:44.890801: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00c00 of size 256 next 9
2020-04-04 04:11:44.890805: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00d00 of size 256 next 10
2020-04-04 04:11:44.890810: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00e00 of size 256 next 11
2020-04-04 04:11:44.890814: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec00f00 of size 256 next 12
2020-04-04 04:11:44.890818: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01000 of size 256 next 13
2020-04-04 04:11:44.890824: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01100 of size 256 next 14
2020-04-04 04:11:44.890828: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01200 of size 256 next 15
2020-04-04 04:11:44.890832: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01300 of size 256 next 16
2020-04-04 04:11:44.890837: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01400 of size 256 next 17
2020-04-04 04:11:44.890842: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01500 of size 512 next 18
2020-04-04 04:11:44.890846: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74ec01700 of size 1042688 next 18446744073709551615
2020-04-04 04:11:44.890852: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 2097152
2020-04-04 04:11:44.890856: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f000000 of size 512 next 20
2020-04-04 04:11:44.890861: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f000200 of size 1024 next 21
2020-04-04 04:11:44.890867: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f000600 of size 1024 next 22
2020-04-04 04:11:44.890871: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f000a00 of size 512 next 23
2020-04-04 04:11:44.890877: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f000c00 of size 512 next 24
2020-04-04 04:11:44.890881: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f000e00 of size 1024 next 25
2020-04-04 04:11:44.890887: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f001200 of size 256 next 26
2020-04-04 04:11:44.890891: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f001300 of size 256 next 27
2020-04-04 04:11:44.890896: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f001400 of size 256 next 68
2020-04-04 04:11:44.890901: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f001500 of size 256 next 69
2020-04-04 04:11:44.890905: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f001600 of size 256 next 70
2020-04-04 04:11:44.890910: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f001700 of size 1536 next 28
2020-04-04 04:11:44.890915: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f001d00 of size 256 next 29
2020-04-04 04:11:44.890919: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f001e00 of size 256 next 30
2020-04-04 04:11:44.890924: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f001f00 of size 256 next 31
2020-04-04 04:11:44.890929: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f002000 of size 147456 next 32
2020-04-04 04:11:44.890935: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f026000 of size 256 next 33
2020-04-04 04:11:44.890939: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f026100 of size 256 next 34
2020-04-04 04:11:44.890944: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f026200 of size 256 next 35
2020-04-04 04:11:44.890949: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f026300 of size 66560 next 36
2020-04-04 04:11:44.890954: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f036700 of size 256 next 37
2020-04-04 04:11:44.890959: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f036800 of size 294912 next 38
2020-04-04 04:11:44.890964: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f07e800 of size 512 next 39
2020-04-04 04:11:44.890969: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f07ea00 of size 256 next 40
2020-04-04 04:11:44.890973: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f07eb00 of size 147456 next 41
2020-04-04 04:11:44.890977: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f0a2b00 of size 512 next 42
2020-04-04 04:11:44.890983: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f0a2d00 of size 512 next 43
2020-04-04 04:11:44.890987: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f0a2f00 of size 147456 next 44
2020-04-04 04:11:44.890993: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f0c6f00 of size 256 next 45
2020-04-04 04:11:44.890997: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f0c7000 of size 589824 next 46
2020-04-04 04:11:44.891001: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f157000 of size 512 next 47
2020-04-04 04:11:44.891005: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f157200 of size 512 next 48
2020-04-04 04:11:44.891010: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f157400 of size 256 next 49
2020-04-04 04:11:44.891015: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f157500 of size 512 next 50
2020-04-04 04:11:44.891019: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f157700 of size 690432 next 18446744073709551615
2020-04-04 04:11:44.891025: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 4194304
2020-04-04 04:11:44.891029: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f200000 of size 512 next 52
2020-04-04 04:11:44.891035: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f200200 of size 512 next 53
2020-04-04 04:11:44.891039: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f200400 of size 512 next 54
2020-04-04 04:11:44.891044: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f200600 of size 512 next 55
2020-04-04 04:11:44.891049: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f200800 of size 1179648 next 56
2020-04-04 04:11:44.891054: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f320800 of size 512 next 57
2020-04-04 04:11:44.891059: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f320a00 of size 2304 next 64
2020-04-04 04:11:44.891064: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f321300 of size 76800 next 66
2020-04-04 04:11:44.891071: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7fa74f333f00 of size 153600 next 65
2020-04-04 04:11:44.891076: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7fa74f359700 of size 2779392 next 18446744073709551615
2020-04-04 04:11:44.891080: I tensorflow/core/common_runtime/bfc_allocator.cc:955]      Summary of in-use Chunks by size: 
2020-04-04 04:11:44.891093: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 27 Chunks of size 256 totalling 6.8KiB
2020-04-04 04:11:44.891099: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 15 Chunks of size 512 totalling 7.5KiB
2020-04-04 04:11:44.891105: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 3 Chunks of size 1024 totalling 3.0KiB
2020-04-04 04:11:44.891112: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 1280 totalling 1.2KiB
2020-04-04 04:11:44.891118: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 66560 totalling 65.0KiB
2020-04-04 04:11:44.891124: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 76800 totalling 75.0KiB
2020-04-04 04:11:44.891131: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 3 Chunks of size 147456 totalling 432.0KiB
2020-04-04 04:11:44.891137: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 153600 totalling 150.0KiB
2020-04-04 04:11:44.891143: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 294912 totalling 288.0KiB
2020-04-04 04:11:44.891150: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 589824 totalling 576.0KiB
2020-04-04 04:11:44.891164: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 690432 totalling 674.2KiB
2020-04-04 04:11:44.891170: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 1042688 totalling 1018.2KiB
2020-04-04 04:11:44.891176: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 1179648 totalling 1.12MiB
2020-04-04 04:11:44.891183: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 4915200 totalling 4.69MiB
2020-04-04 04:11:44.891188: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 2 Chunks of size 314572800 totalling 600.00MiB
2020-04-04 04:11:44.891195: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 365630208 totalling 348.69MiB
2020-04-04 04:11:44.891201: I tensorflow/core/common_runtime/bfc_allocator.cc:962] Sum Total of in-use chunks: 957.72MiB
2020-04-04 04:11:44.891207: I tensorflow/core/common_runtime/bfc_allocator.cc:964] total_region_allocated_bytes_: 1463489280 memory_limit_: 1794244608 available bytes: 330755328 curr_region_allocation_bytes_: 2147483648
2020-04-04 04:11:44.891484: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Stats: 
Limit:                  1794244608
InUse:                  1004246784
MaxInUse:               1110350336
NumAllocs:                      99
MaxAllocSize:            365630208

2020-04-04 04:11:44.891498: W tensorflow/core/common_runtime/bfc_allocator.cc:429] **********************xx***********************______________***********************______________**
2020-04-04 04:11:44.990045: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at fused_batch_norm_op.cc:1186 : Resource exhausted: OOM when allocating tensor with shape[64,64,120,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[04/04/2020 04:11:45 INFO] Got Keyboard Interrupt, saving model and closing.
[04/04/2020 04:11:46 INFO] Saving checkpoint for iteration #0
2020-04-04 04:11:47.282305: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
[04/04/2020 04:16:45 INFO] Running command TRAIN
2020-04-04 04:16:45.817533: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-04 04:16:45.848127: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:16:45.848367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:16:45.848406: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:16:45.848442: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:16:45.853501: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:16:45.854585: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:16:45.858107: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:16:45.859565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:16:45.859594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:16:45.859669: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:16:45.859916: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:16:45.860099: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
[04/04/2020 04:16:45 INFO] Number of GPUs detected: 1
[04/04/2020 04:17:12 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f2c3c06ad40> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[04/04/2020 04:17:12 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/synthetic_shapes.py:189: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
[04/04/2020 04:17:12 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/datasets/utils/pipeline.py:69: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[04/04/2020 04:17:13 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f2c089429e0> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

[04/04/2020 04:17:13 WARNING] AutoGraph could not transform <function SyntheticShapes._get_data.<locals>.<lambda> at 0x7f2c08341680> and will run it as-is.
Cause: could not parse the source code:

                    lambda image, points:

This error may be avoided by creating the lambda in a standalone statement.

2020-04-04 04:17:13.234608: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-04 04:17:13.382112: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 3199980000 Hz
2020-04-04 04:17:13.382799: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557b8a6feb0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-04 04:17:13.382811: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-04 04:17:13.514473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:13.514748: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5557b8a53530 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-04 04:17:13.514760: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2060 SUPER, Compute Capability 7.5
2020-04-04 04:17:13.515185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:13.515374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:17:13.525862: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:17:13.525880: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:17:13.599317: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:17:13.599371: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:17:13.599383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:17:13.599395: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:17:13.599404: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:17:13.599473: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:13.599721: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:13.599902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-04 04:17:13.613583: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:17:14.599587: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-04 04:17:14.599612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-04 04:17:14.599616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-04 04:17:14.608128: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:14.608361: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:14.608551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1711 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
{'training': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'validation': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>, 'test': <ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>}
{'name': 'magic_point', 'batch_size': 64, 'eval_batch_size': 50, 'learning_rate': 0.001, 'kernel_reg': 0.0, 'detection_threshold': 0.001, 'nms': 4}
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
<ParallelMapDataset shapes: {image: (None, None, 1), keypoints: (None, 2), valid_mask: (None, None), keypoint_map: (None, None)}, types: {image: tf.float32, keypoints: tf.float32, valid_mask: tf.int32, keypoint_map: tf.int32}>
[04/04/2020 04:17:14 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[04/04/2020 04:17:14 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[04/04/2020 04:17:14 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
[04/04/2020 04:17:14 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[04/04/2020 04:17:14 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[04/04/2020 04:17:14 WARNING] From /home/hashswan/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[04/04/2020 04:17:14 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[04/04/2020 04:17:14 WARNING] From /home/hashswan/Desktop/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.
2020-04-04 04:17:16.110074: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:16.110301: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:01:00.0 name: GeForce RTX 2060 SUPER computeCapability: 7.5
coreClock: 1.83GHz coreCount: 34 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s
2020-04-04 04:17:16.110324: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-04 04:17:16.110333: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:17:16.110346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-04 04:17:16.110353: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-04 04:17:16.110359: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-04 04:17:16.110366: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-04 04:17:16.110372: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:17:16.110415: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:16.110609: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:16.110774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-04 04:17:16.110790: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-04 04:17:16.110794: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-04 04:17:16.110797: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-04 04:17:16.110845: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:16.111038: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2020-04-04 04:17:16.111211: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1711 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2060 SUPER, pci bus id: 0000:01:00.0, compute capability: 7.5)
[04/04/2020 04:17:18 INFO] Start training
2020-04-04 04:17:42.607000: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-04 04:17:46.938928: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:17:46.980873: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.03GiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:17:47.025030: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 701.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:17:47.025126: W tensorflow/core/common_runtime/bfc_allocator.cc:243] Allocator (GPU_0_bfc) ran out of memory trying to allocate 701.56MiB with freed_by_count=0. The caller indicates that this is not a failure, but may mean that there could be performance gains if more memory were available.
2020-04-04 04:17:47.770416: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-04 04:17:49.471793: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 624.12M (654442496 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.472395: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 561.71M (588998400 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.472708: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 505.54M (530098688 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.473022: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 454.99M (477089024 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.473336: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 409.49M (429380096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.473648: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 368.54M (386442240 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.473957: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 331.69M (347798016 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.473969: W tensorflow/core/common_runtime/bfc_allocator.cc:309] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
2020-04-04 04:17:49.482326: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 664.12M (696385536 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:49.482638: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 664.12M (696385536 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:59.483136: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 664.12M (696385536 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:59.483477: I tensorflow/stream_executor/cuda/cuda_driver.cc:801] failed to allocate 664.12M (696385536 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory
2020-04-04 04:17:59.505459: W tensorflow/core/common_runtime/bfc_allocator.cc:424] Allocator (GPU_0_bfc) ran out of memory trying to allocate 300.00MiB (rounded to 314572800).  Current allocation summary follows.
2020-04-04 04:17:59.530500: I tensorflow/core/common_runtime/bfc_allocator.cc:894] BFCAllocator dump for GPU_0_bfc
2020-04-04 04:17:59.530543: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (256): 	Total Chunks: 31, Chunks in use: 30. 7.8KiB allocated for chunks. 7.5KiB in use in bin. 3.5KiB client-requested in use in bin.
2020-04-04 04:17:59.530552: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (512): 	Total Chunks: 15, Chunks in use: 15. 7.5KiB allocated for chunks. 7.5KiB in use in bin. 6.8KiB client-requested in use in bin.
2020-04-04 04:17:59.530560: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (1024): 	Total Chunks: 5, Chunks in use: 4. 5.8KiB allocated for chunks. 4.2KiB in use in bin. 4.0KiB client-requested in use in bin.
2020-04-04 04:17:59.530568: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (2048): 	Total Chunks: 1, Chunks in use: 0. 2.2KiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530575: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (4096): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530582: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (8192): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530589: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (16384): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530596: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (32768): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530609: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (65536): 	Total Chunks: 2, Chunks in use: 2. 140.0KiB allocated for chunks. 140.0KiB in use in bin. 140.0KiB client-requested in use in bin.
2020-04-04 04:17:59.530618: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (131072): 	Total Chunks: 4, Chunks in use: 4. 582.0KiB allocated for chunks. 582.0KiB in use in bin. 582.0KiB client-requested in use in bin.
2020-04-04 04:17:59.530626: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (262144): 	Total Chunks: 2, Chunks in use: 1. 590.5KiB allocated for chunks. 288.0KiB in use in bin. 288.0KiB client-requested in use in bin.
2020-04-04 04:17:59.530632: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (524288): 	Total Chunks: 3, Chunks in use: 3. 1.70MiB allocated for chunks. 1.70MiB in use in bin. 1.69MiB client-requested in use in bin.
2020-04-04 04:17:59.530638: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (1048576): 	Total Chunks: 1, Chunks in use: 1. 1.12MiB allocated for chunks. 1.12MiB in use in bin. 1.12MiB client-requested in use in bin.
2020-04-04 04:17:59.530645: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (2097152): 	Total Chunks: 1, Chunks in use: 0. 2.88MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530651: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (4194304): 	Total Chunks: 1, Chunks in use: 1. 6.62MiB allocated for chunks. 6.62MiB in use in bin. 4.69MiB client-requested in use in bin.
2020-04-04 04:17:59.530658: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (8388608): 	Total Chunks: 1, Chunks in use: 0. 9.38MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530662: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (16777216): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530665: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (33554432): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530669: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (67108864): 	Total Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530673: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (134217728): 	Total Chunks: 2, Chunks in use: 0. 424.00MiB allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.
2020-04-04 04:17:59.530677: I tensorflow/core/common_runtime/bfc_allocator.cc:901] Bin (268435456): 	Total Chunks: 2, Chunks in use: 2. 600.00MiB allocated for chunks. 600.00MiB in use in bin. 600.00MiB client-requested in use in bin.
2020-04-04 04:17:59.530682: I tensorflow/core/common_runtime/bfc_allocator.cc:917] Bin for 300.00MiB was 256.00MiB, Chunk State: 
2020-04-04 04:17:59.530685: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 536870912
2020-04-04 04:17:59.558430: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f29e0000000 of size 314572800 next 69
2020-04-04 04:17:59.558449: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f29f2c00000 of size 222298112 next 18446744073709551615
2020-04-04 04:17:59.558454: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 536870912
2020-04-04 04:17:59.558457: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2ace000000 of size 314572800 next 66
2020-04-04 04:17:59.558460: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2ae0c00000 of size 222298112 next 18446744073709551615
2020-04-04 04:17:59.558462: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 16777216
2020-04-04 04:17:59.558465: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2af0000000 of size 9830400 next 62
2020-04-04 04:17:59.558468: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2af0960000 of size 6946816 next 18446744073709551615
2020-04-04 04:17:59.558471: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 1048576
2020-04-04 04:17:59.558474: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00000 of size 1280 next 1
2020-04-04 04:17:59.558479: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00500 of size 256 next 2
2020-04-04 04:17:59.558482: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00600 of size 256 next 3
2020-04-04 04:17:59.558485: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00700 of size 256 next 4
2020-04-04 04:17:59.558487: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00800 of size 256 next 5
2020-04-04 04:17:59.558489: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00900 of size 256 next 6
2020-04-04 04:17:59.558492: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00a00 of size 256 next 7
2020-04-04 04:17:59.558494: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00b00 of size 256 next 8
2020-04-04 04:17:59.558497: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00c00 of size 256 next 9
2020-04-04 04:17:59.558499: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00d00 of size 256 next 10
2020-04-04 04:17:59.558502: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00e00 of size 256 next 11
2020-04-04 04:17:59.558504: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c00f00 of size 256 next 12
2020-04-04 04:17:59.558507: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01000 of size 256 next 13
2020-04-04 04:17:59.558509: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01100 of size 256 next 14
2020-04-04 04:17:59.558512: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01200 of size 256 next 15
2020-04-04 04:17:59.558514: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01300 of size 256 next 16
2020-04-04 04:17:59.558517: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01400 of size 256 next 17
2020-04-04 04:17:59.558519: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01500 of size 512 next 18
2020-04-04 04:17:59.558522: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01700 of size 256 next 19
2020-04-04 04:17:59.558524: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2b64c01800 of size 256 next 20
2020-04-04 04:17:59.558528: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c01900 of size 147456 next 21
2020-04-04 04:17:59.558530: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c25900 of size 512 next 22
2020-04-04 04:17:59.558533: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c25b00 of size 256 next 23
2020-04-04 04:17:59.558535: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c25c00 of size 256 next 24
2020-04-04 04:17:59.558538: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c25d00 of size 256 next 25
2020-04-04 04:17:59.558540: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c25e00 of size 294912 next 26
2020-04-04 04:17:59.558543: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c6de00 of size 256 next 27
2020-04-04 04:17:59.558546: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b64c6df00 of size 598272 next 18446744073709551615
2020-04-04 04:17:59.558548: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 2097152
2020-04-04 04:17:59.558551: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65000000 of size 256 next 29
2020-04-04 04:17:59.558553: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65000100 of size 256 next 30
2020-04-04 04:17:59.558556: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65000200 of size 512 next 31
2020-04-04 04:17:59.558558: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65000400 of size 512 next 32
2020-04-04 04:17:59.558561: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65000600 of size 147456 next 33
2020-04-04 04:17:59.558564: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65024600 of size 512 next 34
2020-04-04 04:17:59.558566: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65024800 of size 256 next 35
2020-04-04 04:17:59.558569: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65024900 of size 589824 next 36
2020-04-04 04:17:59.558571: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b4900 of size 512 next 37
2020-04-04 04:17:59.558574: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b4b00 of size 512 next 38
2020-04-04 04:17:59.558577: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b4d00 of size 1024 next 39
2020-04-04 04:17:59.558579: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5100 of size 512 next 40
2020-04-04 04:17:59.558581: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5300 of size 512 next 41
2020-04-04 04:17:59.558584: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5500 of size 512 next 42
2020-04-04 04:17:59.558586: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5700 of size 1024 next 43
2020-04-04 04:17:59.558589: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5b00 of size 512 next 44
2020-04-04 04:17:59.558591: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5d00 of size 512 next 45
2020-04-04 04:17:59.558594: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b5f00 of size 512 next 46
2020-04-04 04:17:59.558596: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b6100 of size 1024 next 47
2020-04-04 04:17:59.558599: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b6500 of size 512 next 48
2020-04-04 04:17:59.558601: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b650b6700 of size 589824 next 49
2020-04-04 04:17:59.558604: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65146700 of size 66560 next 52
2020-04-04 04:17:59.558606: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65156b00 of size 512 next 53
2020-04-04 04:17:59.558609: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65156d00 of size 256 next 54
2020-04-04 04:17:59.558611: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65156e00 of size 256 next 55
2020-04-04 04:17:59.558614: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65156f00 of size 256 next 70
2020-04-04 04:17:59.558616: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65157000 of size 256 next 71
2020-04-04 04:17:59.558619: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65157100 of size 256 next 72
2020-04-04 04:17:59.558621: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2b65157200 of size 1536 next 56
2020-04-04 04:17:59.558624: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65157800 of size 256 next 57
2020-04-04 04:17:59.558626: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65157900 of size 147456 next 58
2020-04-04 04:17:59.558629: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2b6517b900 of size 2304 next 67
2020-04-04 04:17:59.558631: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b6517c200 of size 76800 next 68
2020-04-04 04:17:59.558634: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b6518ee00 of size 153600 next 64
2020-04-04 04:17:59.558636: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2b651b4600 of size 309760 next 18446744073709551615
2020-04-04 04:17:59.558639: I tensorflow/core/common_runtime/bfc_allocator.cc:930] Next region of size 4194304
2020-04-04 04:17:59.558643: I tensorflow/core/common_runtime/bfc_allocator.cc:950] InUse at 7f2b65200000 of size 1179648 next 51
2020-04-04 04:17:59.558645: I tensorflow/core/common_runtime/bfc_allocator.cc:950] Free  at 7f2b65320000 of size 3014656 next 18446744073709551615
2020-04-04 04:17:59.558648: I tensorflow/core/common_runtime/bfc_allocator.cc:955]      Summary of in-use Chunks by size: 
2020-04-04 04:17:59.558655: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 30 Chunks of size 256 totalling 7.5KiB
2020-04-04 04:17:59.558658: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 15 Chunks of size 512 totalling 7.5KiB
2020-04-04 04:17:59.558661: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 3 Chunks of size 1024 totalling 3.0KiB
2020-04-04 04:17:59.558664: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 1280 totalling 1.2KiB
2020-04-04 04:17:59.558667: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 66560 totalling 65.0KiB
2020-04-04 04:17:59.558670: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 76800 totalling 75.0KiB
2020-04-04 04:17:59.558673: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 3 Chunks of size 147456 totalling 432.0KiB
2020-04-04 04:17:59.558677: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 153600 totalling 150.0KiB
2020-04-04 04:17:59.558679: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 294912 totalling 288.0KiB
2020-04-04 04:17:59.558682: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 2 Chunks of size 589824 totalling 1.12MiB
2020-04-04 04:17:59.558686: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 598272 totalling 584.2KiB
2020-04-04 04:17:59.558688: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 1179648 totalling 1.12MiB
2020-04-04 04:17:59.558691: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 1 Chunks of size 6946816 totalling 6.62MiB
2020-04-04 04:17:59.558694: I tensorflow/core/common_runtime/bfc_allocator.cc:958] 2 Chunks of size 314572800 totalling 600.00MiB
2020-04-04 04:17:59.558697: I tensorflow/core/common_runtime/bfc_allocator.cc:962] Sum Total of in-use chunks: 610.45MiB
2020-04-04 04:17:59.558700: I tensorflow/core/common_runtime/bfc_allocator.cc:964] total_region_allocated_bytes_: 1097859072 memory_limit_: 1794244608 available bytes: 696385536 curr_region_allocation_bytes_: 1073741824
2020-04-04 04:17:59.606409: I tensorflow/core/common_runtime/bfc_allocator.cc:970] Stats: 
Limit:                  1794244608
InUse:                   640103936
MaxInUse:                717899264
NumAllocs:                      90
MaxAllocSize:            331350016

2020-04-04 04:17:59.606448: W tensorflow/core/common_runtime/bfc_allocator.cc:429] *****************************___________________******************************____________________**
2020-04-04 04:17:59.794602: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at conv_ops.cc:539 : Resource exhausted: OOM when allocating tensor with shape[64,64,120,160] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc
[04/04/2020 04:17:59 INFO] Got Keyboard Interrupt, saving model and closing.
[04/04/2020 04:18:01 INFO] Saving checkpoint for iteration #0
2020-04-04 04:18:02.152013: W tensorflow/core/kernels/data/cache_dataset_ops.cc:822] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
