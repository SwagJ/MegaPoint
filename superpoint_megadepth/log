[04/24/2020 21:54:40 INFO] Running command TRAIN
2020-04-24 21:54:40.034178: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-24 21:54:40.087639: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 21:54:40.090760: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-24 21:54:40.115620: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-24 21:54:40.130667: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-24 21:54:40.138247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-24 21:54:40.165379: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-24 21:54:40.174433: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-24 21:54:40.232232: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-24 21:54:40.237383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
[04/24/2020 21:54:40 INFO] Number of GPUs detected: 1
[04/24/2020 22:00:37 WARNING] From /cluster/scratch/yiflu/SuperPoint/superpoint/datasets/utils/pipeline.py:99: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
[04/24/2020 22:00:38 WARNING] From /cluster/scratch/yiflu/SuperPoint/superpoint/datasets/megadepth.py:100: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.
Instructions for updating:
tf.py_func is deprecated in TF V2. Instead, there are two
    options available in V2.
    - tf.py_function takes a python function which manipulates tf eager
    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to
    an ndarray (just call tensor.numpy()) but having access to eager tensors
    means `tf.py_function`s can use accelerators such as GPUs as well as
    being differentiable using a gradient tape.
    - tf.numpy_function maintains the semantics of the deprecated tf.py_func
    (it is not differentiable, and manipulates numpy arrays). It drops the
    stateful argument making all functions stateful.
    
2020-04-24 22:00:41.542271: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2020-04-24 22:00:41.550755: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2200070000 Hz
2020-04-24 22:00:41.551309: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x995ed30 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-04-24 22:00:41.551334: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-04-24 22:00:41.726587: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x99cd280 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-04-24 22:00:41.726651: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce GTX 1080 Ti, Compute Capability 6.1
2020-04-24 22:00:41.730356: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 22:00:41.730487: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-24 22:00:41.730519: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-24 22:00:41.730546: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-24 22:00:41.730576: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-24 22:00:41.730600: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-24 22:00:41.730623: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-24 22:00:41.730650: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-24 22:00:41.735416: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-24 22:00:41.737393: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-24 22:00:41.739841: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 22:00:41.739868: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-24 22:00:41.739884: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-24 22:00:41.744670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
2020-04-24 22:01:19.366633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 22:01:19.366733: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-24 22:01:19.366761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-24 22:01:19.366780: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-24 22:01:19.366795: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-24 22:01:19.366809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-24 22:01:19.366823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-24 22:01:19.366842: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-24 22:01:19.371653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-24 22:01:19.386145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 22:01:19.386196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-24 22:01:19.386208: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-24 22:01:19.391613: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
/cluster/scratch/yiflu/SuperPoint/superpoint/datasets/megadepth.py:68: UserWarning: Seed 2326140390 from outer graph might be getting used by function Dataset_map_lambda, if the random op has not been provided any seed. Explicitly set the seed in the function if this is not the intended behavior.
  fn, num_parallel_calls=config['num_parallel_calls'])
[04/24/2020 22:01:27 WARNING] From /cluster/home/yiflu/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:347: Iterator.output_types (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_types(iterator)`.
[04/24/2020 22:01:27 WARNING] From /cluster/home/yiflu/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:348: Iterator.output_shapes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_shapes(iterator)`.
[04/24/2020 22:01:27 WARNING] From /cluster/home/yiflu/.local/lib/python3.7/site-packages/tensorflow_core/python/data/ops/iterator_ops.py:350: Iterator.output_classes (from tensorflow.python.data.ops.iterator_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.compat.v1.data.get_output_classes(iterator)`.
[04/24/2020 22:01:42 WARNING] From /cluster/scratch/yiflu/SuperPoint/superpoint/models/backbones/vgg.py:10: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.keras.layers.Conv2D` instead.
[04/24/2020 22:01:42 WARNING] From /cluster/home/yiflu/.local/lib/python3.7/site-packages/tensorflow_core/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `layer.__call__` method instead.
[04/24/2020 22:01:42 WARNING] From /cluster/home/yiflu/.local/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.
Instructions for updating:
If using Keras pass *_constraint arguments to layers.
[04/24/2020 22:01:42 WARNING] From /cluster/scratch/yiflu/SuperPoint/superpoint/models/backbones/vgg.py:14: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).
[04/24/2020 22:01:42 WARNING] From /cluster/scratch/yiflu/SuperPoint/superpoint/models/backbones/vgg.py:28: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.MaxPooling2D instead.
2020-04-24 22:01:48.408593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1555] Found device 0 with properties: 
pciBusID: 0000:0c:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1
coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.92GiB deviceMemoryBandwidth: 451.17GiB/s
2020-04-24 22:01:48.408677: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-04-24 22:01:48.408704: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-24 22:01:48.408725: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-04-24 22:01:48.408749: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-04-24 22:01:48.408772: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-24 22:01:48.408793: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-04-24 22:01:48.408814: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-24 22:01:48.413544: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1697] Adding visible gpu devices: 0
2020-04-24 22:01:48.413598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1096] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-24 22:01:48.413614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102]      0 
2020-04-24 22:01:48.413624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] 0:   N 
2020-04-24 22:01:48.419061: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1241] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10481 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:0c:00.0, compute capability: 6.1)
[04/24/2020 22:02:45 INFO] Start training
2020-04-24 22:02:59.199785: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-24 22:03:02.651360: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-24 22:03:02.653819: I tensorflow/core/kernels/cuda_solvers.cc:159] Creating CudaSolver handles for stream 0x99dec60
2020-04-24 22:03:02.654247: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-04-24 22:03:04.419729: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-04-24 22:03:05.451182: W tensorflow/stream_executor/gpu/redzone_allocator.cc:312] Not found: ./bin/ptxas not found
Relying on driver to perform ptx compilation. This message will be only logged once.
2020-04-24 22:03:06.301322: W tensorflow/core/common_runtime/bfc_allocator.cc:309] Garbage collection: deallocate free memory regions (i.e., allocations) so that we can re-allocate a larger region to avoid OOM due to memory fragmentation. If you see this message frequently, you are running near the threshold of the available device memory and re-allocation may incur great performance overhead. You may try smaller batch sizes to observe the performance impact. Set TF_ENABLE_GPU_GARBAGE_COLLECTION=false if you'd like to disable this feature.
[04/24/2020 22:07:54 INFO] Iter    0: loss 10.1787, precision 0.0059, recall 0.0073
[04/24/2020 22:29:22 INFO] Iter 5000: loss 6.1546, precision 0.0473, recall 0.0605
[04/24/2020 22:48:51 INFO] Iter 10000: loss 4.6073, precision 0.1595, recall 0.2021
[04/24/2020 23:07:52 INFO] Iter 15000: loss 3.5344, precision 0.2397, recall 0.3030
[04/24/2020 23:27:18 INFO] Iter 20000: loss 3.6644, precision 0.2853, recall 0.3594
[04/24/2020 23:46:38 INFO] Iter 25000: loss 2.5995, precision 0.3134, recall 0.3885
[04/25/2020 00:06:08 INFO] Iter 30000: loss 2.5180, precision 0.3481, recall 0.4364
[04/25/2020 00:25:27 INFO] Iter 35000: loss 2.7493, precision 0.3681, recall 0.4584
[04/25/2020 00:44:51 INFO] Iter 40000: loss 2.6053, precision 0.3802, recall 0.4751
[04/25/2020 01:03:55 INFO] Iter 45000: loss 2.1852, precision 0.3906, recall 0.4853
[04/25/2020 01:23:28 INFO] Iter 50000: loss 2.7602, precision 0.4084, recall 0.5112
[04/25/2020 01:42:48 INFO] Iter 55000: loss 2.4140, precision 0.4081, recall 0.5114
[04/25/2020 02:01:31 INFO] Iter 60000: loss 1.3099, precision 0.4050, recall 0.5070
[04/25/2020 02:20:59 INFO] Iter 65000: loss 2.4054, precision 0.4189, recall 0.5260
[04/25/2020 02:40:29 INFO] Iter 70000: loss 2.8721, precision 0.4246, recall 0.5324
[04/25/2020 03:00:05 INFO] Iter 75000: loss 2.8841, precision 0.4318, recall 0.5391
[04/25/2020 03:19:25 INFO] Iter 80000: loss 2.0259, precision 0.4390, recall 0.5393
[04/25/2020 03:40:11 INFO] Iter 85000: loss 2.3063, precision 0.4336, recall 0.5429
[04/25/2020 04:00:41 INFO] Iter 90000: loss 2.7882, precision 0.4274, recall 0.4983
[04/25/2020 04:21:42 INFO] Iter 95000: loss 3.1615, precision 0.4303, recall 0.5419
[04/25/2020 04:42:01 INFO] Iter 100000: loss 3.0700, precision 0.4305, recall 0.5411
[04/25/2020 05:01:56 INFO] Iter 105000: loss 2.7266, precision 0.4417, recall 0.5516
[04/25/2020 05:21:33 INFO] Iter 110000: loss 2.3849, precision 0.4396, recall 0.5509
[04/25/2020 05:41:47 INFO] Iter 115000: loss 2.6223, precision 0.4469, recall 0.5580
[04/25/2020 06:01:15 INFO] Iter 120000: loss 2.0510, precision 0.4536, recall 0.5678
[04/25/2020 06:20:20 INFO] Iter 125000: loss 1.3600, precision 0.4409, recall 0.5504
[04/25/2020 06:40:18 INFO] Iter 130000: loss 4.9489, precision 0.2438, recall 0.2864
[04/25/2020 06:59:48 INFO] Iter 135000: loss 3.1661, precision 0.4423, recall 0.5569
[04/25/2020 07:19:28 INFO] Iter 140000: loss 2.4021, precision 0.4545, recall 0.5677
[04/25/2020 07:38:36 INFO] Iter 145000: loss 3.2398, precision 0.4473, recall 0.5618
[04/25/2020 07:58:43 INFO] Iter 150000: loss 2.5700, precision 0.4493, recall 0.5629
[04/25/2020 08:18:40 INFO] Iter 155000: loss 2.1491, precision 0.4580, recall 0.5721
[04/25/2020 08:38:49 INFO] Iter 160000: loss 2.4493, precision 0.4556, recall 0.5713
[04/25/2020 08:58:38 INFO] Iter 165000: loss 1.9768, precision 0.4537, recall 0.5682
[04/25/2020 09:18:21 INFO] Iter 170000: loss 3.3840, precision 0.4515, recall 0.5667
[04/25/2020 09:37:42 INFO] Iter 175000: loss 2.6982, precision 0.4623, recall 0.5779
[04/25/2020 09:57:47 INFO] Iter 180000: loss 2.2068, precision 0.4467, recall 0.5617
[04/25/2020 10:17:05 INFO] Iter 185000: loss 2.6473, precision 0.4585, recall 0.5736
[04/25/2020 10:36:18 INFO] Iter 190000: loss 1.7071, precision 0.4665, recall 0.5741
[04/25/2020 10:56:09 INFO] Iter 195000: loss 2.0573, precision 0.4624, recall 0.5766
[04/25/2020 11:15:44 INFO] Iter 200000: loss 2.4161, precision 0.4616, recall 0.5758
[04/25/2020 11:35:21 INFO] Iter 205000: loss 2.7643, precision 0.4605, recall 0.5765
[04/25/2020 11:54:45 INFO] Iter 210000: loss 2.7961, precision 0.4532, recall 0.5698
[04/25/2020 12:14:49 INFO] Iter 215000: loss 2.7458, precision 0.4572, recall 0.5713
[04/25/2020 12:34:29 INFO] Iter 220000: loss 2.2114, precision 0.4544, recall 0.5711
[04/25/2020 12:54:18 INFO] Iter 225000: loss 1.8017, precision 0.4656, recall 0.5815
[04/25/2020 13:14:16 INFO] Iter 230000: loss 2.6804, precision 0.4563, recall 0.5738
[04/25/2020 13:33:54 INFO] Iter 235000: loss 5.1750, precision 0.4627, recall 0.3617
[04/25/2020 13:53:17 INFO] Iter 240000: loss 1.4831, precision 0.4384, recall 0.5528
[04/25/2020 14:13:11 INFO] Iter 245000: loss 1.3745, precision 0.4568, recall 0.5743
[04/25/2020 14:32:29 INFO] Iter 250000: loss 3.5581, precision 0.4631, recall 0.5784
[04/25/2020 14:52:02 INFO] Iter 255000: loss 2.8364, precision 0.4646, recall 0.5764
[04/25/2020 15:11:37 INFO] Iter 260000: loss 2.0993, precision 0.4593, recall 0.5751
[04/25/2020 15:31:15 INFO] Iter 265000: loss 1.8090, precision 0.4728, recall 0.5894
[04/25/2020 15:50:52 INFO] Iter 270000: loss 2.5422, precision 0.4673, recall 0.5857
[04/25/2020 16:10:28 INFO] Iter 275000: loss 1.9571, precision 0.4593, recall 0.5739
[04/25/2020 16:30:23 INFO] Iter 280000: loss 1.6247, precision 0.4588, recall 0.5756
[04/25/2020 16:50:23 INFO] Iter 285000: loss 1.8423, precision 0.4755, recall 0.5925
[04/25/2020 17:10:26 INFO] Iter 290000: loss 2.7212, precision 0.4595, recall 0.5772
[04/25/2020 17:30:25 INFO] Iter 295000: loss 3.6372, precision 0.4693, recall 0.5870
[04/25/2020 17:50:31 INFO] Iter 300000: loss 1.6867, precision 0.4629, recall 0.5810
[04/25/2020 18:09:56 INFO] Iter 305000: loss 2.1786, precision 0.4607, recall 0.5782
[04/25/2020 18:29:50 INFO] Iter 310000: loss 3.0058, precision 0.4616, recall 0.5765
[04/25/2020 18:49:15 INFO] Iter 315000: loss 2.8186, precision 0.4615, recall 0.5795
[04/25/2020 19:08:44 INFO] Iter 320000: loss 2.5508, precision 0.4638, recall 0.5819
[04/25/2020 19:28:16 INFO] Iter 325000: loss 2.3153, precision 0.4646, recall 0.5821
[04/25/2020 19:48:06 INFO] Iter 330000: loss 2.6244, precision 0.4635, recall 0.5822
[04/25/2020 20:07:45 INFO] Iter 335000: loss 2.2661, precision 0.4680, recall 0.5848
[04/25/2020 20:28:01 INFO] Iter 340000: loss 2.2153, precision 0.4626, recall 0.5807
[04/25/2020 20:48:35 INFO] Iter 345000: loss 1.4070, precision 0.4575, recall 0.5743
[04/25/2020 21:08:40 INFO] Iter 350000: loss 2.0644, precision 0.4632, recall 0.5818
[04/25/2020 21:28:40 INFO] Iter 355000: loss 1.8107, precision 0.4657, recall 0.5841
[04/25/2020 21:49:06 INFO] Iter 360000: loss 1.8683, precision 0.4744, recall 0.5932
[04/25/2020 22:09:15 INFO] Iter 365000: loss 1.3985, precision 0.4658, recall 0.5829
[04/25/2020 22:28:35 INFO] Iter 370000: loss 2.6337, precision 0.4652, recall 0.5839
[04/25/2020 22:48:27 INFO] Iter 375000: loss 2.5413, precision 0.4634, recall 0.5825
[04/25/2020 23:07:16 INFO] Iter 380000: loss 2.3154, precision 0.4671, recall 0.5866
[04/25/2020 23:26:30 INFO] Iter 385000: loss 1.7574, precision 0.4694, recall 0.5874
[04/25/2020 23:45:44 INFO] Iter 390000: loss 2.6406, precision 0.4659, recall 0.5845
[04/26/2020 00:05:03 INFO] Iter 395000: loss 3.0057, precision 0.4656, recall 0.5851
[04/26/2020 00:24:34 INFO] Iter 400000: loss 1.2993, precision 0.4715, recall 0.5843
[04/26/2020 00:44:10 INFO] Iter 405000: loss 2.6321, precision 0.4703, recall 0.5893
[04/26/2020 01:04:10 INFO] Iter 410000: loss 2.5567, precision 0.4618, recall 0.5811
[04/26/2020 01:23:46 INFO] Iter 415000: loss 2.2947, precision 0.4651, recall 0.5841
[04/26/2020 01:43:34 INFO] Iter 420000: loss 1.9606, precision 0.4724, recall 0.5931
[04/26/2020 02:03:08 INFO] Iter 425000: loss 2.1982, precision 0.4648, recall 0.5831
[04/26/2020 02:22:36 INFO] Iter 430000: loss 2.4724, precision 0.4686, recall 0.5865
[04/26/2020 02:41:49 INFO] Iter 435000: loss 2.5375, precision 0.4533, recall 0.5705
[04/26/2020 03:01:25 INFO] Iter 440000: loss 2.5833, precision 0.4718, recall 0.5912
[04/26/2020 03:20:28 INFO] Iter 445000: loss 2.5079, precision 0.4625, recall 0.5808
[04/26/2020 03:40:03 INFO] Iter 450000: loss 1.3763, precision 0.4640, recall 0.5831
[04/26/2020 03:59:31 INFO] Iter 455000: loss 1.6519, precision 0.4631, recall 0.5787
[04/26/2020 04:18:51 INFO] Iter 460000: loss 3.3749, precision 0.4637, recall 0.5818
[04/26/2020 04:38:16 INFO] Iter 465000: loss 2.0648, precision 0.4661, recall 0.5850
[04/26/2020 04:57:43 INFO] Iter 470000: loss 2.7873, precision 0.4638, recall 0.5816
[04/26/2020 05:17:42 INFO] Iter 475000: loss 2.6289, precision 0.4674, recall 0.5863
[04/26/2020 05:37:26 INFO] Iter 480000: loss 3.0356, precision 0.4593, recall 0.5780
[04/26/2020 05:57:03 INFO] Iter 485000: loss 3.4510, precision 0.4636, recall 0.5148
[04/26/2020 06:16:42 INFO] Iter 490000: loss 3.0671, precision 0.4688, recall 0.5889
[04/26/2020 06:35:49 INFO] Iter 495000: loss 2.8280, precision 0.4663, recall 0.5843
[04/26/2020 06:54:51 INFO] Iter 500000: loss 1.9678, precision 0.4691, recall 0.5878
[04/26/2020 07:14:08 INFO] Iter 505000: loss 2.8584, precision 0.4685, recall 0.5871
[04/26/2020 07:32:48 INFO] Iter 510000: loss 2.8043, precision 0.4624, recall 0.5821
[04/26/2020 07:52:11 INFO] Iter 515000: loss 3.4746, precision 0.4567, recall 0.5756
[04/26/2020 08:11:11 INFO] Iter 520000: loss 3.5127, precision 0.4747, recall 0.5936
[04/26/2020 08:30:12 INFO] Iter 525000: loss 2.7603, precision 0.4790, recall 0.5951
[04/26/2020 08:49:17 INFO] Iter 530000: loss 2.5683, precision 0.4664, recall 0.5837
[04/26/2020 09:08:44 INFO] Iter 535000: loss 1.8299, precision 0.4660, recall 0.5853
[04/26/2020 09:28:16 INFO] Iter 540000: loss 2.6459, precision 0.4400, recall 0.5534
[04/26/2020 09:48:34 INFO] Iter 545000: loss 2.3522, precision 0.4657, recall 0.5846
[04/26/2020 10:08:00 INFO] Iter 550000: loss 2.9035, precision 0.4700, recall 0.5899
[04/26/2020 10:28:05 INFO] Iter 555000: loss 3.6729, precision 0.4593, recall 0.5787
[04/26/2020 10:47:42 INFO] Iter 560000: loss 2.5918, precision 0.4665, recall 0.5851
[04/26/2020 11:07:33 INFO] Iter 565000: loss 2.7539, precision 0.4701, recall 0.5897
[04/26/2020 11:27:04 INFO] Iter 570000: loss 2.3716, precision 0.4718, recall 0.5910
[04/26/2020 11:46:11 INFO] Iter 575000: loss 2.4457, precision 0.4599, recall 0.5789
[04/26/2020 12:06:08 INFO] Iter 580000: loss 2.3819, precision 0.4642, recall 0.5832
[04/26/2020 12:25:25 INFO] Iter 585000: loss 2.1051, precision 0.4752, recall 0.5944
[04/26/2020 12:44:14 INFO] Iter 590000: loss 3.6456, precision 0.4743, recall 0.5934
[04/26/2020 13:02:41 INFO] Iter 595000: loss 1.8586, precision 0.4769, recall 0.5958
[04/26/2020 13:21:25 INFO] Training finished
[04/26/2020 13:21:33 INFO] Saving checkpoint for iteration #600000
training
image (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
validation
image (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
test
image (None, None, 1)
name ()
keypoints (None, 2)
valid_mask (None, None)
warped {'image': TensorShape([None, None, 1]), 'name': TensorShape([]), 'keypoints': TensorShape([None, 2]), 'valid_mask': TensorShape([None, None]), 'homography': TensorShape([8]), 'keypoint_map': TensorShape([None, None])}
keypoint_map (None, None)
